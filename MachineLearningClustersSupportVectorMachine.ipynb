{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70fd4e91",
   "metadata": {},
   "source": [
    "## A Machine Learning approach to classifying $b$-matrices by cluster algebra: Support Vector Machines\n",
    "\n",
    "The preceding notebook aims to use artificial neural networks in Keras to classify $b$-matrices by cluster algebra. Since we are trying to classify vectors in real space here we attempt to use support vector machines (in scikit) to solve this problem. Firstly we experiment with a binary classification of $b$-matrices of $A_5$ and $D_5$ type, as see that by choosing a support vector machine with a quartic kernel we are able to achieve perfect accuracy on our test data. We then apply this same model to the $A_6$ and $D_6$ case, and see that the accuracy suffers ($0.95$) but is still very good. Finally we introduce $b$-matrices of $E_6$ type to attempt a ternary classification for $A_6$, $D_6$ and $E_6$. With the same model as before we have accuracies of $0.8$. Moreover we see that if we take a degree $6$ kernel we can improve this slightly to $0.825$.\n",
    "\n",
    "We reiterate our gratefulness to the papers [1, 2], where the authors first applied machine learning to various problems in cluster algebras. A more detailed introduction is given in our Keras notebook.\n",
    "\n",
    "<cite data-cite=\"bao\">[1] Bao, Jiakang, et al. \"Quiver mutations, Seiberg duality, and machine learning.\" Physical Review D 102.8 (2020): 086013.</cite> https://arxiv.org/abs/2006.10783\n",
    "    \n",
    "<cite data-cite=\"dechant\">[2] Dechant, Pierre-Philippe, et al. \"Cluster Algebras: Network Science and Machine Learning.\" arXiv preprint arXiv:2203.13847 (2022)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a531f793",
   "metadata": {},
   "source": [
    "## Contents:\n",
    "* [Importing the $A_5$ and $D_5$ data](#1)\n",
    "* [Support vector machines for $A_5$ and $D_5$](#2)\n",
    "* [Support vector machines for $A_6$ and $D_6$](#3)\n",
    "* [Ternary classification with $A_6$, $D_6$ and $E_6$](#4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafeab6b",
   "metadata": {},
   "source": [
    "## Importing the $A_5$ and $D_5$ data <a class=\"anchor\" id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c806f68b",
   "metadata": {},
   "source": [
    "We import all the necessary data we will experiment with with little explanation. More details about this process are given in the preceeding Keras notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "124ff2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import sklearn\n",
    "from sklearn.model_selection import *\n",
    "from sklearn import *\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27ebfa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A5 data\n",
    "\n",
    "with open('cluster_data_A5_depth_100.csv') as fp:\n",
    "    reader = csv.reader(fp, delimiter=\",\", quotechar='\"')\n",
    "    data = [row for row in reader]\n",
    "\n",
    "data=data[0] # All stored in first row, so just take that\n",
    "\n",
    "cluster_type = data[0] # Cluster type stored as first entry\n",
    "\n",
    "data = [np.array(np.matrix(data[i])).ravel() for i in range(1, len(data))] # The vectors have been converted to strings,\n",
    "                                                                           # so need to undo this. Also discard cluster type\n",
    "data = [np.append(i, np.array([0])) for i in data] # A5 encoded as 0\n",
    "A5_data = data\n",
    "\n",
    "A5_array = A5_data[0]\n",
    "for i in range(1, len(A5_data)):\n",
    "    A5_array = np.vstack([A5_array, A5_data[i]])\n",
    "\n",
    "# D5 data\n",
    "    \n",
    "with open('cluster_data_D5_depth_100.csv') as fp:\n",
    "    reader = csv.reader(fp, delimiter=\",\", quotechar='\"')\n",
    "    data = [row for row in reader]    \n",
    "data=data[0]\n",
    "cluster_type = data[0]\n",
    "data = [np.array(np.matrix(data[i])).ravel() for i in range(1, len(data))]\n",
    "data = [np.append(i, np.array([1])) for i in data] # D5 encoded as 1\n",
    "D5_data = data\n",
    "\n",
    "D5_array = D5_data[0]\n",
    "for i in range(1, len(D5_data)):\n",
    "    D5_array = np.vstack([D5_array, D5_data[i]])\n",
    "    \n",
    "# The features\n",
    "X = np.vstack([A5_array[:,:-1], D5_array[:,:-1]])\n",
    "\n",
    "y = np.vstack([A5_array[:,-1:], D5_array[:,-1:]])\n",
    "\n",
    "y = y.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c9f710",
   "metadata": {},
   "source": [
    "## Support vector machines for $A_5$ and $D_5$ <a class=\"anchor\" id=\"2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257e5f67",
   "metadata": {},
   "source": [
    "Here we try appling scikit's support vector machines to the $A_5$ and $D_5$ data. We see that in this case, with the C support vector classification we are able to obtain accuracies of $1$, which is very encouraging."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493c4499",
   "metadata": {},
   "source": [
    "Firstly we apply a scaler to the data. In this case this has little effect, however."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87f4b46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(X)\n",
    "\n",
    "# Train / test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a9bd71",
   "metadata": {},
   "source": [
    "First of all we try the linear SVC. With the default settings the accuracy is poor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d212f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default accuracy is 0.3260445983979216\n"
     ]
    }
   ],
   "source": [
    "machine = svm.LinearSVC()\n",
    "machine.fit(X_train, y_train)\n",
    "y_predict = machine.predict(X_test)\n",
    "print(f'Default accuracy is {metrics.accuracy_score(y_test, y_predict)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a1a5f6",
   "metadata": {},
   "source": [
    "We can set the C parameter which is inversely proportional to the regularization, we need to set max_iter parameter higher for this to work, but it doesn't give good results anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16facafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.3260445983979216\n"
     ]
    }
   ],
   "source": [
    "machine = svm.LinearSVC(C=10, max_iter=10000)\n",
    "machine.fit(X_train, y_train)\n",
    "y_predict = machine.predict(X_test)\n",
    "print(f'Accuracy is {metrics.accuracy_score(y_test, y_predict)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835e0d57",
   "metadata": {},
   "source": [
    "Next we try the C-support vector classification. Again, by default the accuracy is poor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66b4556a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default accuracy is 0.5730909090909091\n"
     ]
    }
   ],
   "source": [
    "machine = svm.SVC()\n",
    "machine.fit(X_train, y_train)\n",
    "y_predict = machine.predict(X_test)\n",
    "print(f'Default accuracy is {metrics.accuracy_score(y_test, y_predict)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca12624c",
   "metadata": {},
   "source": [
    "We have control over a parameter $C$, which is inversely proportional to the regularization. This seems to be very fruitful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16e1f707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With C as 30 accuracy is 0.7992727272727272\n"
     ]
    }
   ],
   "source": [
    "machine = svm.SVC(C=30)\n",
    "machine.fit(X_train, y_train)\n",
    "y_predict = machine.predict(X_test)\n",
    "print(f'With C as 30 accuracy is {metrics.accuracy_score(y_test, y_predict)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc7ea4f",
   "metadata": {},
   "source": [
    "We also have a kernel parameter, which is 'rbf' by default. We can try the other options. In particular we have a polynomial kernel, for which we need to select a degree. With even degrees this does very well, in particular degree $4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4f24fa0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With linear kernel accuracy is 0.5301818181818182\n",
      "With polynomial kernel and degree 0 accuracy is 0.5301818181818182\n",
      "With polynomial kernel and degree 1 accuracy is 0.5301818181818182\n",
      "With polynomial kernel and degree 2 accuracy is 0.5621818181818182\n",
      "With polynomial kernel and degree 3 accuracy is 0.37454545454545457\n",
      "With polynomial kernel and degree 4 accuracy is 1.0\n",
      "With polynomial kernel and degree 5 accuracy is 0.1781818181818182\n",
      "With polynomial kernel and degree 6 accuracy is 0.9127272727272727\n",
      "With polynomial kernel and degree 7 accuracy is 0.4109090909090909\n",
      "With sigmoid kernel accuracy is 0.5381818181818182\n"
     ]
    }
   ],
   "source": [
    "# Linear kernel, not very good.\n",
    "\n",
    "machine = svm.SVC(C=30, kernel='linear')\n",
    "machine.fit(X_train, y_train)\n",
    "y_predict = machine.predict(X_test)\n",
    "print(f'With linear kernel accuracy is {metrics.accuracy_score(y_test, y_predict)}')\n",
    "\n",
    "# Polynomial kernel, we also need to set a degree here. Here even degrees seems to be very good, odd degrees are very bad. \n",
    "# We see very good results for quartic. \n",
    "\n",
    "for i in range(8):\n",
    "    machine = svm.SVC(C=30, kernel='poly', degree=i)\n",
    "    machine.fit(X_train, y_train)\n",
    "    y_predict = machine.predict(X_test)\n",
    "    print(f'With polynomial kernel and degree {i} accuracy is {metrics.accuracy_score(y_test, y_predict)}')\n",
    "    \n",
    "# Sigmoid kernel, accuracy is not good.    \n",
    "\n",
    "machine = svm.SVC(C=30, kernel='sigmoid')\n",
    "machine.fit(X_train, y_train)\n",
    "y_predict = machine.predict(X_test)\n",
    "print(f'With sigmoid kernel accuracy is {metrics.accuracy_score(y_test, y_predict)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46277be",
   "metadata": {},
   "source": [
    "Finally we have $\\nu$-support vector classification. Apparently this is a reparametrization of the SVC. The default accuracy here is quite good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3a7fae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default accuracy is 0.8072727272727273\n"
     ]
    }
   ],
   "source": [
    "machine = svm.NuSVC()\n",
    "machine.fit(X_train, y_train)\n",
    "y_predict = machine.predict(X_test)\n",
    "print(f'Default accuracy is {metrics.accuracy_score(y_test, y_predict)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac19317",
   "metadata": {},
   "source": [
    "The name of this is due to the $\\nu$ parameter in $(0,1]$. We can get some good accuracies for $\\nu$ close to $0.1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ab50c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With nu as 0.06, accuracy is 0.8807272727272727\n",
      "With nu as 0.08249999999999999, accuracy is 0.8770909090909091\n",
      "With nu as 0.105, accuracy is 0.8792727272727273\n",
      "With nu as 0.1275, accuracy is 0.8785454545454545\n",
      "With nu as 0.15, accuracy is 0.88\n"
     ]
    }
   ],
   "source": [
    "for nu in np.linspace(0.06, 0.15, 5):\n",
    "    machine = svm.NuSVC(nu=nu)\n",
    "    machine.fit(X_train, y_train)\n",
    "    y_predict = machine.predict(X_test)\n",
    "    print(f'With nu as {nu}, accuracy is {metrics.accuracy_score(y_test, y_predict)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361c8241",
   "metadata": {},
   "source": [
    "The same as before, we have a kernel parameter, which is 'rbf' by default. Again we see the best results with a quartic polynomial kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b4032e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With linear kernel accuracy is 0.488\n",
      "With polynomial kernel and degree 2 accuracy is 0.45381818181818184\n",
      "With polynomial kernel and degree 3 accuracy is 0.5243636363636364\n",
      "With polynomial kernel and degree 4 accuracy is 1.0\n",
      "With polynomial kernel and degree 5 accuracy is 0.632\n",
      "With polynomial kernel and degree 6 accuracy is 0.9141818181818182\n",
      "With sigmoid kernel accuracy is 0.4749090909090909\n"
     ]
    }
   ],
   "source": [
    "# Linear\n",
    "\n",
    "machine = svm.NuSVC(nu=0.1, kernel='linear')\n",
    "machine.fit(X_train, y_train)\n",
    "y_predict = machine.predict(X_test)\n",
    "print(f'With linear kernel accuracy is {metrics.accuracy_score(y_test, y_predict)}')\n",
    "\n",
    "# Polynomial\n",
    "\n",
    "for i in range(2, 7):\n",
    "    machine = svm.NuSVC(nu=0.1, kernel='poly', degree=i)\n",
    "    machine.fit(X_train, y_train)\n",
    "    y_predict = machine.predict(X_test)\n",
    "    print(f'With polynomial kernel and degree {i} accuracy is {metrics.accuracy_score(y_test, y_predict)}')    \n",
    "    \n",
    "# Sigmoid\n",
    "\n",
    "machine = svm.NuSVC(nu=0.1, kernel='sigmoid')\n",
    "machine.fit(X_train, y_train)\n",
    "y_predict = machine.predict(X_test)\n",
    "print(f'With sigmoid kernel accuracy is {metrics.accuracy_score(y_test, y_predict)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbeb8447",
   "metadata": {},
   "source": [
    "## Support vector machines for $A_6$ and $D_6$ <a class=\"anchor\" id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a7d243",
   "metadata": {},
   "source": [
    "Now we look at $b$-matrices for $A_6$ and $D_6$, to see how our machine performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23db3b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A6\n",
    "\n",
    "with open('cluster_data_A6_depth_6.csv') as fp:\n",
    "    reader = csv.reader(fp, delimiter=\",\", quotechar='\"')\n",
    "    data = [row for row in reader]\n",
    "data=data[0]\n",
    "cluster_type = data[0]\n",
    "data = [np.array(np.matrix(data[i])).ravel() for i in range(1, len(data))]\n",
    "data = [np.append(i, np.array([0])) for i in data]\n",
    "A6_data = data\n",
    "A6_array = A6_data[0]\n",
    "for i in range(1, len(A6_data)):\n",
    "    A6_array = np.vstack([A6_array, A6_data[i]])\n",
    "    \n",
    "# D6\n",
    "\n",
    "with open('cluster_data_D6_depth_6.csv') as fp:\n",
    "    reader = csv.reader(fp, delimiter=\",\", quotechar='\"')\n",
    "    data = [row for row in reader]\n",
    "data=data[0]\n",
    "cluster_type = data[0]\n",
    "data = [np.array(np.matrix(data[i])).ravel() for i in range(1, len(data))]\n",
    "data = [np.append(i, np.array([1])) for i in data]\n",
    "D6_data = data\n",
    "D6_array = D6_data[0]\n",
    "for i in range(1, len(D6_data)):\n",
    "    D6_array = np.vstack([D6_array, D6_data[i]])\n",
    "    \n",
    "# Features, targets\n",
    "\n",
    "X = np.vstack([A6_array[:,:-1], D6_array[:,:-1]])\n",
    "y = np.vstack([A6_array[:,-1:], D6_array[:,-1:]])\n",
    "y = y.ravel()\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6638d8",
   "metadata": {},
   "source": [
    "Our best machine from the previous case was SVC with a quartic kernel, which here achieves accuracies of $0.95$, which is good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7efb766f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With polynomial kernel of degree 4 accuracy is 0.9525897061211236\n"
     ]
    }
   ],
   "source": [
    "machine = svm.SVC(C=30, kernel='poly', degree=4)\n",
    "machine.fit(X_train, y_train)\n",
    "y_predict = machine.predict(X_test)\n",
    "print(f'With polynomial kernel of degree 4 accuracy is {metrics.accuracy_score(y_test, y_predict)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf4ab7e",
   "metadata": {},
   "source": [
    "Since we have more data we check to see how a higher degree even polynomial kernel performs. We can see it is good but still worse than degree $4$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "95717820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With polynomial kernel of degree 6 accuracy is 0.9363533041078097\n"
     ]
    }
   ],
   "source": [
    "machine = svm.SVC(C=30, kernel='poly', degree=6)\n",
    "machine.fit(X_train, y_train)\n",
    "y_predict = machine.predict(X_test)\n",
    "print(f'With polynomial kernel of degree 6 accuracy is {metrics.accuracy_score(y_test, y_predict)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4f4e2b",
   "metadata": {},
   "source": [
    "## Ternary classification with $A_6$, $D_6$ and $E_6$ <a class=\"anchor\" id=\"4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2293a77",
   "metadata": {},
   "source": [
    "Now we introduce $b$-matrices of $E_6$ type to see how our model can handle a ternary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f4b1fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A6\n",
    "\n",
    "with open('cluster_data_A6_depth_6.csv') as fp:\n",
    "    reader = csv.reader(fp, delimiter=\",\", quotechar='\"')\n",
    "    data = [row for row in reader]\n",
    "data=data[0]\n",
    "cluster_type = data[0]\n",
    "data = [np.array(np.matrix(data[i])).ravel() for i in range(1, len(data))]\n",
    "data = [np.append(i, np.array([0])) for i in data] # Now we have 3 labels need to relabel targets as 3-d basis vectors\n",
    "A6_data = data\n",
    "A6_array = A6_data[0]\n",
    "for i in range(1, len(A6_data)):\n",
    "    A6_array = np.vstack([A6_array, A6_data[i]])\n",
    "    \n",
    "# D6\n",
    "    \n",
    "with open('cluster_data_D6_depth_6.csv') as fp:\n",
    "    reader = csv.reader(fp, delimiter=\",\", quotechar='\"')\n",
    "    data = [row for row in reader]\n",
    "data=data[0]\n",
    "cluster_type = data[0]\n",
    "data = [np.array(np.matrix(data[i])).ravel() for i in range(1, len(data))]\n",
    "data = [np.append(i, np.array([1])) for i in data]\n",
    "D6_data = data\n",
    "D6_array = D6_data[0]\n",
    "for i in range(1, len(D6_data)):\n",
    "    D6_array = np.vstack([D6_array, D6_data[i]])\n",
    "\n",
    "# E6     \n",
    "    \n",
    "with open('cluster_data_E6_depth_6.csv') as fp:\n",
    "    reader = csv.reader(fp, delimiter=\",\", quotechar='\"')\n",
    "    data = [row for row in reader]\n",
    "data=data[0]\n",
    "cluster_type = data[0]\n",
    "data = [np.array(np.matrix(data[i])).ravel() for i in range(1, len(data))]\n",
    "data = [np.append(i, np.array([2])) for i in data]\n",
    "E6_data = data\n",
    "E6_array = E6_data[0]\n",
    "for i in range(1, len(E6_data)):\n",
    "    E6_array = np.vstack([E6_array, E6_data[i]])\n",
    "    \n",
    "# Features, targets\n",
    "\n",
    "X = np.vstack([A6_array[:,:-1], D6_array[:,:-1]])\n",
    "X = np.vstack([X, E6_array[:,:-1]])\n",
    "y = np.vstack([A6_array[:,-1:], D6_array[:,-1:]])\n",
    "y = np.vstack([y, E6_array[:,-1:]])\n",
    "y = y.ravel()\n",
    "scaler = StandardScaler()\n",
    "scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31453071",
   "metadata": {},
   "source": [
    "We first try our best machine so far. It's accuracy is around $0.8$, which is good for a ternary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f96d4075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With polynomial kernel of degree 4 accuracy is 0.8063433643645811\n"
     ]
    }
   ],
   "source": [
    "machine = svm.SVC(C=30, kernel='poly', degree=4)\n",
    "machine.fit(X_train, y_train)\n",
    "y_predict = machine.predict(X_test)\n",
    "print(f'With polynomial kernel of degree 4 accuracy is {metrics.accuracy_score(y_test, y_predict)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4b3674",
   "metadata": {},
   "source": [
    "We again check to see how degree $6$ performs, and see that in this case it is slightly better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d5be634f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With polynomial kernel of degree 6 accuracy is 0.8256116042433427\n"
     ]
    }
   ],
   "source": [
    "machine = svm.SVC(C=30, kernel='poly', degree=6)\n",
    "machine.fit(X_train, y_train)\n",
    "y_predict = machine.predict(X_test)\n",
    "print(f'With polynomial kernel of degree 6 accuracy is {metrics.accuracy_score(y_test, y_predict)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5198ad07",
   "metadata": {},
   "source": [
    "Finally we check to see if degree $8$ is reliable, but it is worse than degree $6$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "622f6ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With polynomial kernel of degree 8 accuracy is 0.8060186187486469\n"
     ]
    }
   ],
   "source": [
    "machine = svm.SVC(C=30, kernel='poly', degree=8)\n",
    "machine.fit(X_train, y_train)\n",
    "y_predict = machine.predict(X_test)\n",
    "print(f'With polynomial kernel of degree 8 accuracy is {metrics.accuracy_score(y_test, y_predict)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
