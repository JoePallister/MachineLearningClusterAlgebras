{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a364b50",
   "metadata": {},
   "source": [
    "## A Machine Learning approach to classifying $b$-matrices by cluster algebra: Keras with convolution layers\n",
    "\n",
    "This notebook is a continuation of the previous few. Our goal is to explore the application of machine learning algorithms to classifications of $b$-matrices in cluster algebras. Before we mapped the matrices to vectors, which became the inputs for our models. Here we keep the matrix structure and use Keras with convolution layers instead. This was inspired by the recent (2020) work of [1]. \n",
    "\n",
    "The $b$-matrices mentioned above are generated in a supplementary worksheet running the Sage kernel, to make use of the Sage package for cluster algebras https://doc.sagemath.org/html/en/reference/algebras/sage/algebras/cluster_algebra.html. Interested readers may make use of the compendium for this package [2].\n",
    "\n",
    "<cite data-cite=\"bao\">[1] Bao, Jiakang, et al. \"Quiver mutations, Seiberg duality, and machine learning.\" Physical Review D 102.8 (2020): 086013.</cite> https://arxiv.org/abs/2006.10783\n",
    "\n",
    "<cite data-cite=\"musiker\">[2] Musiker, Gregg, and Christian Stump. \"A compendium on the cluster algebra and quiver package in Sage.\" arXiv preprint arXiv:1102.4844 (2011). </cite> https://arxiv.org/abs/1102.4844"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb02e3e",
   "metadata": {},
   "source": [
    "## Contents:\n",
    "* [Importing the $A_5$ and $D_5$ data](#1)\n",
    "* [Keras models for $A_5$ and $D_5$ with convolution](#2)\n",
    "* [The same Keras model with $A_6$ and $D_6$](#3)\n",
    "* [Ternary classification with $A_6$, $D_6$ and $E_6$](#4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d772f35",
   "metadata": {},
   "source": [
    "## Importing the $A_5$ and $D_5$ data <a class=\"anchor\" id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4177c3f5",
   "metadata": {},
   "source": [
    "Here we import our $A_5$ and $D_5$ data. We have to reshape our feature variables $X$ as matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c72bfbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73965ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A5\n",
    "\n",
    "with open('cluster_data_A5_depth_100.csv') as fp:\n",
    "    reader = csv.reader(fp, delimiter=\",\", quotechar='\"')\n",
    "    data = [row for row in reader]\n",
    "data=data[0]\n",
    "cluster_type = data[0]\n",
    "data = [np.array(np.matrix(data[i])).ravel() for i in range(1, len(data))]\n",
    "data = [np.append(i, np.array([1, 0])) for i in data]\n",
    "A5_data = data\n",
    "A5_array = A5_data[0]\n",
    "for i in range(1, len(A5_data)):\n",
    "    A5_array = np.vstack([A5_array, A5_data[i]])\n",
    "    \n",
    "# D5\n",
    "\n",
    "with open('cluster_data_D5_depth_100.csv') as fp:\n",
    "    reader = csv.reader(fp, delimiter=\",\", quotechar='\"')\n",
    "    data = [row for row in reader]    \n",
    "data=data[0]\n",
    "cluster_type = data[0]\n",
    "data = [np.array(np.matrix(data[i])).ravel() for i in range(1, len(data))]\n",
    "data = [np.append(i, np.array([0, 1])) for i in data]\n",
    "D5_data = data\n",
    "D5_array = D5_data[0]\n",
    "for i in range(1, len(D5_data)):\n",
    "    D5_array = np.vstack([D5_array, D5_data[i]])\n",
    "    \n",
    "# Features\n",
    "X = np.vstack([A5_array[:,:-2], D5_array[:,:-2]])\n",
    "\n",
    "# Reshape as matrices\n",
    "Z = np.array([np.resize(X[0], (5,5))])\n",
    "for i in range(1, len(X)):\n",
    "    new = np.resize(X[i], (5,5))\n",
    "    new2 = np.array([new])\n",
    "    Z = np.append(Z, new2, axis=0)\n",
    "\n",
    "X = Z\n",
    "\n",
    "# Targets\n",
    "y = np.vstack([A5_array[:,-2:], D5_array[:,-2:]])\n",
    "\n",
    "# Train / test split.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2545d1",
   "metadata": {},
   "source": [
    "## Keras models for $A_5$ and $D_5$ with convolution <a class=\"anchor\" id=\"2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d0de3b",
   "metadata": {},
   "source": [
    "Here we run a simple Keras model with one convolution layer. With a large number of epochs we can achieve accuracies of $0.7$, which is okay for such a simple model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98d9bb4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "75/75 [==============================] - 1s 4ms/step - loss: 0.6937 - accuracy: 0.5150 - val_loss: 0.6912 - val_accuracy: 0.5233\n",
      "Epoch 2/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6913 - accuracy: 0.5307 - val_loss: 0.6904 - val_accuracy: 0.5179\n",
      "Epoch 3/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6892 - accuracy: 0.5307 - val_loss: 0.6901 - val_accuracy: 0.5161\n",
      "Epoch 4/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6877 - accuracy: 0.5459 - val_loss: 0.6900 - val_accuracy: 0.5143\n",
      "Epoch 5/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6865 - accuracy: 0.5428 - val_loss: 0.6892 - val_accuracy: 0.5215\n",
      "Epoch 6/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6845 - accuracy: 0.5710 - val_loss: 0.6875 - val_accuracy: 0.5394\n",
      "Epoch 7/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6817 - accuracy: 0.5558 - val_loss: 0.6894 - val_accuracy: 0.5430\n",
      "Epoch 8/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6809 - accuracy: 0.5814 - val_loss: 0.6867 - val_accuracy: 0.5448\n",
      "Epoch 9/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6775 - accuracy: 0.5778 - val_loss: 0.6847 - val_accuracy: 0.5448\n",
      "Epoch 10/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6753 - accuracy: 0.5899 - val_loss: 0.6831 - val_accuracy: 0.5484\n",
      "Epoch 11/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6727 - accuracy: 0.5975 - val_loss: 0.6802 - val_accuracy: 0.5789\n",
      "Epoch 12/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6691 - accuracy: 0.6015 - val_loss: 0.6793 - val_accuracy: 0.5699\n",
      "Epoch 13/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6666 - accuracy: 0.6065 - val_loss: 0.6775 - val_accuracy: 0.5806\n",
      "Epoch 14/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6633 - accuracy: 0.6221 - val_loss: 0.6760 - val_accuracy: 0.5896\n",
      "Epoch 15/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6597 - accuracy: 0.6114 - val_loss: 0.6733 - val_accuracy: 0.5860\n",
      "Epoch 16/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6572 - accuracy: 0.6150 - val_loss: 0.6717 - val_accuracy: 0.5914\n",
      "Epoch 17/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6532 - accuracy: 0.6298 - val_loss: 0.6724 - val_accuracy: 0.5681\n",
      "Epoch 18/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6500 - accuracy: 0.6275 - val_loss: 0.6708 - val_accuracy: 0.5663\n",
      "Epoch 19/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6468 - accuracy: 0.6410 - val_loss: 0.6650 - val_accuracy: 0.5842\n",
      "Epoch 20/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6444 - accuracy: 0.6351 - val_loss: 0.6680 - val_accuracy: 0.5609\n",
      "Epoch 21/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6421 - accuracy: 0.6441 - val_loss: 0.6624 - val_accuracy: 0.5842\n",
      "Epoch 22/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6396 - accuracy: 0.6428 - val_loss: 0.6589 - val_accuracy: 0.5950\n",
      "Epoch 23/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6367 - accuracy: 0.6517 - val_loss: 0.6579 - val_accuracy: 0.6093\n",
      "Epoch 24/1000\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.6326 - accuracy: 0.6513 - val_loss: 0.6569 - val_accuracy: 0.5914\n",
      "Epoch 25/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6312 - accuracy: 0.6656 - val_loss: 0.6554 - val_accuracy: 0.5914\n",
      "Epoch 26/1000\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.6284 - accuracy: 0.6616 - val_loss: 0.6535 - val_accuracy: 0.6039\n",
      "Epoch 27/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6257 - accuracy: 0.6625 - val_loss: 0.6514 - val_accuracy: 0.5986\n",
      "Epoch 28/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6242 - accuracy: 0.6661 - val_loss: 0.6486 - val_accuracy: 0.6004\n",
      "Epoch 29/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6205 - accuracy: 0.6602 - val_loss: 0.6484 - val_accuracy: 0.6057\n",
      "Epoch 30/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6199 - accuracy: 0.6607 - val_loss: 0.6477 - val_accuracy: 0.6039\n",
      "Epoch 31/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6187 - accuracy: 0.6723 - val_loss: 0.6451 - val_accuracy: 0.6075\n",
      "Epoch 32/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6145 - accuracy: 0.6737 - val_loss: 0.6431 - val_accuracy: 0.6219\n",
      "Epoch 33/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6126 - accuracy: 0.6759 - val_loss: 0.6415 - val_accuracy: 0.6165\n",
      "Epoch 34/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6102 - accuracy: 0.6719 - val_loss: 0.6402 - val_accuracy: 0.6219\n",
      "Epoch 35/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6086 - accuracy: 0.6777 - val_loss: 0.6422 - val_accuracy: 0.6111\n",
      "Epoch 36/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6084 - accuracy: 0.6800 - val_loss: 0.6379 - val_accuracy: 0.6165\n",
      "Epoch 37/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6041 - accuracy: 0.6840 - val_loss: 0.6375 - val_accuracy: 0.6290\n",
      "Epoch 38/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6032 - accuracy: 0.6849 - val_loss: 0.6329 - val_accuracy: 0.6201\n",
      "Epoch 39/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.6010 - accuracy: 0.6800 - val_loss: 0.6331 - val_accuracy: 0.6326\n",
      "Epoch 40/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5989 - accuracy: 0.6827 - val_loss: 0.6363 - val_accuracy: 0.6308\n",
      "Epoch 41/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5967 - accuracy: 0.6836 - val_loss: 0.6288 - val_accuracy: 0.6416\n",
      "Epoch 42/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5962 - accuracy: 0.6853 - val_loss: 0.6348 - val_accuracy: 0.6344\n",
      "Epoch 43/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5949 - accuracy: 0.6871 - val_loss: 0.6256 - val_accuracy: 0.6434\n",
      "Epoch 44/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5942 - accuracy: 0.6903 - val_loss: 0.6284 - val_accuracy: 0.6362\n",
      "Epoch 45/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5906 - accuracy: 0.6907 - val_loss: 0.6255 - val_accuracy: 0.6452\n",
      "Epoch 46/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5905 - accuracy: 0.6930 - val_loss: 0.6239 - val_accuracy: 0.6470\n",
      "Epoch 47/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5885 - accuracy: 0.6907 - val_loss: 0.6236 - val_accuracy: 0.6398\n",
      "Epoch 48/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5875 - accuracy: 0.6943 - val_loss: 0.6231 - val_accuracy: 0.6434\n",
      "Epoch 49/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5867 - accuracy: 0.6965 - val_loss: 0.6205 - val_accuracy: 0.6470\n",
      "Epoch 50/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5858 - accuracy: 0.6965 - val_loss: 0.6218 - val_accuracy: 0.6577\n",
      "Epoch 51/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5849 - accuracy: 0.6948 - val_loss: 0.6198 - val_accuracy: 0.6470\n",
      "Epoch 52/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5846 - accuracy: 0.6943 - val_loss: 0.6192 - val_accuracy: 0.6523\n",
      "Epoch 53/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5829 - accuracy: 0.6939 - val_loss: 0.6196 - val_accuracy: 0.6452\n",
      "Epoch 54/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5812 - accuracy: 0.6934 - val_loss: 0.6165 - val_accuracy: 0.6523\n",
      "Epoch 55/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5794 - accuracy: 0.7015 - val_loss: 0.6193 - val_accuracy: 0.6523\n",
      "Epoch 56/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5791 - accuracy: 0.7019 - val_loss: 0.6183 - val_accuracy: 0.6613\n",
      "Epoch 57/1000\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.5780 - accuracy: 0.7060 - val_loss: 0.6166 - val_accuracy: 0.6416\n",
      "Epoch 58/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5775 - accuracy: 0.6970 - val_loss: 0.6162 - val_accuracy: 0.6505\n",
      "Epoch 59/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5759 - accuracy: 0.6992 - val_loss: 0.6185 - val_accuracy: 0.6452\n",
      "Epoch 60/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5762 - accuracy: 0.7046 - val_loss: 0.6141 - val_accuracy: 0.6523\n",
      "Epoch 61/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5747 - accuracy: 0.6979 - val_loss: 0.6124 - val_accuracy: 0.6541\n",
      "Epoch 62/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5754 - accuracy: 0.7037 - val_loss: 0.6130 - val_accuracy: 0.6649\n",
      "Epoch 63/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5745 - accuracy: 0.7046 - val_loss: 0.6139 - val_accuracy: 0.6505\n",
      "Epoch 64/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5723 - accuracy: 0.7073 - val_loss: 0.6160 - val_accuracy: 0.6577\n",
      "Epoch 65/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5718 - accuracy: 0.7015 - val_loss: 0.6139 - val_accuracy: 0.6649\n",
      "Epoch 66/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5717 - accuracy: 0.7042 - val_loss: 0.6164 - val_accuracy: 0.6541\n",
      "Epoch 67/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5716 - accuracy: 0.7069 - val_loss: 0.6117 - val_accuracy: 0.6703\n",
      "Epoch 68/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5722 - accuracy: 0.7091 - val_loss: 0.6148 - val_accuracy: 0.6505\n",
      "Epoch 69/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5710 - accuracy: 0.7055 - val_loss: 0.6120 - val_accuracy: 0.6720\n",
      "Epoch 70/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5689 - accuracy: 0.7060 - val_loss: 0.6133 - val_accuracy: 0.6595\n",
      "Epoch 71/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5685 - accuracy: 0.7095 - val_loss: 0.6153 - val_accuracy: 0.6595\n",
      "Epoch 72/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5698 - accuracy: 0.7082 - val_loss: 0.6111 - val_accuracy: 0.6649\n",
      "Epoch 73/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5684 - accuracy: 0.7082 - val_loss: 0.6134 - val_accuracy: 0.6613\n",
      "Epoch 74/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5680 - accuracy: 0.7073 - val_loss: 0.6132 - val_accuracy: 0.6577\n",
      "Epoch 75/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5671 - accuracy: 0.7060 - val_loss: 0.6101 - val_accuracy: 0.6738\n",
      "Epoch 76/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5679 - accuracy: 0.7109 - val_loss: 0.6112 - val_accuracy: 0.6703\n",
      "Epoch 77/1000\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.5666 - accuracy: 0.7131 - val_loss: 0.6110 - val_accuracy: 0.6685\n",
      "Epoch 78/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5658 - accuracy: 0.7113 - val_loss: 0.6106 - val_accuracy: 0.6577\n",
      "Epoch 79/1000\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.5648 - accuracy: 0.7113 - val_loss: 0.6102 - val_accuracy: 0.6595\n",
      "Epoch 80/1000\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.5659 - accuracy: 0.7131 - val_loss: 0.6163 - val_accuracy: 0.6505\n",
      "Epoch 81/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5640 - accuracy: 0.7113 - val_loss: 0.6116 - val_accuracy: 0.6595\n",
      "Epoch 82/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5640 - accuracy: 0.7118 - val_loss: 0.6107 - val_accuracy: 0.6613\n",
      "Epoch 83/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5640 - accuracy: 0.7091 - val_loss: 0.6118 - val_accuracy: 0.6613\n",
      "Epoch 84/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5636 - accuracy: 0.7046 - val_loss: 0.6092 - val_accuracy: 0.6649\n",
      "Epoch 85/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5617 - accuracy: 0.7100 - val_loss: 0.6108 - val_accuracy: 0.6595\n",
      "Epoch 86/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5635 - accuracy: 0.7104 - val_loss: 0.6088 - val_accuracy: 0.6613\n",
      "Epoch 87/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5632 - accuracy: 0.7087 - val_loss: 0.6107 - val_accuracy: 0.6595\n",
      "Epoch 88/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5616 - accuracy: 0.7185 - val_loss: 0.6097 - val_accuracy: 0.6667\n",
      "Epoch 89/1000\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.5643 - accuracy: 0.7046 - val_loss: 0.6083 - val_accuracy: 0.6703\n",
      "Epoch 90/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5622 - accuracy: 0.7082 - val_loss: 0.6102 - val_accuracy: 0.6720\n",
      "Epoch 91/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5616 - accuracy: 0.7100 - val_loss: 0.6089 - val_accuracy: 0.6667\n",
      "Epoch 92/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5627 - accuracy: 0.7100 - val_loss: 0.6118 - val_accuracy: 0.6595\n",
      "Epoch 93/1000\n",
      "75/75 [==============================] - 0s 5ms/step - loss: 0.5615 - accuracy: 0.7131 - val_loss: 0.6118 - val_accuracy: 0.6595\n",
      "Epoch 94/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5596 - accuracy: 0.7163 - val_loss: 0.6378 - val_accuracy: 0.6452\n",
      "Epoch 95/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5630 - accuracy: 0.7069 - val_loss: 0.6098 - val_accuracy: 0.6667\n",
      "Epoch 96/1000\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.5605 - accuracy: 0.7167 - val_loss: 0.6110 - val_accuracy: 0.6577\n",
      "Epoch 97/1000\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.5596 - accuracy: 0.7158 - val_loss: 0.6091 - val_accuracy: 0.6649\n",
      "Epoch 98/1000\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.5600 - accuracy: 0.7185 - val_loss: 0.6098 - val_accuracy: 0.6667\n",
      "Epoch 99/1000\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.5612 - accuracy: 0.7082 - val_loss: 0.6110 - val_accuracy: 0.6703\n",
      "Epoch 100/1000\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.5587 - accuracy: 0.7154 - val_loss: 0.6078 - val_accuracy: 0.6703\n",
      "Epoch 101/1000\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.5584 - accuracy: 0.7113 - val_loss: 0.6112 - val_accuracy: 0.6720\n",
      "Epoch 102/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5593 - accuracy: 0.7176 - val_loss: 0.6137 - val_accuracy: 0.6631\n",
      "Epoch 103/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5586 - accuracy: 0.7203 - val_loss: 0.6080 - val_accuracy: 0.6685\n",
      "Epoch 104/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5572 - accuracy: 0.7185 - val_loss: 0.6085 - val_accuracy: 0.6667\n",
      "Epoch 105/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5578 - accuracy: 0.7176 - val_loss: 0.6153 - val_accuracy: 0.6577\n",
      "Epoch 106/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5603 - accuracy: 0.7109 - val_loss: 0.6096 - val_accuracy: 0.6756\n",
      "Epoch 107/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5570 - accuracy: 0.7118 - val_loss: 0.6100 - val_accuracy: 0.6541\n",
      "Epoch 108/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5570 - accuracy: 0.7154 - val_loss: 0.6093 - val_accuracy: 0.6667\n",
      "Epoch 109/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5597 - accuracy: 0.7082 - val_loss: 0.6058 - val_accuracy: 0.6756\n",
      "Epoch 110/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5564 - accuracy: 0.7154 - val_loss: 0.6092 - val_accuracy: 0.6649\n",
      "Epoch 111/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5570 - accuracy: 0.7131 - val_loss: 0.6134 - val_accuracy: 0.6595\n",
      "Epoch 112/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5558 - accuracy: 0.7172 - val_loss: 0.6076 - val_accuracy: 0.6720\n",
      "Epoch 113/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5562 - accuracy: 0.7167 - val_loss: 0.6101 - val_accuracy: 0.6720\n",
      "Epoch 114/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5557 - accuracy: 0.7199 - val_loss: 0.6129 - val_accuracy: 0.6703\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5559 - accuracy: 0.7167 - val_loss: 0.6069 - val_accuracy: 0.6720\n",
      "Epoch 116/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5548 - accuracy: 0.7154 - val_loss: 0.6099 - val_accuracy: 0.6774\n",
      "Epoch 117/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5548 - accuracy: 0.7158 - val_loss: 0.6160 - val_accuracy: 0.6649\n",
      "Epoch 118/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5559 - accuracy: 0.7194 - val_loss: 0.6087 - val_accuracy: 0.6631\n",
      "Epoch 119/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5551 - accuracy: 0.7167 - val_loss: 0.6077 - val_accuracy: 0.6685\n",
      "Epoch 120/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5560 - accuracy: 0.7163 - val_loss: 0.6080 - val_accuracy: 0.6774\n",
      "Epoch 121/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5559 - accuracy: 0.7176 - val_loss: 0.6080 - val_accuracy: 0.6756\n",
      "Epoch 122/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5556 - accuracy: 0.7167 - val_loss: 0.6090 - val_accuracy: 0.6738\n",
      "Epoch 123/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5554 - accuracy: 0.7140 - val_loss: 0.6074 - val_accuracy: 0.6631\n",
      "Epoch 124/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5543 - accuracy: 0.7158 - val_loss: 0.6088 - val_accuracy: 0.6738\n",
      "Epoch 125/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.7239 - val_loss: 0.6087 - val_accuracy: 0.6685\n",
      "Epoch 126/1000\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.5568 - accuracy: 0.7163 - val_loss: 0.6099 - val_accuracy: 0.6685\n",
      "Epoch 127/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5535 - accuracy: 0.7167 - val_loss: 0.6111 - val_accuracy: 0.6720\n",
      "Epoch 128/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5540 - accuracy: 0.7185 - val_loss: 0.6077 - val_accuracy: 0.6738\n",
      "Epoch 129/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5534 - accuracy: 0.7208 - val_loss: 0.6112 - val_accuracy: 0.6703\n",
      "Epoch 130/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5528 - accuracy: 0.7212 - val_loss: 0.6071 - val_accuracy: 0.6774\n",
      "Epoch 131/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5530 - accuracy: 0.7154 - val_loss: 0.6072 - val_accuracy: 0.6756\n",
      "Epoch 132/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5536 - accuracy: 0.7167 - val_loss: 0.6102 - val_accuracy: 0.6685\n",
      "Epoch 133/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5541 - accuracy: 0.7181 - val_loss: 0.6058 - val_accuracy: 0.6738\n",
      "Epoch 134/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5536 - accuracy: 0.7190 - val_loss: 0.6067 - val_accuracy: 0.6846\n",
      "Epoch 135/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5535 - accuracy: 0.7185 - val_loss: 0.6067 - val_accuracy: 0.6810\n",
      "Epoch 136/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5540 - accuracy: 0.7181 - val_loss: 0.6078 - val_accuracy: 0.6774\n",
      "Epoch 137/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5509 - accuracy: 0.7212 - val_loss: 0.6054 - val_accuracy: 0.6792\n",
      "Epoch 138/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5525 - accuracy: 0.7149 - val_loss: 0.6087 - val_accuracy: 0.6720\n",
      "Epoch 139/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5514 - accuracy: 0.7261 - val_loss: 0.6094 - val_accuracy: 0.6703\n",
      "Epoch 140/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5514 - accuracy: 0.7225 - val_loss: 0.6060 - val_accuracy: 0.6846\n",
      "Epoch 141/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5510 - accuracy: 0.7248 - val_loss: 0.6083 - val_accuracy: 0.6703\n",
      "Epoch 142/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.7239 - val_loss: 0.6081 - val_accuracy: 0.6738\n",
      "Epoch 143/1000\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.5509 - accuracy: 0.7140 - val_loss: 0.6067 - val_accuracy: 0.6685\n",
      "Epoch 144/1000\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.5513 - accuracy: 0.7239 - val_loss: 0.6082 - val_accuracy: 0.6756\n",
      "Epoch 145/1000\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.5504 - accuracy: 0.7190 - val_loss: 0.6115 - val_accuracy: 0.6703\n",
      "Epoch 146/1000\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.5503 - accuracy: 0.7212 - val_loss: 0.6128 - val_accuracy: 0.6667\n",
      "Epoch 147/1000\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.5496 - accuracy: 0.7239 - val_loss: 0.6083 - val_accuracy: 0.6828\n",
      "Epoch 148/1000\n",
      "75/75 [==============================] - 0s 4ms/step - loss: 0.5499 - accuracy: 0.7266 - val_loss: 0.6098 - val_accuracy: 0.6703\n",
      "Epoch 149/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5501 - accuracy: 0.7252 - val_loss: 0.6075 - val_accuracy: 0.6577\n",
      "Epoch 150/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5507 - accuracy: 0.7252 - val_loss: 0.6045 - val_accuracy: 0.6828\n",
      "Epoch 151/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5500 - accuracy: 0.7234 - val_loss: 0.6089 - val_accuracy: 0.6685\n",
      "Epoch 152/1000\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.5510 - accuracy: 0.7221 - val_loss: 0.6047 - val_accuracy: 0.6738\n",
      "Epoch 153/1000\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.5504 - accuracy: 0.7185 - val_loss: 0.6120 - val_accuracy: 0.6667\n",
      "Epoch 154/1000\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.5500 - accuracy: 0.7190 - val_loss: 0.6063 - val_accuracy: 0.6792\n",
      "Epoch 155/1000\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.5491 - accuracy: 0.7239 - val_loss: 0.6108 - val_accuracy: 0.6631\n",
      "Epoch 156/1000\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.5485 - accuracy: 0.7288 - val_loss: 0.6075 - val_accuracy: 0.6756\n",
      "Epoch 157/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5502 - accuracy: 0.7230 - val_loss: 0.6168 - val_accuracy: 0.6685\n",
      "Epoch 158/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5484 - accuracy: 0.7149 - val_loss: 0.6110 - val_accuracy: 0.6703\n",
      "Epoch 159/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5475 - accuracy: 0.7234 - val_loss: 0.6107 - val_accuracy: 0.6703\n",
      "Epoch 160/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5489 - accuracy: 0.7248 - val_loss: 0.6085 - val_accuracy: 0.6810\n",
      "Epoch 161/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5487 - accuracy: 0.7190 - val_loss: 0.6074 - val_accuracy: 0.6756\n",
      "Epoch 162/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5484 - accuracy: 0.7275 - val_loss: 0.6106 - val_accuracy: 0.6774\n",
      "Epoch 163/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5481 - accuracy: 0.7181 - val_loss: 0.6062 - val_accuracy: 0.6738\n",
      "Epoch 164/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5468 - accuracy: 0.7243 - val_loss: 0.6082 - val_accuracy: 0.6738\n",
      "Epoch 165/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5481 - accuracy: 0.7176 - val_loss: 0.6042 - val_accuracy: 0.6738\n",
      "Epoch 166/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5485 - accuracy: 0.7230 - val_loss: 0.6067 - val_accuracy: 0.6810\n",
      "Epoch 167/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5476 - accuracy: 0.7212 - val_loss: 0.6063 - val_accuracy: 0.6685\n",
      "Epoch 168/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5501 - accuracy: 0.7239 - val_loss: 0.6077 - val_accuracy: 0.6703\n",
      "Epoch 169/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5469 - accuracy: 0.7261 - val_loss: 0.6071 - val_accuracy: 0.6774\n",
      "Epoch 170/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5463 - accuracy: 0.7248 - val_loss: 0.6097 - val_accuracy: 0.6720\n",
      "Epoch 171/1000\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.5477 - accuracy: 0.7266 - val_loss: 0.6053 - val_accuracy: 0.6792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.5474 - accuracy: 0.7270 - val_loss: 0.6051 - val_accuracy: 0.6720\n",
      "Epoch 173/1000\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.5469 - accuracy: 0.7212 - val_loss: 0.6055 - val_accuracy: 0.6792\n",
      "Epoch 174/1000\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.5457 - accuracy: 0.7284 - val_loss: 0.6078 - val_accuracy: 0.6738\n",
      "Epoch 175/1000\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.5478 - accuracy: 0.7243 - val_loss: 0.6063 - val_accuracy: 0.6738\n",
      "Epoch 176/1000\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.5451 - accuracy: 0.7293 - val_loss: 0.6080 - val_accuracy: 0.6810\n",
      "Epoch 177/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5444 - accuracy: 0.7230 - val_loss: 0.6039 - val_accuracy: 0.6774\n",
      "Epoch 178/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.7270 - val_loss: 0.6085 - val_accuracy: 0.6667\n",
      "Epoch 179/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.7252 - val_loss: 0.6040 - val_accuracy: 0.6774\n",
      "Epoch 180/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 0.7252 - val_loss: 0.6116 - val_accuracy: 0.6703\n",
      "Epoch 181/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.7261 - val_loss: 0.6056 - val_accuracy: 0.6738\n",
      "Epoch 182/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5460 - accuracy: 0.7288 - val_loss: 0.6078 - val_accuracy: 0.6685\n",
      "Epoch 183/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5450 - accuracy: 0.7275 - val_loss: 0.6085 - val_accuracy: 0.6685\n",
      "Epoch 184/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5454 - accuracy: 0.7257 - val_loss: 0.6024 - val_accuracy: 0.6685\n",
      "Epoch 185/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5449 - accuracy: 0.7279 - val_loss: 0.6070 - val_accuracy: 0.6756\n",
      "Epoch 186/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7270 - val_loss: 0.6035 - val_accuracy: 0.6792\n",
      "Epoch 187/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5442 - accuracy: 0.7306 - val_loss: 0.6034 - val_accuracy: 0.6810\n",
      "Epoch 188/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5448 - accuracy: 0.7288 - val_loss: 0.6028 - val_accuracy: 0.6792\n",
      "Epoch 189/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5468 - accuracy: 0.7239 - val_loss: 0.6059 - val_accuracy: 0.6720\n",
      "Epoch 190/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7266 - val_loss: 0.6020 - val_accuracy: 0.6846\n",
      "Epoch 191/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7239 - val_loss: 0.6059 - val_accuracy: 0.6738\n",
      "Epoch 192/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 0.7297 - val_loss: 0.6035 - val_accuracy: 0.6810\n",
      "Epoch 193/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.7266 - val_loss: 0.6041 - val_accuracy: 0.6738\n",
      "Epoch 194/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.7194 - val_loss: 0.6056 - val_accuracy: 0.6774\n",
      "Epoch 195/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5440 - accuracy: 0.7311 - val_loss: 0.6053 - val_accuracy: 0.6792\n",
      "Epoch 196/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5427 - accuracy: 0.7275 - val_loss: 0.6033 - val_accuracy: 0.6774\n",
      "Epoch 197/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5449 - accuracy: 0.7288 - val_loss: 0.6103 - val_accuracy: 0.6685\n",
      "Epoch 198/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5419 - accuracy: 0.7239 - val_loss: 0.6020 - val_accuracy: 0.6792\n",
      "Epoch 199/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5420 - accuracy: 0.7306 - val_loss: 0.6093 - val_accuracy: 0.6667\n",
      "Epoch 200/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5414 - accuracy: 0.7279 - val_loss: 0.6053 - val_accuracy: 0.6720\n",
      "Epoch 201/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5418 - accuracy: 0.7234 - val_loss: 0.6030 - val_accuracy: 0.6846\n",
      "Epoch 202/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5404 - accuracy: 0.7320 - val_loss: 0.6026 - val_accuracy: 0.6756\n",
      "Epoch 203/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5434 - accuracy: 0.7248 - val_loss: 0.6049 - val_accuracy: 0.6828\n",
      "Epoch 204/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5413 - accuracy: 0.7284 - val_loss: 0.6036 - val_accuracy: 0.6774\n",
      "Epoch 205/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5410 - accuracy: 0.7320 - val_loss: 0.6052 - val_accuracy: 0.6828\n",
      "Epoch 206/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5428 - accuracy: 0.7234 - val_loss: 0.6062 - val_accuracy: 0.6846\n",
      "Epoch 207/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5411 - accuracy: 0.7257 - val_loss: 0.6054 - val_accuracy: 0.6685\n",
      "Epoch 208/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5407 - accuracy: 0.7279 - val_loss: 0.6057 - val_accuracy: 0.6756\n",
      "Epoch 209/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5420 - accuracy: 0.7302 - val_loss: 0.6049 - val_accuracy: 0.6774\n",
      "Epoch 210/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5419 - accuracy: 0.7302 - val_loss: 0.6041 - val_accuracy: 0.6882\n",
      "Epoch 211/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5408 - accuracy: 0.7288 - val_loss: 0.6093 - val_accuracy: 0.6649\n",
      "Epoch 212/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5411 - accuracy: 0.7302 - val_loss: 0.6008 - val_accuracy: 0.6828\n",
      "Epoch 213/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5411 - accuracy: 0.7216 - val_loss: 0.6024 - val_accuracy: 0.6756\n",
      "Epoch 214/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5411 - accuracy: 0.7252 - val_loss: 0.6043 - val_accuracy: 0.6774\n",
      "Epoch 215/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5400 - accuracy: 0.7324 - val_loss: 0.6060 - val_accuracy: 0.6774\n",
      "Epoch 216/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5418 - accuracy: 0.7297 - val_loss: 0.6088 - val_accuracy: 0.6774\n",
      "Epoch 217/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5399 - accuracy: 0.7306 - val_loss: 0.6178 - val_accuracy: 0.6559\n",
      "Epoch 218/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5408 - accuracy: 0.7288 - val_loss: 0.6007 - val_accuracy: 0.6828\n",
      "Epoch 219/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.7297 - val_loss: 0.6013 - val_accuracy: 0.6810\n",
      "Epoch 220/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.7302 - val_loss: 0.6007 - val_accuracy: 0.6738\n",
      "Epoch 221/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5389 - accuracy: 0.7315 - val_loss: 0.6055 - val_accuracy: 0.6720\n",
      "Epoch 222/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5411 - accuracy: 0.7320 - val_loss: 0.6012 - val_accuracy: 0.6792\n",
      "Epoch 223/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5397 - accuracy: 0.7270 - val_loss: 0.6081 - val_accuracy: 0.6756\n",
      "Epoch 224/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5382 - accuracy: 0.7324 - val_loss: 0.6062 - val_accuracy: 0.6703\n",
      "Epoch 225/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5387 - accuracy: 0.7320 - val_loss: 0.5999 - val_accuracy: 0.6792\n",
      "Epoch 226/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5406 - accuracy: 0.7346 - val_loss: 0.6032 - val_accuracy: 0.6828\n",
      "Epoch 227/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5386 - accuracy: 0.7302 - val_loss: 0.6078 - val_accuracy: 0.6613\n",
      "Epoch 228/1000\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.5409 - accuracy: 0.7221 - val_loss: 0.6036 - val_accuracy: 0.6810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5404 - accuracy: 0.7297 - val_loss: 0.6052 - val_accuracy: 0.6756\n",
      "Epoch 230/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5377 - accuracy: 0.7360 - val_loss: 0.6011 - val_accuracy: 0.6792\n",
      "Epoch 231/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5376 - accuracy: 0.7315 - val_loss: 0.6007 - val_accuracy: 0.6828\n",
      "Epoch 232/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5387 - accuracy: 0.7320 - val_loss: 0.6003 - val_accuracy: 0.6810\n",
      "Epoch 233/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5378 - accuracy: 0.7297 - val_loss: 0.6139 - val_accuracy: 0.6703\n",
      "Epoch 234/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5387 - accuracy: 0.7346 - val_loss: 0.6051 - val_accuracy: 0.6846\n",
      "Epoch 235/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5372 - accuracy: 0.7306 - val_loss: 0.6026 - val_accuracy: 0.6828\n",
      "Epoch 236/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.7355 - val_loss: 0.6031 - val_accuracy: 0.6828\n",
      "Epoch 237/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5367 - accuracy: 0.7378 - val_loss: 0.6070 - val_accuracy: 0.6738\n",
      "Epoch 238/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5375 - accuracy: 0.7311 - val_loss: 0.6009 - val_accuracy: 0.6810\n",
      "Epoch 239/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5380 - accuracy: 0.7302 - val_loss: 0.6007 - val_accuracy: 0.6846\n",
      "Epoch 240/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5366 - accuracy: 0.7320 - val_loss: 0.5988 - val_accuracy: 0.6792\n",
      "Epoch 241/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5361 - accuracy: 0.7364 - val_loss: 0.6143 - val_accuracy: 0.6649\n",
      "Epoch 242/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5393 - accuracy: 0.7284 - val_loss: 0.6014 - val_accuracy: 0.6738\n",
      "Epoch 243/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5374 - accuracy: 0.7257 - val_loss: 0.6043 - val_accuracy: 0.6774\n",
      "Epoch 244/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5362 - accuracy: 0.7293 - val_loss: 0.6006 - val_accuracy: 0.6918\n",
      "Epoch 245/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5378 - accuracy: 0.7324 - val_loss: 0.6024 - val_accuracy: 0.6846\n",
      "Epoch 246/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5367 - accuracy: 0.7338 - val_loss: 0.6024 - val_accuracy: 0.6828\n",
      "Epoch 247/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5369 - accuracy: 0.7351 - val_loss: 0.6024 - val_accuracy: 0.6738\n",
      "Epoch 248/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5361 - accuracy: 0.7306 - val_loss: 0.6027 - val_accuracy: 0.6828\n",
      "Epoch 249/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5345 - accuracy: 0.7302 - val_loss: 0.6063 - val_accuracy: 0.6685\n",
      "Epoch 250/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5363 - accuracy: 0.7360 - val_loss: 0.6017 - val_accuracy: 0.6738\n",
      "Epoch 251/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5356 - accuracy: 0.7387 - val_loss: 0.6062 - val_accuracy: 0.6685\n",
      "Epoch 252/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5349 - accuracy: 0.7369 - val_loss: 0.6006 - val_accuracy: 0.6810\n",
      "Epoch 253/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5344 - accuracy: 0.7360 - val_loss: 0.6019 - val_accuracy: 0.6882\n",
      "Epoch 254/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5375 - accuracy: 0.7311 - val_loss: 0.6017 - val_accuracy: 0.6864\n",
      "Epoch 255/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5348 - accuracy: 0.7369 - val_loss: 0.6016 - val_accuracy: 0.6756\n",
      "Epoch 256/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5354 - accuracy: 0.7369 - val_loss: 0.6019 - val_accuracy: 0.6810\n",
      "Epoch 257/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.7342 - val_loss: 0.6009 - val_accuracy: 0.6828\n",
      "Epoch 258/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5346 - accuracy: 0.7342 - val_loss: 0.6065 - val_accuracy: 0.6703\n",
      "Epoch 259/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5345 - accuracy: 0.7320 - val_loss: 0.6023 - val_accuracy: 0.6738\n",
      "Epoch 260/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.7315 - val_loss: 0.6032 - val_accuracy: 0.6792\n",
      "Epoch 261/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5349 - accuracy: 0.7329 - val_loss: 0.6020 - val_accuracy: 0.6774\n",
      "Epoch 262/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5351 - accuracy: 0.7342 - val_loss: 0.5977 - val_accuracy: 0.6846\n",
      "Epoch 263/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5347 - accuracy: 0.7315 - val_loss: 0.6020 - val_accuracy: 0.6792\n",
      "Epoch 264/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5345 - accuracy: 0.7333 - val_loss: 0.5995 - val_accuracy: 0.6882\n",
      "Epoch 265/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5342 - accuracy: 0.7338 - val_loss: 0.6022 - val_accuracy: 0.6756\n",
      "Epoch 266/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5351 - accuracy: 0.7338 - val_loss: 0.6026 - val_accuracy: 0.6774\n",
      "Epoch 267/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5342 - accuracy: 0.7351 - val_loss: 0.6070 - val_accuracy: 0.6613\n",
      "Epoch 268/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5357 - accuracy: 0.7355 - val_loss: 0.6022 - val_accuracy: 0.6810\n",
      "Epoch 269/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5343 - accuracy: 0.7333 - val_loss: 0.5991 - val_accuracy: 0.6792\n",
      "Epoch 270/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5334 - accuracy: 0.7329 - val_loss: 0.5998 - val_accuracy: 0.6864\n",
      "Epoch 271/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5335 - accuracy: 0.7409 - val_loss: 0.5994 - val_accuracy: 0.6774\n",
      "Epoch 272/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5357 - accuracy: 0.7329 - val_loss: 0.5986 - val_accuracy: 0.6846\n",
      "Epoch 273/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5327 - accuracy: 0.7355 - val_loss: 0.5984 - val_accuracy: 0.6846\n",
      "Epoch 274/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5337 - accuracy: 0.7351 - val_loss: 0.5960 - val_accuracy: 0.6918\n",
      "Epoch 275/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5331 - accuracy: 0.7279 - val_loss: 0.6068 - val_accuracy: 0.6667\n",
      "Epoch 276/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.7346 - val_loss: 0.6012 - val_accuracy: 0.6756\n",
      "Epoch 277/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5332 - accuracy: 0.7342 - val_loss: 0.6024 - val_accuracy: 0.6828\n",
      "Epoch 278/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.7311 - val_loss: 0.6001 - val_accuracy: 0.6756\n",
      "Epoch 279/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5317 - accuracy: 0.7378 - val_loss: 0.6002 - val_accuracy: 0.6756\n",
      "Epoch 280/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5322 - accuracy: 0.7418 - val_loss: 0.5973 - val_accuracy: 0.6882\n",
      "Epoch 281/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.7311 - val_loss: 0.5997 - val_accuracy: 0.6882\n",
      "Epoch 282/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5331 - accuracy: 0.7320 - val_loss: 0.5978 - val_accuracy: 0.6846\n",
      "Epoch 283/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.7369 - val_loss: 0.5972 - val_accuracy: 0.6828\n",
      "Epoch 284/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5331 - accuracy: 0.7360 - val_loss: 0.5981 - val_accuracy: 0.6846\n",
      "Epoch 285/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5318 - accuracy: 0.7333 - val_loss: 0.6058 - val_accuracy: 0.6828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.7320 - val_loss: 0.5990 - val_accuracy: 0.6756\n",
      "Epoch 287/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5320 - accuracy: 0.7333 - val_loss: 0.5993 - val_accuracy: 0.6774\n",
      "Epoch 288/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5331 - accuracy: 0.7346 - val_loss: 0.5984 - val_accuracy: 0.6828\n",
      "Epoch 289/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5322 - accuracy: 0.7342 - val_loss: 0.6035 - val_accuracy: 0.6882\n",
      "Epoch 290/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5325 - accuracy: 0.7324 - val_loss: 0.6111 - val_accuracy: 0.6685\n",
      "Epoch 291/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5307 - accuracy: 0.7396 - val_loss: 0.5999 - val_accuracy: 0.6810\n",
      "Epoch 292/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5312 - accuracy: 0.7396 - val_loss: 0.5982 - val_accuracy: 0.6756\n",
      "Epoch 293/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.7329 - val_loss: 0.6041 - val_accuracy: 0.6738\n",
      "Epoch 294/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7329 - val_loss: 0.6043 - val_accuracy: 0.6774\n",
      "Epoch 295/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5312 - accuracy: 0.7302 - val_loss: 0.6047 - val_accuracy: 0.6720\n",
      "Epoch 296/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.7351 - val_loss: 0.6005 - val_accuracy: 0.6810\n",
      "Epoch 297/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5303 - accuracy: 0.7355 - val_loss: 0.6021 - val_accuracy: 0.6810\n",
      "Epoch 298/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5312 - accuracy: 0.7346 - val_loss: 0.5988 - val_accuracy: 0.6810\n",
      "Epoch 299/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5312 - accuracy: 0.7342 - val_loss: 0.6006 - val_accuracy: 0.6738\n",
      "Epoch 300/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.7364 - val_loss: 0.6030 - val_accuracy: 0.6792\n",
      "Epoch 301/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5303 - accuracy: 0.7270 - val_loss: 0.6010 - val_accuracy: 0.6828\n",
      "Epoch 302/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5304 - accuracy: 0.7396 - val_loss: 0.5989 - val_accuracy: 0.6828\n",
      "Epoch 303/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5347 - accuracy: 0.7338 - val_loss: 0.6045 - val_accuracy: 0.6738\n",
      "Epoch 304/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5326 - accuracy: 0.7378 - val_loss: 0.6029 - val_accuracy: 0.6756\n",
      "Epoch 305/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5318 - accuracy: 0.7311 - val_loss: 0.5993 - val_accuracy: 0.6882\n",
      "Epoch 306/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.7351 - val_loss: 0.6036 - val_accuracy: 0.6792\n",
      "Epoch 307/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5297 - accuracy: 0.7382 - val_loss: 0.6038 - val_accuracy: 0.6792\n",
      "Epoch 308/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5301 - accuracy: 0.7364 - val_loss: 0.6027 - val_accuracy: 0.6738\n",
      "Epoch 309/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5301 - accuracy: 0.7364 - val_loss: 0.5979 - val_accuracy: 0.6918\n",
      "Epoch 310/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.7409 - val_loss: 0.5998 - val_accuracy: 0.6810\n",
      "Epoch 311/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.7387 - val_loss: 0.5955 - val_accuracy: 0.6882\n",
      "Epoch 312/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5294 - accuracy: 0.7382 - val_loss: 0.5988 - val_accuracy: 0.6810\n",
      "Epoch 313/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5283 - accuracy: 0.7364 - val_loss: 0.6004 - val_accuracy: 0.6774\n",
      "Epoch 314/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.7414 - val_loss: 0.5988 - val_accuracy: 0.6810\n",
      "Epoch 315/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.7360 - val_loss: 0.6030 - val_accuracy: 0.6810\n",
      "Epoch 316/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.7324 - val_loss: 0.6132 - val_accuracy: 0.6810\n",
      "Epoch 317/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.7364 - val_loss: 0.6023 - val_accuracy: 0.6720\n",
      "Epoch 318/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5301 - accuracy: 0.7329 - val_loss: 0.5975 - val_accuracy: 0.6792\n",
      "Epoch 319/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5300 - accuracy: 0.7333 - val_loss: 0.6004 - val_accuracy: 0.6756\n",
      "Epoch 320/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.7351 - val_loss: 0.5990 - val_accuracy: 0.6810\n",
      "Epoch 321/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5298 - accuracy: 0.7351 - val_loss: 0.6008 - val_accuracy: 0.6792\n",
      "Epoch 322/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.7391 - val_loss: 0.5970 - val_accuracy: 0.6810\n",
      "Epoch 323/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5279 - accuracy: 0.7378 - val_loss: 0.6048 - val_accuracy: 0.6720\n",
      "Epoch 324/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5288 - accuracy: 0.7351 - val_loss: 0.5972 - val_accuracy: 0.6810\n",
      "Epoch 325/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5290 - accuracy: 0.7391 - val_loss: 0.6022 - val_accuracy: 0.6756\n",
      "Epoch 326/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5300 - accuracy: 0.7338 - val_loss: 0.5981 - val_accuracy: 0.6828\n",
      "Epoch 327/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5300 - accuracy: 0.7360 - val_loss: 0.6024 - val_accuracy: 0.6756\n",
      "Epoch 328/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5278 - accuracy: 0.7355 - val_loss: 0.6070 - val_accuracy: 0.6685\n",
      "Epoch 329/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.7400 - val_loss: 0.5995 - val_accuracy: 0.6774\n",
      "Epoch 330/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5286 - accuracy: 0.7414 - val_loss: 0.6033 - val_accuracy: 0.6756\n",
      "Epoch 331/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5307 - accuracy: 0.7320 - val_loss: 0.6066 - val_accuracy: 0.6756\n",
      "Epoch 332/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.7400 - val_loss: 0.5992 - val_accuracy: 0.6864\n",
      "Epoch 333/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.7418 - val_loss: 0.6031 - val_accuracy: 0.6720\n",
      "Epoch 334/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5283 - accuracy: 0.7346 - val_loss: 0.6001 - val_accuracy: 0.6792\n",
      "Epoch 335/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5278 - accuracy: 0.7436 - val_loss: 0.5984 - val_accuracy: 0.6810\n",
      "Epoch 336/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.7382 - val_loss: 0.6003 - val_accuracy: 0.6756\n",
      "Epoch 337/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.7346 - val_loss: 0.6052 - val_accuracy: 0.6792\n",
      "Epoch 338/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.7387 - val_loss: 0.6016 - val_accuracy: 0.6738\n",
      "Epoch 339/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5283 - accuracy: 0.7405 - val_loss: 0.6008 - val_accuracy: 0.6792\n",
      "Epoch 340/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.7378 - val_loss: 0.6008 - val_accuracy: 0.6756\n",
      "Epoch 341/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5319 - accuracy: 0.7329 - val_loss: 0.5983 - val_accuracy: 0.6756\n",
      "Epoch 342/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.7364 - val_loss: 0.6041 - val_accuracy: 0.6738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.7387 - val_loss: 0.6064 - val_accuracy: 0.6738\n",
      "Epoch 344/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5279 - accuracy: 0.7369 - val_loss: 0.6004 - val_accuracy: 0.6810\n",
      "Epoch 345/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.7351 - val_loss: 0.6037 - val_accuracy: 0.6738\n",
      "Epoch 346/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5272 - accuracy: 0.7405 - val_loss: 0.6016 - val_accuracy: 0.6774\n",
      "Epoch 347/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.7360 - val_loss: 0.5974 - val_accuracy: 0.6864\n",
      "Epoch 348/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.7382 - val_loss: 0.6069 - val_accuracy: 0.6738\n",
      "Epoch 349/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.7373 - val_loss: 0.5977 - val_accuracy: 0.6792\n",
      "Epoch 350/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.7396 - val_loss: 0.5965 - val_accuracy: 0.6774\n",
      "Epoch 351/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5273 - accuracy: 0.7405 - val_loss: 0.6020 - val_accuracy: 0.6918\n",
      "Epoch 352/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.7450 - val_loss: 0.6010 - val_accuracy: 0.6685\n",
      "Epoch 353/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.7364 - val_loss: 0.6063 - val_accuracy: 0.6792\n",
      "Epoch 354/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5311 - accuracy: 0.7338 - val_loss: 0.5999 - val_accuracy: 0.6756\n",
      "Epoch 355/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.7373 - val_loss: 0.6007 - val_accuracy: 0.6792\n",
      "Epoch 356/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.7373 - val_loss: 0.5954 - val_accuracy: 0.6918\n",
      "Epoch 357/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5279 - accuracy: 0.7373 - val_loss: 0.6036 - val_accuracy: 0.6756\n",
      "Epoch 358/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5252 - accuracy: 0.7396 - val_loss: 0.6019 - val_accuracy: 0.6756\n",
      "Epoch 359/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5263 - accuracy: 0.7333 - val_loss: 0.6011 - val_accuracy: 0.6720\n",
      "Epoch 360/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.7360 - val_loss: 0.5993 - val_accuracy: 0.6738\n",
      "Epoch 361/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5273 - accuracy: 0.7414 - val_loss: 0.5997 - val_accuracy: 0.6846\n",
      "Epoch 362/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.7391 - val_loss: 0.5993 - val_accuracy: 0.6756\n",
      "Epoch 363/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5247 - accuracy: 0.7391 - val_loss: 0.6026 - val_accuracy: 0.6720\n",
      "Epoch 364/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.7355 - val_loss: 0.6038 - val_accuracy: 0.6720\n",
      "Epoch 365/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5258 - accuracy: 0.7396 - val_loss: 0.6027 - val_accuracy: 0.6828\n",
      "Epoch 366/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5242 - accuracy: 0.7378 - val_loss: 0.5970 - val_accuracy: 0.6810\n",
      "Epoch 367/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.7378 - val_loss: 0.5967 - val_accuracy: 0.6828\n",
      "Epoch 368/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.7423 - val_loss: 0.6061 - val_accuracy: 0.6738\n",
      "Epoch 369/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5259 - accuracy: 0.7378 - val_loss: 0.5997 - val_accuracy: 0.6756\n",
      "Epoch 370/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.7338 - val_loss: 0.6041 - val_accuracy: 0.6756\n",
      "Epoch 371/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5255 - accuracy: 0.7346 - val_loss: 0.6002 - val_accuracy: 0.6720\n",
      "Epoch 372/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.7373 - val_loss: 0.6006 - val_accuracy: 0.6720\n",
      "Epoch 373/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7400 - val_loss: 0.5994 - val_accuracy: 0.6756\n",
      "Epoch 374/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7414 - val_loss: 0.6010 - val_accuracy: 0.6774\n",
      "Epoch 375/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.7378 - val_loss: 0.6029 - val_accuracy: 0.6774\n",
      "Epoch 376/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.7391 - val_loss: 0.6011 - val_accuracy: 0.6774\n",
      "Epoch 377/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5273 - accuracy: 0.7355 - val_loss: 0.6027 - val_accuracy: 0.6774\n",
      "Epoch 378/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.7382 - val_loss: 0.6080 - val_accuracy: 0.6756\n",
      "Epoch 379/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7436 - val_loss: 0.6147 - val_accuracy: 0.6756\n",
      "Epoch 380/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.7338 - val_loss: 0.5999 - val_accuracy: 0.6828\n",
      "Epoch 381/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.7355 - val_loss: 0.5999 - val_accuracy: 0.6774\n",
      "Epoch 382/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.7423 - val_loss: 0.6014 - val_accuracy: 0.6738\n",
      "Epoch 383/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5239 - accuracy: 0.7342 - val_loss: 0.5990 - val_accuracy: 0.6828\n",
      "Epoch 384/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.7409 - val_loss: 0.6084 - val_accuracy: 0.6738\n",
      "Epoch 385/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.7378 - val_loss: 0.5983 - val_accuracy: 0.6756\n",
      "Epoch 386/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5252 - accuracy: 0.7378 - val_loss: 0.5984 - val_accuracy: 0.6828\n",
      "Epoch 387/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.7427 - val_loss: 0.5981 - val_accuracy: 0.6774\n",
      "Epoch 388/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.7355 - val_loss: 0.6006 - val_accuracy: 0.6738\n",
      "Epoch 389/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5238 - accuracy: 0.7382 - val_loss: 0.6049 - val_accuracy: 0.6720\n",
      "Epoch 390/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5267 - accuracy: 0.7391 - val_loss: 0.5990 - val_accuracy: 0.6756\n",
      "Epoch 391/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7409 - val_loss: 0.6056 - val_accuracy: 0.6703\n",
      "Epoch 392/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.7369 - val_loss: 0.5962 - val_accuracy: 0.6810\n",
      "Epoch 393/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.7373 - val_loss: 0.6036 - val_accuracy: 0.6846\n",
      "Epoch 394/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5241 - accuracy: 0.7427 - val_loss: 0.6134 - val_accuracy: 0.6720\n",
      "Epoch 395/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5252 - accuracy: 0.7405 - val_loss: 0.5983 - val_accuracy: 0.6792\n",
      "Epoch 396/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.7418 - val_loss: 0.6036 - val_accuracy: 0.6792\n",
      "Epoch 397/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.7369 - val_loss: 0.6056 - val_accuracy: 0.6810\n",
      "Epoch 398/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5234 - accuracy: 0.7382 - val_loss: 0.5996 - val_accuracy: 0.6792\n",
      "Epoch 399/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5241 - accuracy: 0.7418 - val_loss: 0.5999 - val_accuracy: 0.6792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.7396 - val_loss: 0.6025 - val_accuracy: 0.6703\n",
      "Epoch 401/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.7338 - val_loss: 0.6020 - val_accuracy: 0.6756\n",
      "Epoch 402/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5232 - accuracy: 0.7378 - val_loss: 0.5979 - val_accuracy: 0.6756\n",
      "Epoch 403/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5236 - accuracy: 0.7414 - val_loss: 0.6031 - val_accuracy: 0.6774\n",
      "Epoch 404/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.7445 - val_loss: 0.6025 - val_accuracy: 0.6774\n",
      "Epoch 405/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7391 - val_loss: 0.5992 - val_accuracy: 0.6756\n",
      "Epoch 406/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.7414 - val_loss: 0.5980 - val_accuracy: 0.6756\n",
      "Epoch 407/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.7396 - val_loss: 0.6046 - val_accuracy: 0.6792\n",
      "Epoch 408/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7378 - val_loss: 0.5992 - val_accuracy: 0.6846\n",
      "Epoch 409/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7387 - val_loss: 0.6081 - val_accuracy: 0.6756\n",
      "Epoch 410/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.7418 - val_loss: 0.6006 - val_accuracy: 0.6738\n",
      "Epoch 411/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5242 - accuracy: 0.7378 - val_loss: 0.5975 - val_accuracy: 0.6828\n",
      "Epoch 412/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.7396 - val_loss: 0.6014 - val_accuracy: 0.6810\n",
      "Epoch 413/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5224 - accuracy: 0.7423 - val_loss: 0.5993 - val_accuracy: 0.6828\n",
      "Epoch 414/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.7396 - val_loss: 0.6016 - val_accuracy: 0.6774\n",
      "Epoch 415/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.7342 - val_loss: 0.6050 - val_accuracy: 0.6828\n",
      "Epoch 416/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7414 - val_loss: 0.6057 - val_accuracy: 0.6703\n",
      "Epoch 417/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5238 - accuracy: 0.7387 - val_loss: 0.6023 - val_accuracy: 0.6774\n",
      "Epoch 418/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7441 - val_loss: 0.5997 - val_accuracy: 0.6864\n",
      "Epoch 419/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.7355 - val_loss: 0.6044 - val_accuracy: 0.6738\n",
      "Epoch 420/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.7423 - val_loss: 0.6007 - val_accuracy: 0.6703\n",
      "Epoch 421/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5224 - accuracy: 0.7387 - val_loss: 0.6085 - val_accuracy: 0.6703\n",
      "Epoch 422/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5224 - accuracy: 0.7414 - val_loss: 0.6138 - val_accuracy: 0.6738\n",
      "Epoch 423/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.7378 - val_loss: 0.6040 - val_accuracy: 0.6828\n",
      "Epoch 424/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5216 - accuracy: 0.7373 - val_loss: 0.6018 - val_accuracy: 0.6846\n",
      "Epoch 425/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5238 - accuracy: 0.7418 - val_loss: 0.5991 - val_accuracy: 0.6792\n",
      "Epoch 426/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.7468 - val_loss: 0.5968 - val_accuracy: 0.6810\n",
      "Epoch 427/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7387 - val_loss: 0.6023 - val_accuracy: 0.6738\n",
      "Epoch 428/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5236 - accuracy: 0.7396 - val_loss: 0.6010 - val_accuracy: 0.6756\n",
      "Epoch 429/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5236 - accuracy: 0.7382 - val_loss: 0.6023 - val_accuracy: 0.6738\n",
      "Epoch 430/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5224 - accuracy: 0.7378 - val_loss: 0.6007 - val_accuracy: 0.6720\n",
      "Epoch 431/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.7360 - val_loss: 0.6051 - val_accuracy: 0.6828\n",
      "Epoch 432/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.7409 - val_loss: 0.6084 - val_accuracy: 0.6703\n",
      "Epoch 433/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.7382 - val_loss: 0.5996 - val_accuracy: 0.6846\n",
      "Epoch 434/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7351 - val_loss: 0.6032 - val_accuracy: 0.6846\n",
      "Epoch 435/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.7436 - val_loss: 0.6072 - val_accuracy: 0.6738\n",
      "Epoch 436/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.7418 - val_loss: 0.6131 - val_accuracy: 0.6810\n",
      "Epoch 437/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5238 - accuracy: 0.7373 - val_loss: 0.6028 - val_accuracy: 0.6774\n",
      "Epoch 438/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.7382 - val_loss: 0.6084 - val_accuracy: 0.6720\n",
      "Epoch 439/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.7400 - val_loss: 0.6021 - val_accuracy: 0.6774\n",
      "Epoch 440/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.7387 - val_loss: 0.6004 - val_accuracy: 0.6774\n",
      "Epoch 441/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.7463 - val_loss: 0.6091 - val_accuracy: 0.6756\n",
      "Epoch 442/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5204 - accuracy: 0.7445 - val_loss: 0.6027 - val_accuracy: 0.6738\n",
      "Epoch 443/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.7432 - val_loss: 0.6029 - val_accuracy: 0.6774\n",
      "Epoch 444/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5218 - accuracy: 0.7418 - val_loss: 0.6029 - val_accuracy: 0.6667\n",
      "Epoch 445/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7369 - val_loss: 0.5988 - val_accuracy: 0.6792\n",
      "Epoch 446/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5232 - accuracy: 0.7445 - val_loss: 0.6030 - val_accuracy: 0.6738\n",
      "Epoch 447/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7405 - val_loss: 0.6144 - val_accuracy: 0.6756\n",
      "Epoch 448/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.7378 - val_loss: 0.6030 - val_accuracy: 0.6685\n",
      "Epoch 449/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.7432 - val_loss: 0.6018 - val_accuracy: 0.6756\n",
      "Epoch 450/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5212 - accuracy: 0.7432 - val_loss: 0.5994 - val_accuracy: 0.6810\n",
      "Epoch 451/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.7364 - val_loss: 0.6029 - val_accuracy: 0.6738\n",
      "Epoch 452/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.7409 - val_loss: 0.6157 - val_accuracy: 0.6703\n",
      "Epoch 453/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5216 - accuracy: 0.7436 - val_loss: 0.6032 - val_accuracy: 0.6828\n",
      "Epoch 454/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.7400 - val_loss: 0.6004 - val_accuracy: 0.6810\n",
      "Epoch 455/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7400 - val_loss: 0.6030 - val_accuracy: 0.6720\n",
      "Epoch 456/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5224 - accuracy: 0.7427 - val_loss: 0.6064 - val_accuracy: 0.6774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5224 - accuracy: 0.7418 - val_loss: 0.6058 - val_accuracy: 0.6720\n",
      "Epoch 458/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5212 - accuracy: 0.7409 - val_loss: 0.6061 - val_accuracy: 0.6738\n",
      "Epoch 459/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7463 - val_loss: 0.6053 - val_accuracy: 0.6685\n",
      "Epoch 460/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.7351 - val_loss: 0.6003 - val_accuracy: 0.6792\n",
      "Epoch 461/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5218 - accuracy: 0.7418 - val_loss: 0.6001 - val_accuracy: 0.6828\n",
      "Epoch 462/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5220 - accuracy: 0.7387 - val_loss: 0.6060 - val_accuracy: 0.6667\n",
      "Epoch 463/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5207 - accuracy: 0.7405 - val_loss: 0.6034 - val_accuracy: 0.6667\n",
      "Epoch 464/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.7436 - val_loss: 0.6004 - val_accuracy: 0.6756\n",
      "Epoch 465/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.7329 - val_loss: 0.6056 - val_accuracy: 0.6685\n",
      "Epoch 466/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.7454 - val_loss: 0.6023 - val_accuracy: 0.6828\n",
      "Epoch 467/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7414 - val_loss: 0.6012 - val_accuracy: 0.6828\n",
      "Epoch 468/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5207 - accuracy: 0.7378 - val_loss: 0.6013 - val_accuracy: 0.6792\n",
      "Epoch 469/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7414 - val_loss: 0.6057 - val_accuracy: 0.6792\n",
      "Epoch 470/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.7378 - val_loss: 0.5988 - val_accuracy: 0.6774\n",
      "Epoch 471/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.7459 - val_loss: 0.6004 - val_accuracy: 0.6810\n",
      "Epoch 472/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5214 - accuracy: 0.7355 - val_loss: 0.6023 - val_accuracy: 0.6864\n",
      "Epoch 473/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7400 - val_loss: 0.6016 - val_accuracy: 0.6828\n",
      "Epoch 474/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7436 - val_loss: 0.6097 - val_accuracy: 0.6738\n",
      "Epoch 475/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.7409 - val_loss: 0.5982 - val_accuracy: 0.6738\n",
      "Epoch 476/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.7436 - val_loss: 0.6030 - val_accuracy: 0.6774\n",
      "Epoch 477/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.7418 - val_loss: 0.6015 - val_accuracy: 0.6828\n",
      "Epoch 478/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5221 - accuracy: 0.7382 - val_loss: 0.6013 - val_accuracy: 0.6774\n",
      "Epoch 479/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.7418 - val_loss: 0.6007 - val_accuracy: 0.6756\n",
      "Epoch 480/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.7369 - val_loss: 0.6148 - val_accuracy: 0.6667\n",
      "Epoch 481/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5236 - accuracy: 0.7346 - val_loss: 0.5988 - val_accuracy: 0.6774\n",
      "Epoch 482/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7427 - val_loss: 0.6177 - val_accuracy: 0.6631\n",
      "Epoch 483/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5230 - accuracy: 0.7441 - val_loss: 0.6064 - val_accuracy: 0.6738\n",
      "Epoch 484/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5202 - accuracy: 0.7427 - val_loss: 0.6039 - val_accuracy: 0.6703\n",
      "Epoch 485/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5213 - accuracy: 0.7454 - val_loss: 0.6069 - val_accuracy: 0.6738\n",
      "Epoch 486/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.7396 - val_loss: 0.6055 - val_accuracy: 0.6738\n",
      "Epoch 487/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5220 - accuracy: 0.7450 - val_loss: 0.6059 - val_accuracy: 0.6720\n",
      "Epoch 488/1000\n",
      "75/75 [==============================] - 0s 3ms/step - loss: 0.5196 - accuracy: 0.7387 - val_loss: 0.6055 - val_accuracy: 0.6810\n",
      "Epoch 489/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7387 - val_loss: 0.6049 - val_accuracy: 0.6649\n",
      "Epoch 490/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5201 - accuracy: 0.7409 - val_loss: 0.6067 - val_accuracy: 0.6703\n",
      "Epoch 491/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5224 - accuracy: 0.7369 - val_loss: 0.6051 - val_accuracy: 0.6685\n",
      "Epoch 492/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.7427 - val_loss: 0.6006 - val_accuracy: 0.6828\n",
      "Epoch 493/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5201 - accuracy: 0.7476 - val_loss: 0.5988 - val_accuracy: 0.6828\n",
      "Epoch 494/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.7414 - val_loss: 0.6022 - val_accuracy: 0.6738\n",
      "Epoch 495/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7355 - val_loss: 0.6037 - val_accuracy: 0.6720\n",
      "Epoch 496/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7405 - val_loss: 0.6056 - val_accuracy: 0.6703\n",
      "Epoch 497/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.7382 - val_loss: 0.6085 - val_accuracy: 0.6703\n",
      "Epoch 498/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.7382 - val_loss: 0.6026 - val_accuracy: 0.6738\n",
      "Epoch 499/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7351 - val_loss: 0.6041 - val_accuracy: 0.6720\n",
      "Epoch 500/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.7436 - val_loss: 0.6118 - val_accuracy: 0.6738\n",
      "Epoch 501/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5207 - accuracy: 0.7414 - val_loss: 0.6053 - val_accuracy: 0.6720\n",
      "Epoch 502/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7409 - val_loss: 0.6018 - val_accuracy: 0.6810\n",
      "Epoch 503/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5207 - accuracy: 0.7387 - val_loss: 0.6000 - val_accuracy: 0.6703\n",
      "Epoch 504/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5202 - accuracy: 0.7427 - val_loss: 0.6041 - val_accuracy: 0.6720\n",
      "Epoch 505/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7387 - val_loss: 0.6066 - val_accuracy: 0.6774\n",
      "Epoch 506/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.7432 - val_loss: 0.6094 - val_accuracy: 0.6756\n",
      "Epoch 507/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7409 - val_loss: 0.6034 - val_accuracy: 0.6792\n",
      "Epoch 508/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.7391 - val_loss: 0.6114 - val_accuracy: 0.6738\n",
      "Epoch 509/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.7427 - val_loss: 0.6019 - val_accuracy: 0.6792\n",
      "Epoch 510/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5216 - accuracy: 0.7450 - val_loss: 0.6069 - val_accuracy: 0.6720\n",
      "Epoch 511/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.7454 - val_loss: 0.6055 - val_accuracy: 0.6720\n",
      "Epoch 512/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.7427 - val_loss: 0.6049 - val_accuracy: 0.6756\n",
      "Epoch 513/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7445 - val_loss: 0.5997 - val_accuracy: 0.6774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 514/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.7423 - val_loss: 0.5998 - val_accuracy: 0.6774\n",
      "Epoch 515/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.7441 - val_loss: 0.6058 - val_accuracy: 0.6685\n",
      "Epoch 516/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.7400 - val_loss: 0.6059 - val_accuracy: 0.6720\n",
      "Epoch 517/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5217 - accuracy: 0.7387 - val_loss: 0.6111 - val_accuracy: 0.6685\n",
      "Epoch 518/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.7373 - val_loss: 0.6029 - val_accuracy: 0.6792\n",
      "Epoch 519/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7333 - val_loss: 0.6081 - val_accuracy: 0.6756\n",
      "Epoch 520/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.7414 - val_loss: 0.6046 - val_accuracy: 0.6703\n",
      "Epoch 521/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5211 - accuracy: 0.7391 - val_loss: 0.6118 - val_accuracy: 0.6720\n",
      "Epoch 522/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5201 - accuracy: 0.7414 - val_loss: 0.6025 - val_accuracy: 0.6810\n",
      "Epoch 523/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5220 - accuracy: 0.7382 - val_loss: 0.6143 - val_accuracy: 0.6738\n",
      "Epoch 524/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7346 - val_loss: 0.6017 - val_accuracy: 0.6738\n",
      "Epoch 525/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.7396 - val_loss: 0.6072 - val_accuracy: 0.6774\n",
      "Epoch 526/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5197 - accuracy: 0.7405 - val_loss: 0.6030 - val_accuracy: 0.6756\n",
      "Epoch 527/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7454 - val_loss: 0.6020 - val_accuracy: 0.6720\n",
      "Epoch 528/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5212 - accuracy: 0.7400 - val_loss: 0.6027 - val_accuracy: 0.6792\n",
      "Epoch 529/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.7445 - val_loss: 0.6008 - val_accuracy: 0.6828\n",
      "Epoch 530/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5187 - accuracy: 0.7391 - val_loss: 0.6042 - val_accuracy: 0.6667\n",
      "Epoch 531/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7454 - val_loss: 0.6038 - val_accuracy: 0.6756\n",
      "Epoch 532/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.7423 - val_loss: 0.6018 - val_accuracy: 0.6738\n",
      "Epoch 533/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7423 - val_loss: 0.6088 - val_accuracy: 0.6703\n",
      "Epoch 534/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5193 - accuracy: 0.7396 - val_loss: 0.6017 - val_accuracy: 0.6828\n",
      "Epoch 535/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7445 - val_loss: 0.6005 - val_accuracy: 0.6738\n",
      "Epoch 536/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.7459 - val_loss: 0.6025 - val_accuracy: 0.6792\n",
      "Epoch 537/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7427 - val_loss: 0.6065 - val_accuracy: 0.6685\n",
      "Epoch 538/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.7414 - val_loss: 0.6032 - val_accuracy: 0.6828\n",
      "Epoch 539/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5204 - accuracy: 0.7418 - val_loss: 0.6042 - val_accuracy: 0.6756\n",
      "Epoch 540/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.7391 - val_loss: 0.6038 - val_accuracy: 0.6738\n",
      "Epoch 541/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.7454 - val_loss: 0.6144 - val_accuracy: 0.6703\n",
      "Epoch 542/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.7418 - val_loss: 0.6133 - val_accuracy: 0.6756\n",
      "Epoch 543/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.7418 - val_loss: 0.6046 - val_accuracy: 0.6667\n",
      "Epoch 544/1000\n",
      "75/75 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.7454 - val_loss: 0.6039 - val_accuracy: 0.6828\n",
      "43/43 - 0s - loss: 0.5577 - accuracy: 0.7091 - 64ms/epoch - 1ms/step\n"
     ]
    }
   ],
   "source": [
    "input_shape = (5, 5, 1)\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=input_shape),\n",
    "    Conv2D(filters=25, kernel_size=[2,2]), \n",
    "    Activation(\"relu\"),\n",
    "    Flatten(),\n",
    "    Dense(2)\n",
    "])\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=30)\n",
    "\n",
    "model.compile(\n",
    "    loss = keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    optimizer = keras.optimizers.Adam(0.001),\n",
    "    metrics = [\"accuracy\"],\n",
    ")\n",
    "history = model.fit(X_train, y_train, batch_size=30, epochs=1000, validation_split=0.2, verbose=True, callbacks=[callback])\n",
    "test_scores = model.evaluate(X_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b1f8b8",
   "metadata": {},
   "source": [
    "The plot shows that accuracy stops improving around epoch $75$, for both training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1c2b649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dec995",
   "metadata": {},
   "source": [
    "The following model is much more complicated. We have $3$ convolution layers followed by $2$ dense layers, and then the output. We run this for a large number of epochs to see if the training stops eventually. We also have a polynomial training schedule so that the learning rate decreases, though not as quickly as with an exponential schedule. We are using dropout on the dense layers to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b2bead8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "5/5 [==============================] - 1s 77ms/step - loss: 0.6990 - accuracy: 0.5052 - val_loss: 0.6972 - val_accuracy: 0.5287\n",
      "Epoch 2/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.6981 - accuracy: 0.5173 - val_loss: 0.6894 - val_accuracy: 0.5376\n",
      "Epoch 3/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.6884 - accuracy: 0.5298 - val_loss: 0.6793 - val_accuracy: 0.5986\n",
      "Epoch 4/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.6759 - accuracy: 0.5809 - val_loss: 0.6834 - val_accuracy: 0.6004\n",
      "Epoch 5/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.6679 - accuracy: 0.6020 - val_loss: 0.6624 - val_accuracy: 0.6057\n",
      "Epoch 6/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.6542 - accuracy: 0.6212 - val_loss: 0.6640 - val_accuracy: 0.5878\n",
      "Epoch 7/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.6436 - accuracy: 0.6307 - val_loss: 0.6602 - val_accuracy: 0.6237\n",
      "Epoch 8/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.6329 - accuracy: 0.6468 - val_loss: 0.6641 - val_accuracy: 0.6022\n",
      "Epoch 9/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.6322 - accuracy: 0.6526 - val_loss: 0.6388 - val_accuracy: 0.6308\n",
      "Epoch 10/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.6331 - accuracy: 0.6517 - val_loss: 0.6555 - val_accuracy: 0.6720\n",
      "Epoch 11/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.6186 - accuracy: 0.6719 - val_loss: 0.6546 - val_accuracy: 0.6039\n",
      "Epoch 12/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.6158 - accuracy: 0.6611 - val_loss: 0.6378 - val_accuracy: 0.6720\n",
      "Epoch 13/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.6060 - accuracy: 0.6701 - val_loss: 0.6394 - val_accuracy: 0.6470\n",
      "Epoch 14/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.6109 - accuracy: 0.6665 - val_loss: 0.6411 - val_accuracy: 0.6649\n",
      "Epoch 15/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.6069 - accuracy: 0.6795 - val_loss: 0.6333 - val_accuracy: 0.6541\n",
      "Epoch 16/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.5894 - accuracy: 0.6867 - val_loss: 0.6261 - val_accuracy: 0.6470\n",
      "Epoch 17/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.5796 - accuracy: 0.7001 - val_loss: 0.6081 - val_accuracy: 0.6631\n",
      "Epoch 18/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.5721 - accuracy: 0.7028 - val_loss: 0.6119 - val_accuracy: 0.6953\n",
      "Epoch 19/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.5660 - accuracy: 0.7042 - val_loss: 0.6084 - val_accuracy: 0.6971\n",
      "Epoch 20/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.5638 - accuracy: 0.7006 - val_loss: 0.5744 - val_accuracy: 0.6864\n",
      "Epoch 21/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.5377 - accuracy: 0.7257 - val_loss: 0.5663 - val_accuracy: 0.7061\n",
      "Epoch 22/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.5387 - accuracy: 0.7199 - val_loss: 0.5596 - val_accuracy: 0.7025\n",
      "Epoch 23/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.5276 - accuracy: 0.7199 - val_loss: 0.5603 - val_accuracy: 0.7043\n",
      "Epoch 24/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.5308 - accuracy: 0.7145 - val_loss: 0.5450 - val_accuracy: 0.7276\n",
      "Epoch 25/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.5132 - accuracy: 0.7373 - val_loss: 0.5662 - val_accuracy: 0.6864\n",
      "Epoch 26/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.5082 - accuracy: 0.7355 - val_loss: 0.5712 - val_accuracy: 0.7061\n",
      "Epoch 27/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.5167 - accuracy: 0.7293 - val_loss: 0.5507 - val_accuracy: 0.7079\n",
      "Epoch 28/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.5125 - accuracy: 0.7333 - val_loss: 0.5238 - val_accuracy: 0.7222\n",
      "Epoch 29/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4795 - accuracy: 0.7503 - val_loss: 0.5342 - val_accuracy: 0.7079\n",
      "Epoch 30/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4786 - accuracy: 0.7580 - val_loss: 0.4874 - val_accuracy: 0.7581\n",
      "Epoch 31/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.4510 - accuracy: 0.7692 - val_loss: 0.4897 - val_accuracy: 0.7491\n",
      "Epoch 32/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4351 - accuracy: 0.7781 - val_loss: 0.4619 - val_accuracy: 0.7670\n",
      "Epoch 33/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.4287 - accuracy: 0.7884 - val_loss: 0.4784 - val_accuracy: 0.7527\n",
      "Epoch 34/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.4315 - accuracy: 0.7893 - val_loss: 0.4795 - val_accuracy: 0.7599\n",
      "Epoch 35/1000\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.4282 - accuracy: 0.7889 - val_loss: 0.5216 - val_accuracy: 0.7616\n",
      "Epoch 36/1000\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.4043 - accuracy: 0.7987 - val_loss: 0.4530 - val_accuracy: 0.7509\n",
      "Epoch 37/1000\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.3935 - accuracy: 0.8001 - val_loss: 0.4230 - val_accuracy: 0.7849\n",
      "Epoch 38/1000\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.3855 - accuracy: 0.8140 - val_loss: 0.4238 - val_accuracy: 0.7849\n",
      "Epoch 39/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.3841 - accuracy: 0.8068 - val_loss: 0.4349 - val_accuracy: 0.7670\n",
      "Epoch 40/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.3743 - accuracy: 0.8082 - val_loss: 0.4273 - val_accuracy: 0.7903\n",
      "Epoch 41/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.3962 - accuracy: 0.8117 - val_loss: 0.4326 - val_accuracy: 0.7975\n",
      "Epoch 42/1000\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.3854 - accuracy: 0.8162 - val_loss: 0.4364 - val_accuracy: 0.7921\n",
      "Epoch 43/1000\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.3632 - accuracy: 0.8216 - val_loss: 0.4113 - val_accuracy: 0.8011\n",
      "Epoch 44/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.3363 - accuracy: 0.8355 - val_loss: 0.4491 - val_accuracy: 0.7814\n",
      "Epoch 45/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.3352 - accuracy: 0.8418 - val_loss: 0.3998 - val_accuracy: 0.8029\n",
      "Epoch 46/1000\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.3121 - accuracy: 0.8476 - val_loss: 0.3604 - val_accuracy: 0.8208\n",
      "Epoch 47/1000\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.2925 - accuracy: 0.8557 - val_loss: 0.3701 - val_accuracy: 0.8118\n",
      "Epoch 48/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.2926 - accuracy: 0.8606 - val_loss: 0.3750 - val_accuracy: 0.8208\n",
      "Epoch 49/1000\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.2955 - accuracy: 0.8624 - val_loss: 0.3728 - val_accuracy: 0.8262\n",
      "Epoch 50/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.2821 - accuracy: 0.8723 - val_loss: 0.3734 - val_accuracy: 0.8244\n",
      "Epoch 51/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.2694 - accuracy: 0.8754 - val_loss: 0.3797 - val_accuracy: 0.8190\n",
      "Epoch 52/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.2570 - accuracy: 0.8803 - val_loss: 0.3553 - val_accuracy: 0.8369\n",
      "Epoch 53/1000\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.2463 - accuracy: 0.8866 - val_loss: 0.3544 - val_accuracy: 0.8315\n",
      "Epoch 54/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.2563 - accuracy: 0.8884 - val_loss: 0.3977 - val_accuracy: 0.8118\n",
      "Epoch 55/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.2702 - accuracy: 0.8785 - val_loss: 0.3692 - val_accuracy: 0.8405\n",
      "Epoch 56/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.2492 - accuracy: 0.8884 - val_loss: 0.3568 - val_accuracy: 0.8244\n",
      "Epoch 57/1000\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.2539 - accuracy: 0.8875 - val_loss: 0.3206 - val_accuracy: 0.8495\n",
      "Epoch 58/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.2279 - accuracy: 0.8951 - val_loss: 0.3721 - val_accuracy: 0.8351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/1000\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.2354 - accuracy: 0.8853 - val_loss: 0.3463 - val_accuracy: 0.8459\n",
      "Epoch 60/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.2266 - accuracy: 0.9054 - val_loss: 0.3460 - val_accuracy: 0.8441\n",
      "Epoch 61/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.2342 - accuracy: 0.8956 - val_loss: 0.3269 - val_accuracy: 0.8584\n",
      "Epoch 62/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.2343 - accuracy: 0.9036 - val_loss: 0.3650 - val_accuracy: 0.8602\n",
      "Epoch 63/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.2038 - accuracy: 0.9072 - val_loss: 0.3039 - val_accuracy: 0.8692\n",
      "Epoch 64/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.1945 - accuracy: 0.9171 - val_loss: 0.3378 - val_accuracy: 0.8548\n",
      "Epoch 65/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.1975 - accuracy: 0.9099 - val_loss: 0.2785 - val_accuracy: 0.8835\n",
      "Epoch 66/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.1837 - accuracy: 0.9229 - val_loss: 0.2868 - val_accuracy: 0.8763\n",
      "Epoch 67/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.1693 - accuracy: 0.9292 - val_loss: 0.3329 - val_accuracy: 0.8763\n",
      "Epoch 68/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.1479 - accuracy: 0.9395 - val_loss: 0.3203 - val_accuracy: 0.8853\n",
      "Epoch 69/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.1567 - accuracy: 0.9381 - val_loss: 0.3062 - val_accuracy: 0.8835\n",
      "Epoch 70/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.1649 - accuracy: 0.9278 - val_loss: 0.3246 - val_accuracy: 0.8710\n",
      "Epoch 71/1000\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.1578 - accuracy: 0.9310 - val_loss: 0.3107 - val_accuracy: 0.8925\n",
      "Epoch 72/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.1483 - accuracy: 0.9413 - val_loss: 0.3109 - val_accuracy: 0.8781\n",
      "Epoch 73/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.1438 - accuracy: 0.9350 - val_loss: 0.3044 - val_accuracy: 0.8996\n",
      "Epoch 74/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.1283 - accuracy: 0.9480 - val_loss: 0.2851 - val_accuracy: 0.8853\n",
      "Epoch 75/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.1415 - accuracy: 0.9435 - val_loss: 0.2920 - val_accuracy: 0.8907\n",
      "Epoch 76/1000\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.1331 - accuracy: 0.9413 - val_loss: 0.3248 - val_accuracy: 0.8889\n",
      "Epoch 77/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.1201 - accuracy: 0.9516 - val_loss: 0.3308 - val_accuracy: 0.8925\n",
      "Epoch 78/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.1374 - accuracy: 0.9462 - val_loss: 0.3560 - val_accuracy: 0.8728\n",
      "Epoch 79/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.1241 - accuracy: 0.9511 - val_loss: 0.3518 - val_accuracy: 0.8781\n",
      "Epoch 80/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.1181 - accuracy: 0.9485 - val_loss: 0.3170 - val_accuracy: 0.8943\n",
      "Epoch 81/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.1293 - accuracy: 0.9516 - val_loss: 0.3428 - val_accuracy: 0.8728\n",
      "Epoch 82/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.1258 - accuracy: 0.9489 - val_loss: 0.3042 - val_accuracy: 0.8817\n",
      "Epoch 83/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.1187 - accuracy: 0.9538 - val_loss: 0.3141 - val_accuracy: 0.8871\n",
      "Epoch 84/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.1241 - accuracy: 0.9498 - val_loss: 0.3663 - val_accuracy: 0.8925\n",
      "Epoch 85/1000\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.1118 - accuracy: 0.9556 - val_loss: 0.3075 - val_accuracy: 0.8925\n",
      "Epoch 86/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.1060 - accuracy: 0.9552 - val_loss: 0.3346 - val_accuracy: 0.9014\n",
      "Epoch 87/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.1018 - accuracy: 0.9579 - val_loss: 0.3095 - val_accuracy: 0.9050\n",
      "Epoch 88/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0833 - accuracy: 0.9677 - val_loss: 0.3318 - val_accuracy: 0.8889\n",
      "Epoch 89/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0865 - accuracy: 0.9637 - val_loss: 0.3584 - val_accuracy: 0.8871\n",
      "Epoch 90/1000\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0858 - accuracy: 0.9691 - val_loss: 0.3229 - val_accuracy: 0.9068\n",
      "Epoch 91/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0863 - accuracy: 0.9682 - val_loss: 0.3232 - val_accuracy: 0.8961\n",
      "Epoch 92/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0858 - accuracy: 0.9677 - val_loss: 0.3144 - val_accuracy: 0.8961\n",
      "Epoch 93/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0712 - accuracy: 0.9745 - val_loss: 0.3151 - val_accuracy: 0.9014\n",
      "Epoch 94/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0706 - accuracy: 0.9709 - val_loss: 0.3089 - val_accuracy: 0.8961\n",
      "Epoch 95/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0652 - accuracy: 0.9740 - val_loss: 0.3386 - val_accuracy: 0.8961\n",
      "Epoch 96/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0648 - accuracy: 0.9749 - val_loss: 0.3531 - val_accuracy: 0.9014\n",
      "Epoch 97/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0641 - accuracy: 0.9758 - val_loss: 0.3440 - val_accuracy: 0.8996\n",
      "Epoch 98/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0563 - accuracy: 0.9776 - val_loss: 0.3403 - val_accuracy: 0.8907\n",
      "Epoch 99/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0619 - accuracy: 0.9776 - val_loss: 0.3325 - val_accuracy: 0.8978\n",
      "Epoch 100/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0764 - accuracy: 0.9745 - val_loss: 0.3489 - val_accuracy: 0.9086\n",
      "Epoch 101/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0526 - accuracy: 0.9843 - val_loss: 0.3354 - val_accuracy: 0.9050\n",
      "Epoch 102/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0544 - accuracy: 0.9807 - val_loss: 0.3344 - val_accuracy: 0.9050\n",
      "Epoch 103/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0486 - accuracy: 0.9816 - val_loss: 0.3411 - val_accuracy: 0.9068\n",
      "Epoch 104/1000\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0482 - accuracy: 0.9816 - val_loss: 0.3501 - val_accuracy: 0.9050\n",
      "Epoch 105/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0526 - accuracy: 0.9816 - val_loss: 0.3454 - val_accuracy: 0.9014\n",
      "Epoch 106/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0443 - accuracy: 0.9852 - val_loss: 0.3437 - val_accuracy: 0.8996\n",
      "Epoch 107/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0486 - accuracy: 0.9834 - val_loss: 0.3356 - val_accuracy: 0.9014\n",
      "Epoch 108/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0461 - accuracy: 0.9848 - val_loss: 0.3346 - val_accuracy: 0.9050\n",
      "Epoch 109/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0503 - accuracy: 0.9830 - val_loss: 0.3279 - val_accuracy: 0.9050\n",
      "Epoch 110/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0511 - accuracy: 0.9821 - val_loss: 0.3224 - val_accuracy: 0.9032\n",
      "Epoch 111/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0457 - accuracy: 0.9825 - val_loss: 0.3249 - val_accuracy: 0.8996\n",
      "Epoch 112/1000\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0435 - accuracy: 0.9830 - val_loss: 0.3403 - val_accuracy: 0.9086\n",
      "Epoch 113/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0465 - accuracy: 0.9852 - val_loss: 0.3476 - val_accuracy: 0.9086\n",
      "Epoch 114/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0386 - accuracy: 0.9901 - val_loss: 0.3478 - val_accuracy: 0.9086\n",
      "Epoch 115/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0465 - accuracy: 0.9857 - val_loss: 0.3407 - val_accuracy: 0.9068\n",
      "Epoch 116/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0448 - accuracy: 0.9843 - val_loss: 0.3450 - val_accuracy: 0.9140\n",
      "Epoch 117/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0411 - accuracy: 0.9866 - val_loss: 0.3405 - val_accuracy: 0.9104\n",
      "Epoch 118/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0413 - accuracy: 0.9852 - val_loss: 0.3423 - val_accuracy: 0.9086\n",
      "Epoch 119/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0409 - accuracy: 0.9883 - val_loss: 0.3488 - val_accuracy: 0.9122\n",
      "Epoch 120/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0368 - accuracy: 0.9892 - val_loss: 0.3522 - val_accuracy: 0.9158\n",
      "Epoch 121/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0412 - accuracy: 0.9848 - val_loss: 0.3468 - val_accuracy: 0.9050\n",
      "Epoch 122/1000\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0425 - accuracy: 0.9834 - val_loss: 0.3520 - val_accuracy: 0.9158\n",
      "Epoch 123/1000\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0455 - accuracy: 0.9816 - val_loss: 0.3765 - val_accuracy: 0.9158\n",
      "Epoch 124/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0389 - accuracy: 0.9866 - val_loss: 0.3598 - val_accuracy: 0.9086\n",
      "Epoch 125/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0431 - accuracy: 0.9857 - val_loss: 0.3519 - val_accuracy: 0.9140\n",
      "Epoch 126/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0415 - accuracy: 0.9870 - val_loss: 0.3539 - val_accuracy: 0.9158\n",
      "Epoch 127/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0447 - accuracy: 0.9830 - val_loss: 0.3437 - val_accuracy: 0.9176\n",
      "Epoch 128/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0486 - accuracy: 0.9861 - val_loss: 0.3590 - val_accuracy: 0.9068\n",
      "Epoch 129/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0358 - accuracy: 0.9888 - val_loss: 0.3688 - val_accuracy: 0.9104\n",
      "Epoch 130/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0372 - accuracy: 0.9897 - val_loss: 0.3720 - val_accuracy: 0.9122\n",
      "Epoch 131/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0486 - accuracy: 0.9830 - val_loss: 0.3651 - val_accuracy: 0.9140\n",
      "Epoch 132/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0398 - accuracy: 0.9879 - val_loss: 0.3537 - val_accuracy: 0.9068\n",
      "Epoch 133/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0411 - accuracy: 0.9870 - val_loss: 0.3364 - val_accuracy: 0.9158\n",
      "Epoch 134/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0432 - accuracy: 0.9839 - val_loss: 0.3385 - val_accuracy: 0.9158\n",
      "Epoch 135/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0431 - accuracy: 0.9874 - val_loss: 0.3362 - val_accuracy: 0.9122\n",
      "Epoch 136/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0325 - accuracy: 0.9897 - val_loss: 0.3449 - val_accuracy: 0.9194\n",
      "Epoch 137/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0376 - accuracy: 0.9874 - val_loss: 0.3468 - val_accuracy: 0.9194\n",
      "Epoch 138/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0396 - accuracy: 0.9892 - val_loss: 0.3453 - val_accuracy: 0.9086\n",
      "Epoch 139/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0355 - accuracy: 0.9892 - val_loss: 0.3439 - val_accuracy: 0.9068\n",
      "Epoch 140/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0390 - accuracy: 0.9866 - val_loss: 0.3455 - val_accuracy: 0.9104\n",
      "Epoch 141/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0343 - accuracy: 0.9897 - val_loss: 0.3546 - val_accuracy: 0.9158\n",
      "Epoch 142/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0349 - accuracy: 0.9874 - val_loss: 0.3480 - val_accuracy: 0.9140\n",
      "Epoch 143/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0446 - accuracy: 0.9857 - val_loss: 0.3590 - val_accuracy: 0.9122\n",
      "Epoch 144/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0324 - accuracy: 0.9888 - val_loss: 0.3684 - val_accuracy: 0.9104\n",
      "Epoch 145/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0270 - accuracy: 0.9910 - val_loss: 0.3661 - val_accuracy: 0.9122\n",
      "Epoch 146/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0323 - accuracy: 0.9906 - val_loss: 0.3658 - val_accuracy: 0.9158\n",
      "Epoch 147/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0380 - accuracy: 0.9906 - val_loss: 0.3668 - val_accuracy: 0.9176\n",
      "Epoch 148/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0356 - accuracy: 0.9870 - val_loss: 0.3675 - val_accuracy: 0.9122\n",
      "Epoch 149/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0382 - accuracy: 0.9874 - val_loss: 0.3702 - val_accuracy: 0.9104\n",
      "Epoch 150/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0314 - accuracy: 0.9901 - val_loss: 0.3841 - val_accuracy: 0.9176\n",
      "Epoch 151/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0380 - accuracy: 0.9892 - val_loss: 0.3757 - val_accuracy: 0.9158\n",
      "Epoch 152/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0342 - accuracy: 0.9879 - val_loss: 0.3773 - val_accuracy: 0.9140\n",
      "Epoch 153/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0390 - accuracy: 0.9897 - val_loss: 0.3783 - val_accuracy: 0.9140\n",
      "Epoch 154/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0388 - accuracy: 0.9870 - val_loss: 0.3733 - val_accuracy: 0.9104\n",
      "Epoch 155/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0344 - accuracy: 0.9888 - val_loss: 0.3741 - val_accuracy: 0.9104\n",
      "Epoch 156/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0334 - accuracy: 0.9906 - val_loss: 0.3786 - val_accuracy: 0.9086\n",
      "Epoch 157/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0341 - accuracy: 0.9892 - val_loss: 0.3931 - val_accuracy: 0.9122\n",
      "Epoch 158/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0344 - accuracy: 0.9874 - val_loss: 0.3976 - val_accuracy: 0.9122\n",
      "Epoch 159/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0452 - accuracy: 0.9861 - val_loss: 0.3986 - val_accuracy: 0.9176\n",
      "Epoch 160/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0310 - accuracy: 0.9919 - val_loss: 0.3933 - val_accuracy: 0.9140\n",
      "Epoch 161/1000\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0340 - accuracy: 0.9874 - val_loss: 0.3905 - val_accuracy: 0.9086\n",
      "Epoch 162/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0281 - accuracy: 0.9915 - val_loss: 0.3746 - val_accuracy: 0.9140\n",
      "Epoch 163/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0309 - accuracy: 0.9901 - val_loss: 0.3746 - val_accuracy: 0.9104\n",
      "Epoch 164/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0306 - accuracy: 0.9919 - val_loss: 0.3773 - val_accuracy: 0.9158\n",
      "Epoch 165/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0322 - accuracy: 0.9879 - val_loss: 0.3683 - val_accuracy: 0.9122\n",
      "Epoch 166/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0358 - accuracy: 0.9866 - val_loss: 0.3628 - val_accuracy: 0.9158\n",
      "Epoch 167/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0271 - accuracy: 0.9910 - val_loss: 0.3787 - val_accuracy: 0.9158\n",
      "Epoch 168/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0297 - accuracy: 0.9897 - val_loss: 0.3922 - val_accuracy: 0.9194\n",
      "Epoch 169/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0293 - accuracy: 0.9901 - val_loss: 0.3916 - val_accuracy: 0.9140\n",
      "Epoch 170/1000\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0308 - accuracy: 0.9915 - val_loss: 0.3860 - val_accuracy: 0.9104\n",
      "Epoch 171/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0390 - accuracy: 0.9848 - val_loss: 0.3785 - val_accuracy: 0.9140\n",
      "Epoch 172/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0297 - accuracy: 0.9915 - val_loss: 0.3714 - val_accuracy: 0.9194\n",
      "Epoch 173/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0221 - accuracy: 0.9937 - val_loss: 0.3666 - val_accuracy: 0.9194\n",
      "Epoch 174/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0254 - accuracy: 0.9928 - val_loss: 0.3670 - val_accuracy: 0.9194\n",
      "Epoch 175/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0236 - accuracy: 0.9933 - val_loss: 0.3788 - val_accuracy: 0.9194\n",
      "Epoch 176/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0278 - accuracy: 0.9888 - val_loss: 0.3832 - val_accuracy: 0.9229\n",
      "Epoch 177/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0269 - accuracy: 0.9901 - val_loss: 0.3867 - val_accuracy: 0.9158\n",
      "Epoch 178/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0309 - accuracy: 0.9901 - val_loss: 0.3904 - val_accuracy: 0.9086\n",
      "Epoch 179/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0289 - accuracy: 0.9910 - val_loss: 0.3917 - val_accuracy: 0.9122\n",
      "Epoch 180/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0321 - accuracy: 0.9892 - val_loss: 0.3861 - val_accuracy: 0.9086\n",
      "Epoch 181/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0369 - accuracy: 0.9879 - val_loss: 0.3758 - val_accuracy: 0.9176\n",
      "Epoch 182/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0379 - accuracy: 0.9848 - val_loss: 0.3682 - val_accuracy: 0.9229\n",
      "Epoch 183/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0286 - accuracy: 0.9910 - val_loss: 0.3608 - val_accuracy: 0.9194\n",
      "Epoch 184/1000\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0300 - accuracy: 0.9879 - val_loss: 0.3738 - val_accuracy: 0.9211\n",
      "Epoch 185/1000\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0279 - accuracy: 0.9897 - val_loss: 0.3609 - val_accuracy: 0.9247\n",
      "Epoch 186/1000\n",
      "5/5 [==============================] - 0s 47ms/step - loss: 0.0289 - accuracy: 0.9892 - val_loss: 0.3697 - val_accuracy: 0.9194\n",
      "Epoch 187/1000\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0269 - accuracy: 0.9919 - val_loss: 0.3844 - val_accuracy: 0.9104\n",
      "Epoch 188/1000\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0313 - accuracy: 0.9915 - val_loss: 0.3904 - val_accuracy: 0.9194\n",
      "Epoch 189/1000\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0356 - accuracy: 0.9888 - val_loss: 0.3871 - val_accuracy: 0.9176\n",
      "Epoch 190/1000\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.0270 - accuracy: 0.9897 - val_loss: 0.3737 - val_accuracy: 0.9194\n",
      "Epoch 191/1000\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0232 - accuracy: 0.9942 - val_loss: 0.3729 - val_accuracy: 0.9283\n",
      "Epoch 192/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0210 - accuracy: 0.9942 - val_loss: 0.3746 - val_accuracy: 0.9283\n",
      "Epoch 193/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0225 - accuracy: 0.9928 - val_loss: 0.3875 - val_accuracy: 0.9301\n",
      "Epoch 194/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0334 - accuracy: 0.9883 - val_loss: 0.3991 - val_accuracy: 0.9265\n",
      "Epoch 195/1000\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0266 - accuracy: 0.9897 - val_loss: 0.4034 - val_accuracy: 0.9265\n",
      "Epoch 196/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0290 - accuracy: 0.9915 - val_loss: 0.4025 - val_accuracy: 0.9265\n",
      "Epoch 197/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0338 - accuracy: 0.9866 - val_loss: 0.4000 - val_accuracy: 0.9283\n",
      "Epoch 198/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0305 - accuracy: 0.9901 - val_loss: 0.4088 - val_accuracy: 0.9211\n",
      "Epoch 199/1000\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0263 - accuracy: 0.9915 - val_loss: 0.3998 - val_accuracy: 0.9247\n",
      "Epoch 200/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0337 - accuracy: 0.9897 - val_loss: 0.4023 - val_accuracy: 0.9140\n",
      "Epoch 201/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0205 - accuracy: 0.9951 - val_loss: 0.3945 - val_accuracy: 0.9176\n",
      "Epoch 202/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0276 - accuracy: 0.9924 - val_loss: 0.4040 - val_accuracy: 0.9211\n",
      "Epoch 203/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0209 - accuracy: 0.9946 - val_loss: 0.4117 - val_accuracy: 0.9176\n",
      "Epoch 204/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0208 - accuracy: 0.9928 - val_loss: 0.4073 - val_accuracy: 0.9122\n",
      "Epoch 205/1000\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0196 - accuracy: 0.9946 - val_loss: 0.4051 - val_accuracy: 0.9158\n",
      "Epoch 206/1000\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0211 - accuracy: 0.9937 - val_loss: 0.4057 - val_accuracy: 0.9229\n",
      "Epoch 207/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0249 - accuracy: 0.9924 - val_loss: 0.4093 - val_accuracy: 0.9229\n",
      "Epoch 208/1000\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0245 - accuracy: 0.9928 - val_loss: 0.4013 - val_accuracy: 0.9194\n",
      "Epoch 209/1000\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0203 - accuracy: 0.9951 - val_loss: 0.3950 - val_accuracy: 0.9211\n",
      "Epoch 210/1000\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0211 - accuracy: 0.9924 - val_loss: 0.4040 - val_accuracy: 0.9247\n",
      "Epoch 211/1000\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.0191 - accuracy: 0.9942 - val_loss: 0.4108 - val_accuracy: 0.9229\n",
      "Epoch 212/1000\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0251 - accuracy: 0.9933 - val_loss: 0.4100 - val_accuracy: 0.9283\n",
      "Epoch 213/1000\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0255 - accuracy: 0.9906 - val_loss: 0.4016 - val_accuracy: 0.9229\n",
      "Epoch 214/1000\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0252 - accuracy: 0.9906 - val_loss: 0.4047 - val_accuracy: 0.9211\n",
      "Epoch 215/1000\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0271 - accuracy: 0.9906 - val_loss: 0.4033 - val_accuracy: 0.9211\n",
      "Epoch 216/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0214 - accuracy: 0.9933 - val_loss: 0.4013 - val_accuracy: 0.9229\n",
      "Epoch 217/1000\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0216 - accuracy: 0.9928 - val_loss: 0.4129 - val_accuracy: 0.9140\n",
      "Epoch 218/1000\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0251 - accuracy: 0.9928 - val_loss: 0.4292 - val_accuracy: 0.9229\n",
      "Epoch 219/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0233 - accuracy: 0.9942 - val_loss: 0.4135 - val_accuracy: 0.9158\n",
      "Epoch 220/1000\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0263 - accuracy: 0.9892 - val_loss: 0.4223 - val_accuracy: 0.9211\n",
      "Epoch 221/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0332 - accuracy: 0.9892 - val_loss: 0.4126 - val_accuracy: 0.9211\n",
      "Epoch 222/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0321 - accuracy: 0.9888 - val_loss: 0.4158 - val_accuracy: 0.9158\n",
      "Epoch 223/1000\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0241 - accuracy: 0.9919 - val_loss: 0.4258 - val_accuracy: 0.9176\n",
      "Epoch 224/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0251 - accuracy: 0.9906 - val_loss: 0.4091 - val_accuracy: 0.9211\n",
      "Epoch 225/1000\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0264 - accuracy: 0.9924 - val_loss: 0.3985 - val_accuracy: 0.9176\n",
      "Epoch 226/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0315 - accuracy: 0.9901 - val_loss: 0.4079 - val_accuracy: 0.9140\n",
      "Epoch 227/1000\n",
      "5/5 [==============================] - 0s 21ms/step - loss: 0.0192 - accuracy: 0.9946 - val_loss: 0.4251 - val_accuracy: 0.9176\n",
      "Epoch 228/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0305 - accuracy: 0.9892 - val_loss: 0.4297 - val_accuracy: 0.9104\n",
      "Epoch 229/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0257 - accuracy: 0.9906 - val_loss: 0.4423 - val_accuracy: 0.9211\n",
      "Epoch 230/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0279 - accuracy: 0.9910 - val_loss: 0.4349 - val_accuracy: 0.9247\n",
      "Epoch 231/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0220 - accuracy: 0.9906 - val_loss: 0.4289 - val_accuracy: 0.9158\n",
      "Epoch 232/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0290 - accuracy: 0.9901 - val_loss: 0.4366 - val_accuracy: 0.9122\n",
      "Epoch 233/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0295 - accuracy: 0.9919 - val_loss: 0.4559 - val_accuracy: 0.9122\n",
      "Epoch 234/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0207 - accuracy: 0.9937 - val_loss: 0.4680 - val_accuracy: 0.9122\n",
      "Epoch 235/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0246 - accuracy: 0.9919 - val_loss: 0.4580 - val_accuracy: 0.9140\n",
      "Epoch 236/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0239 - accuracy: 0.9915 - val_loss: 0.4226 - val_accuracy: 0.9140\n",
      "Epoch 237/1000\n",
      "5/5 [==============================] - 0s 52ms/step - loss: 0.0189 - accuracy: 0.9928 - val_loss: 0.4059 - val_accuracy: 0.9176\n",
      "Epoch 238/1000\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0208 - accuracy: 0.9924 - val_loss: 0.4008 - val_accuracy: 0.9265\n",
      "Epoch 239/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0283 - accuracy: 0.9906 - val_loss: 0.3959 - val_accuracy: 0.9265\n",
      "Epoch 240/1000\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0189 - accuracy: 0.9951 - val_loss: 0.3943 - val_accuracy: 0.9265\n",
      "Epoch 241/1000\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.0210 - accuracy: 0.9933 - val_loss: 0.4078 - val_accuracy: 0.9265\n",
      "Epoch 242/1000\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0161 - accuracy: 0.9946 - val_loss: 0.4198 - val_accuracy: 0.9211\n",
      "Epoch 243/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0183 - accuracy: 0.9946 - val_loss: 0.4204 - val_accuracy: 0.9211\n",
      "Epoch 244/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0171 - accuracy: 0.9951 - val_loss: 0.4252 - val_accuracy: 0.9158\n",
      "Epoch 245/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0204 - accuracy: 0.9901 - val_loss: 0.4365 - val_accuracy: 0.9158\n",
      "Epoch 246/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0184 - accuracy: 0.9928 - val_loss: 0.4340 - val_accuracy: 0.9176\n",
      "Epoch 247/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 0.4322 - val_accuracy: 0.9104\n",
      "Epoch 248/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0219 - accuracy: 0.9915 - val_loss: 0.4302 - val_accuracy: 0.9158\n",
      "Epoch 249/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 0.4451 - val_accuracy: 0.9104\n",
      "Epoch 250/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0171 - accuracy: 0.9942 - val_loss: 0.4608 - val_accuracy: 0.9122\n",
      "Epoch 251/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0159 - accuracy: 0.9951 - val_loss: 0.4717 - val_accuracy: 0.9140\n",
      "Epoch 252/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0169 - accuracy: 0.9951 - val_loss: 0.4681 - val_accuracy: 0.9140\n",
      "Epoch 253/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0233 - accuracy: 0.9924 - val_loss: 0.4688 - val_accuracy: 0.9176\n",
      "Epoch 254/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0169 - accuracy: 0.9951 - val_loss: 0.4762 - val_accuracy: 0.9140\n",
      "Epoch 255/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0236 - accuracy: 0.9951 - val_loss: 0.4419 - val_accuracy: 0.9140\n",
      "Epoch 256/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0150 - accuracy: 0.9955 - val_loss: 0.4308 - val_accuracy: 0.9122\n",
      "Epoch 257/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0161 - accuracy: 0.9946 - val_loss: 0.4353 - val_accuracy: 0.9158\n",
      "Epoch 258/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0156 - accuracy: 0.9946 - val_loss: 0.4365 - val_accuracy: 0.9247\n",
      "Epoch 259/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0187 - accuracy: 0.9955 - val_loss: 0.4377 - val_accuracy: 0.9194\n",
      "Epoch 260/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0153 - accuracy: 0.9951 - val_loss: 0.4427 - val_accuracy: 0.9140\n",
      "Epoch 261/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0149 - accuracy: 0.9942 - val_loss: 0.4595 - val_accuracy: 0.9104\n",
      "Epoch 262/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0128 - accuracy: 0.9951 - val_loss: 0.4669 - val_accuracy: 0.9158\n",
      "Epoch 263/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0167 - accuracy: 0.9946 - val_loss: 0.4531 - val_accuracy: 0.9140\n",
      "Epoch 264/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0175 - accuracy: 0.9937 - val_loss: 0.4448 - val_accuracy: 0.9176\n",
      "Epoch 265/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0234 - accuracy: 0.9919 - val_loss: 0.4511 - val_accuracy: 0.9194\n",
      "Epoch 266/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0222 - accuracy: 0.9933 - val_loss: 0.4579 - val_accuracy: 0.9265\n",
      "Epoch 267/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0235 - accuracy: 0.9924 - val_loss: 0.4577 - val_accuracy: 0.9229\n",
      "Epoch 268/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0248 - accuracy: 0.9924 - val_loss: 0.4515 - val_accuracy: 0.9229\n",
      "Epoch 269/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0170 - accuracy: 0.9937 - val_loss: 0.4338 - val_accuracy: 0.9229\n",
      "Epoch 270/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0173 - accuracy: 0.9937 - val_loss: 0.4295 - val_accuracy: 0.9211\n",
      "Epoch 271/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0183 - accuracy: 0.9951 - val_loss: 0.4353 - val_accuracy: 0.9247\n",
      "Epoch 272/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0238 - accuracy: 0.9919 - val_loss: 0.4497 - val_accuracy: 0.9194\n",
      "Epoch 273/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0218 - accuracy: 0.9937 - val_loss: 0.4725 - val_accuracy: 0.9265\n",
      "Epoch 274/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0247 - accuracy: 0.9919 - val_loss: 0.4850 - val_accuracy: 0.9158\n",
      "Epoch 275/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0138 - accuracy: 0.9955 - val_loss: 0.4644 - val_accuracy: 0.9140\n",
      "Epoch 276/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0174 - accuracy: 0.9946 - val_loss: 0.4657 - val_accuracy: 0.9158\n",
      "Epoch 277/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0239 - accuracy: 0.9924 - val_loss: 0.4659 - val_accuracy: 0.9194\n",
      "Epoch 278/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0162 - accuracy: 0.9946 - val_loss: 0.4714 - val_accuracy: 0.9319\n",
      "Epoch 279/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0275 - accuracy: 0.9892 - val_loss: 0.4368 - val_accuracy: 0.9247\n",
      "Epoch 280/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0242 - accuracy: 0.9910 - val_loss: 0.4296 - val_accuracy: 0.9211\n",
      "Epoch 281/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0211 - accuracy: 0.9928 - val_loss: 0.4383 - val_accuracy: 0.9229\n",
      "Epoch 282/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0204 - accuracy: 0.9946 - val_loss: 0.4576 - val_accuracy: 0.9176\n",
      "Epoch 283/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0253 - accuracy: 0.9933 - val_loss: 0.4757 - val_accuracy: 0.9122\n",
      "Epoch 284/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0180 - accuracy: 0.9946 - val_loss: 0.4503 - val_accuracy: 0.9247\n",
      "Epoch 285/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0133 - accuracy: 0.9969 - val_loss: 0.4502 - val_accuracy: 0.9194\n",
      "Epoch 286/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0184 - accuracy: 0.9942 - val_loss: 0.4419 - val_accuracy: 0.9176\n",
      "Epoch 287/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0148 - accuracy: 0.9937 - val_loss: 0.4468 - val_accuracy: 0.9194\n",
      "Epoch 288/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0241 - accuracy: 0.9960 - val_loss: 0.4528 - val_accuracy: 0.9158\n",
      "Epoch 289/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0197 - accuracy: 0.9933 - val_loss: 0.4551 - val_accuracy: 0.9068\n",
      "Epoch 290/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0227 - accuracy: 0.9915 - val_loss: 0.4523 - val_accuracy: 0.9158\n",
      "Epoch 291/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0125 - accuracy: 0.9964 - val_loss: 0.4682 - val_accuracy: 0.9140\n",
      "Epoch 292/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0214 - accuracy: 0.9919 - val_loss: 0.4837 - val_accuracy: 0.9194\n",
      "Epoch 293/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0177 - accuracy: 0.9942 - val_loss: 0.4729 - val_accuracy: 0.9194\n",
      "Epoch 294/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0244 - accuracy: 0.9942 - val_loss: 0.4648 - val_accuracy: 0.9229\n",
      "Epoch 295/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0151 - accuracy: 0.9955 - val_loss: 0.4571 - val_accuracy: 0.9122\n",
      "Epoch 296/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0178 - accuracy: 0.9951 - val_loss: 0.4652 - val_accuracy: 0.9158\n",
      "Epoch 297/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0211 - accuracy: 0.9942 - val_loss: 0.4756 - val_accuracy: 0.9158\n",
      "Epoch 298/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0186 - accuracy: 0.9933 - val_loss: 0.4612 - val_accuracy: 0.9229\n",
      "Epoch 299/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0197 - accuracy: 0.9933 - val_loss: 0.4605 - val_accuracy: 0.9176\n",
      "Epoch 300/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0205 - accuracy: 0.9933 - val_loss: 0.4490 - val_accuracy: 0.9194\n",
      "Epoch 301/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0242 - accuracy: 0.9933 - val_loss: 0.4519 - val_accuracy: 0.9176\n",
      "Epoch 302/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0211 - accuracy: 0.9919 - val_loss: 0.4679 - val_accuracy: 0.9140\n",
      "Epoch 303/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0172 - accuracy: 0.9937 - val_loss: 0.5006 - val_accuracy: 0.9104\n",
      "Epoch 304/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0187 - accuracy: 0.9951 - val_loss: 0.4956 - val_accuracy: 0.9176\n",
      "Epoch 305/1000\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0158 - accuracy: 0.9951 - val_loss: 0.4659 - val_accuracy: 0.9104\n",
      "Epoch 306/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0214 - accuracy: 0.9928 - val_loss: 0.4518 - val_accuracy: 0.9158\n",
      "Epoch 307/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0187 - accuracy: 0.9919 - val_loss: 0.4801 - val_accuracy: 0.9176\n",
      "Epoch 308/1000\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0141 - accuracy: 0.9951 - val_loss: 0.4938 - val_accuracy: 0.9176\n",
      "Epoch 309/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0202 - accuracy: 0.9937 - val_loss: 0.4899 - val_accuracy: 0.9176\n",
      "Epoch 310/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0150 - accuracy: 0.9960 - val_loss: 0.4810 - val_accuracy: 0.9086\n",
      "Epoch 311/1000\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0185 - accuracy: 0.9928 - val_loss: 0.5040 - val_accuracy: 0.9068\n",
      "Epoch 312/1000\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.0151 - accuracy: 0.9960 - val_loss: 0.5185 - val_accuracy: 0.9140\n",
      "Epoch 313/1000\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0176 - accuracy: 0.9955 - val_loss: 0.5211 - val_accuracy: 0.9122\n",
      "Epoch 314/1000\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0172 - accuracy: 0.9919 - val_loss: 0.5193 - val_accuracy: 0.9122\n",
      "Epoch 315/1000\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0147 - accuracy: 0.9946 - val_loss: 0.5117 - val_accuracy: 0.9140\n",
      "Epoch 316/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0168 - accuracy: 0.9937 - val_loss: 0.5011 - val_accuracy: 0.9122\n",
      "Epoch 317/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0192 - accuracy: 0.9919 - val_loss: 0.4896 - val_accuracy: 0.9158\n",
      "Epoch 318/1000\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0208 - accuracy: 0.9937 - val_loss: 0.4954 - val_accuracy: 0.9211\n",
      "Epoch 319/1000\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0186 - accuracy: 0.9969 - val_loss: 0.4962 - val_accuracy: 0.9211\n",
      "Epoch 320/1000\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0170 - accuracy: 0.9951 - val_loss: 0.4858 - val_accuracy: 0.9158\n",
      "Epoch 321/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0148 - accuracy: 0.9937 - val_loss: 0.4772 - val_accuracy: 0.9158\n",
      "Epoch 322/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0118 - accuracy: 0.9964 - val_loss: 0.5071 - val_accuracy: 0.9122\n",
      "Epoch 323/1000\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0190 - accuracy: 0.9933 - val_loss: 0.5050 - val_accuracy: 0.9140\n",
      "Epoch 324/1000\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0213 - accuracy: 0.9928 - val_loss: 0.4976 - val_accuracy: 0.9158\n",
      "Epoch 325/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0185 - accuracy: 0.9942 - val_loss: 0.5017 - val_accuracy: 0.9122\n",
      "Epoch 326/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 0.4914 - val_accuracy: 0.9122\n",
      "Epoch 327/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0105 - accuracy: 0.9978 - val_loss: 0.4890 - val_accuracy: 0.9176\n",
      "Epoch 328/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0150 - accuracy: 0.9955 - val_loss: 0.4929 - val_accuracy: 0.9176\n",
      "Epoch 329/1000\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0173 - accuracy: 0.9937 - val_loss: 0.5066 - val_accuracy: 0.9140\n",
      "Epoch 330/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0128 - accuracy: 0.9960 - val_loss: 0.4979 - val_accuracy: 0.9140\n",
      "Epoch 331/1000\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0112 - accuracy: 0.9973 - val_loss: 0.5088 - val_accuracy: 0.9122\n",
      "Epoch 332/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0133 - accuracy: 0.9964 - val_loss: 0.5104 - val_accuracy: 0.9158\n",
      "Epoch 333/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0161 - accuracy: 0.9946 - val_loss: 0.5035 - val_accuracy: 0.9140\n",
      "Epoch 334/1000\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0104 - accuracy: 0.9964 - val_loss: 0.5013 - val_accuracy: 0.9211\n",
      "Epoch 335/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0124 - accuracy: 0.9969 - val_loss: 0.5047 - val_accuracy: 0.9176\n",
      "Epoch 336/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0128 - accuracy: 0.9960 - val_loss: 0.5057 - val_accuracy: 0.9194\n",
      "Epoch 337/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0107 - accuracy: 0.9969 - val_loss: 0.5177 - val_accuracy: 0.9140\n",
      "Epoch 338/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0142 - accuracy: 0.9951 - val_loss: 0.5259 - val_accuracy: 0.9158\n",
      "Epoch 339/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0157 - accuracy: 0.9960 - val_loss: 0.5076 - val_accuracy: 0.9176\n",
      "Epoch 340/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0148 - accuracy: 0.9964 - val_loss: 0.4918 - val_accuracy: 0.9176\n",
      "Epoch 341/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0125 - accuracy: 0.9951 - val_loss: 0.5022 - val_accuracy: 0.9140\n",
      "Epoch 342/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0200 - accuracy: 0.9924 - val_loss: 0.5144 - val_accuracy: 0.9176\n",
      "Epoch 343/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0199 - accuracy: 0.9919 - val_loss: 0.5204 - val_accuracy: 0.9194\n",
      "Epoch 344/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0167 - accuracy: 0.9937 - val_loss: 0.5106 - val_accuracy: 0.9194\n",
      "Epoch 345/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0175 - accuracy: 0.9924 - val_loss: 0.5204 - val_accuracy: 0.9265\n",
      "Epoch 346/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0186 - accuracy: 0.9937 - val_loss: 0.5059 - val_accuracy: 0.9194\n",
      "Epoch 347/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0178 - accuracy: 0.9924 - val_loss: 0.5130 - val_accuracy: 0.9158\n",
      "Epoch 348/1000\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0174 - accuracy: 0.9951 - val_loss: 0.5249 - val_accuracy: 0.9158\n",
      "Epoch 349/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0167 - accuracy: 0.9951 - val_loss: 0.5113 - val_accuracy: 0.9158\n",
      "Epoch 350/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0163 - accuracy: 0.9946 - val_loss: 0.5213 - val_accuracy: 0.9194\n",
      "Epoch 351/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0183 - accuracy: 0.9946 - val_loss: 0.5216 - val_accuracy: 0.9229\n",
      "Epoch 352/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0229 - accuracy: 0.9937 - val_loss: 0.5060 - val_accuracy: 0.9158\n",
      "Epoch 353/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0125 - accuracy: 0.9951 - val_loss: 0.5059 - val_accuracy: 0.9194\n",
      "Epoch 354/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0157 - accuracy: 0.9937 - val_loss: 0.5208 - val_accuracy: 0.9176\n",
      "Epoch 355/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0129 - accuracy: 0.9955 - val_loss: 0.5167 - val_accuracy: 0.9265\n",
      "Epoch 356/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0159 - accuracy: 0.9951 - val_loss: 0.5419 - val_accuracy: 0.9158\n",
      "Epoch 357/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0161 - accuracy: 0.9937 - val_loss: 0.5597 - val_accuracy: 0.9176\n",
      "Epoch 358/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0162 - accuracy: 0.9937 - val_loss: 0.5623 - val_accuracy: 0.9229\n",
      "Epoch 359/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0132 - accuracy: 0.9946 - val_loss: 0.5349 - val_accuracy: 0.9158\n",
      "Epoch 360/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0132 - accuracy: 0.9942 - val_loss: 0.5303 - val_accuracy: 0.9176\n",
      "Epoch 361/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.4979 - val_accuracy: 0.9229\n",
      "Epoch 362/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0191 - accuracy: 0.9937 - val_loss: 0.4866 - val_accuracy: 0.9122\n",
      "Epoch 363/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0138 - accuracy: 0.9951 - val_loss: 0.4849 - val_accuracy: 0.9176\n",
      "Epoch 364/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0171 - accuracy: 0.9942 - val_loss: 0.4733 - val_accuracy: 0.9211\n",
      "Epoch 365/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0206 - accuracy: 0.9933 - val_loss: 0.4648 - val_accuracy: 0.9247\n",
      "Epoch 366/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0170 - accuracy: 0.9942 - val_loss: 0.4412 - val_accuracy: 0.9247\n",
      "Epoch 367/1000\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0173 - accuracy: 0.9942 - val_loss: 0.4376 - val_accuracy: 0.9229\n",
      "Epoch 368/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0172 - accuracy: 0.9937 - val_loss: 0.4631 - val_accuracy: 0.9211\n",
      "Epoch 369/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0105 - accuracy: 0.9969 - val_loss: 0.4622 - val_accuracy: 0.9247\n",
      "Epoch 370/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0192 - accuracy: 0.9942 - val_loss: 0.4515 - val_accuracy: 0.9211\n",
      "Epoch 371/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0151 - accuracy: 0.9951 - val_loss: 0.4606 - val_accuracy: 0.9211\n",
      "Epoch 372/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0130 - accuracy: 0.9955 - val_loss: 0.4772 - val_accuracy: 0.9211\n",
      "Epoch 373/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0100 - accuracy: 0.9978 - val_loss: 0.4691 - val_accuracy: 0.9194\n",
      "Epoch 374/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0086 - accuracy: 0.9969 - val_loss: 0.4606 - val_accuracy: 0.9247\n",
      "Epoch 375/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0171 - accuracy: 0.9969 - val_loss: 0.4442 - val_accuracy: 0.9211\n",
      "Epoch 376/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0163 - accuracy: 0.9946 - val_loss: 0.4436 - val_accuracy: 0.9265\n",
      "Epoch 377/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0136 - accuracy: 0.9960 - val_loss: 0.4683 - val_accuracy: 0.9247\n",
      "Epoch 378/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0102 - accuracy: 0.9978 - val_loss: 0.4730 - val_accuracy: 0.9176\n",
      "Epoch 379/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 0.4710 - val_accuracy: 0.9194\n",
      "Epoch 380/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0113 - accuracy: 0.9969 - val_loss: 0.4854 - val_accuracy: 0.9122\n",
      "Epoch 381/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0159 - accuracy: 0.9942 - val_loss: 0.4804 - val_accuracy: 0.9122\n",
      "Epoch 382/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0110 - accuracy: 0.9969 - val_loss: 0.4803 - val_accuracy: 0.9122\n",
      "Epoch 383/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0080 - accuracy: 0.9978 - val_loss: 0.4801 - val_accuracy: 0.9211\n",
      "Epoch 384/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0100 - accuracy: 0.9978 - val_loss: 0.4853 - val_accuracy: 0.9211\n",
      "Epoch 385/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0126 - accuracy: 0.9955 - val_loss: 0.4977 - val_accuracy: 0.9194\n",
      "Epoch 386/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0104 - accuracy: 0.9978 - val_loss: 0.4931 - val_accuracy: 0.9158\n",
      "Epoch 387/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0123 - accuracy: 0.9969 - val_loss: 0.5028 - val_accuracy: 0.9140\n",
      "Epoch 388/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0149 - accuracy: 0.9946 - val_loss: 0.5251 - val_accuracy: 0.9140\n",
      "Epoch 389/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0236 - accuracy: 0.9919 - val_loss: 0.5446 - val_accuracy: 0.9122\n",
      "Epoch 390/1000\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0132 - accuracy: 0.9946 - val_loss: 0.5377 - val_accuracy: 0.9158\n",
      "Epoch 391/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 0.5265 - val_accuracy: 0.9176\n",
      "Epoch 392/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0137 - accuracy: 0.9964 - val_loss: 0.5025 - val_accuracy: 0.9247\n",
      "Epoch 393/1000\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0108 - accuracy: 0.9964 - val_loss: 0.5001 - val_accuracy: 0.9176\n",
      "Epoch 394/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0187 - accuracy: 0.9969 - val_loss: 0.4959 - val_accuracy: 0.9158\n",
      "Epoch 395/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0107 - accuracy: 0.9964 - val_loss: 0.4996 - val_accuracy: 0.9158\n",
      "Epoch 396/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0184 - accuracy: 0.9942 - val_loss: 0.5027 - val_accuracy: 0.9194\n",
      "Epoch 397/1000\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0155 - accuracy: 0.9946 - val_loss: 0.5004 - val_accuracy: 0.9194\n",
      "Epoch 398/1000\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0127 - accuracy: 0.9955 - val_loss: 0.5054 - val_accuracy: 0.9176\n",
      "Epoch 399/1000\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0110 - accuracy: 0.9964 - val_loss: 0.5283 - val_accuracy: 0.9158\n",
      "Epoch 400/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0121 - accuracy: 0.9951 - val_loss: 0.5177 - val_accuracy: 0.9211\n",
      "Epoch 401/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0129 - accuracy: 0.9964 - val_loss: 0.5162 - val_accuracy: 0.9211\n",
      "Epoch 402/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0146 - accuracy: 0.9946 - val_loss: 0.5208 - val_accuracy: 0.9194\n",
      "Epoch 403/1000\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0124 - accuracy: 0.9955 - val_loss: 0.5272 - val_accuracy: 0.9247\n",
      "Epoch 404/1000\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0111 - accuracy: 0.9951 - val_loss: 0.5345 - val_accuracy: 0.9229\n",
      "Epoch 405/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0187 - accuracy: 0.9928 - val_loss: 0.5190 - val_accuracy: 0.9229\n",
      "Epoch 406/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0141 - accuracy: 0.9946 - val_loss: 0.4956 - val_accuracy: 0.9247\n",
      "Epoch 407/1000\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0139 - accuracy: 0.9951 - val_loss: 0.5119 - val_accuracy: 0.9265\n",
      "Epoch 408/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0124 - accuracy: 0.9964 - val_loss: 0.5073 - val_accuracy: 0.9140\n",
      "Epoch 409/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0209 - accuracy: 0.9937 - val_loss: 0.5122 - val_accuracy: 0.9158\n",
      "Epoch 410/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 0.5058 - val_accuracy: 0.9229\n",
      "Epoch 411/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0137 - accuracy: 0.9960 - val_loss: 0.5115 - val_accuracy: 0.9194\n",
      "Epoch 412/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0129 - accuracy: 0.9964 - val_loss: 0.5234 - val_accuracy: 0.9194\n",
      "Epoch 413/1000\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0148 - accuracy: 0.9960 - val_loss: 0.5474 - val_accuracy: 0.9176\n",
      "Epoch 414/1000\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0109 - accuracy: 0.9973 - val_loss: 0.5491 - val_accuracy: 0.9140\n",
      "Epoch 415/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0127 - accuracy: 0.9951 - val_loss: 0.5330 - val_accuracy: 0.9104\n",
      "Epoch 416/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0140 - accuracy: 0.9942 - val_loss: 0.5221 - val_accuracy: 0.9122\n",
      "Epoch 417/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0148 - accuracy: 0.9946 - val_loss: 0.5362 - val_accuracy: 0.9122\n",
      "Epoch 418/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0132 - accuracy: 0.9946 - val_loss: 0.5305 - val_accuracy: 0.9194\n",
      "Epoch 419/1000\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0109 - accuracy: 0.9960 - val_loss: 0.5105 - val_accuracy: 0.9265\n",
      "Epoch 420/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0123 - accuracy: 0.9964 - val_loss: 0.5582 - val_accuracy: 0.9176\n",
      "Epoch 421/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0243 - accuracy: 0.9937 - val_loss: 0.6084 - val_accuracy: 0.9211\n",
      "Epoch 422/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0264 - accuracy: 0.9879 - val_loss: 0.5764 - val_accuracy: 0.9140\n",
      "Epoch 423/1000\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0277 - accuracy: 0.9924 - val_loss: 0.5060 - val_accuracy: 0.9211\n",
      "Epoch 424/1000\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0142 - accuracy: 0.9933 - val_loss: 0.5113 - val_accuracy: 0.9247\n",
      "Epoch 425/1000\n",
      "5/5 [==============================] - 0s 55ms/step - loss: 0.0181 - accuracy: 0.9937 - val_loss: 0.5080 - val_accuracy: 0.9211\n",
      "Epoch 426/1000\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.0137 - accuracy: 0.9951 - val_loss: 0.5007 - val_accuracy: 0.9265\n",
      "Epoch 427/1000\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0114 - accuracy: 0.9960 - val_loss: 0.4904 - val_accuracy: 0.9194\n",
      "Epoch 428/1000\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0157 - accuracy: 0.9946 - val_loss: 0.5052 - val_accuracy: 0.9194\n",
      "Epoch 429/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0154 - accuracy: 0.9955 - val_loss: 0.5066 - val_accuracy: 0.9194\n",
      "Epoch 430/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0133 - accuracy: 0.9955 - val_loss: 0.5287 - val_accuracy: 0.9122\n",
      "Epoch 431/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0123 - accuracy: 0.9955 - val_loss: 0.5242 - val_accuracy: 0.9194\n",
      "Epoch 432/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0082 - accuracy: 0.9982 - val_loss: 0.5066 - val_accuracy: 0.9158\n",
      "Epoch 433/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0115 - accuracy: 0.9964 - val_loss: 0.4977 - val_accuracy: 0.9158\n",
      "Epoch 434/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0080 - accuracy: 0.9978 - val_loss: 0.4880 - val_accuracy: 0.9211\n",
      "Epoch 435/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0101 - accuracy: 0.9969 - val_loss: 0.4898 - val_accuracy: 0.9247\n",
      "Epoch 436/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0113 - accuracy: 0.9955 - val_loss: 0.5124 - val_accuracy: 0.9247\n",
      "Epoch 437/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0084 - accuracy: 0.9978 - val_loss: 0.5272 - val_accuracy: 0.9194\n",
      "Epoch 438/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 0.5152 - val_accuracy: 0.9176\n",
      "Epoch 439/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0098 - accuracy: 0.9964 - val_loss: 0.5105 - val_accuracy: 0.9176\n",
      "Epoch 440/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0113 - accuracy: 0.9960 - val_loss: 0.4985 - val_accuracy: 0.9211\n",
      "Epoch 441/1000\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0080 - accuracy: 0.9964 - val_loss: 0.4963 - val_accuracy: 0.9247\n",
      "Epoch 442/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.5132 - val_accuracy: 0.9247\n",
      "Epoch 443/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.5362 - val_accuracy: 0.9211\n",
      "Epoch 444/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0126 - accuracy: 0.9951 - val_loss: 0.5327 - val_accuracy: 0.9229\n",
      "Epoch 445/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0124 - accuracy: 0.9951 - val_loss: 0.5274 - val_accuracy: 0.9194\n",
      "Epoch 446/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.5246 - val_accuracy: 0.9211\n",
      "Epoch 447/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0148 - accuracy: 0.9937 - val_loss: 0.5124 - val_accuracy: 0.9265\n",
      "Epoch 448/1000\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0074 - accuracy: 0.9973 - val_loss: 0.5077 - val_accuracy: 0.9301\n",
      "Epoch 449/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.5064 - val_accuracy: 0.9301\n",
      "Epoch 450/1000\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0065 - accuracy: 0.9987 - val_loss: 0.5099 - val_accuracy: 0.9247\n",
      "Epoch 451/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0080 - accuracy: 0.9982 - val_loss: 0.5090 - val_accuracy: 0.9247\n",
      "Epoch 452/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0078 - accuracy: 0.9982 - val_loss: 0.5163 - val_accuracy: 0.9211\n",
      "Epoch 453/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0102 - accuracy: 0.9969 - val_loss: 0.5233 - val_accuracy: 0.9211\n",
      "Epoch 454/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0126 - accuracy: 0.9960 - val_loss: 0.5058 - val_accuracy: 0.9247\n",
      "Epoch 455/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0156 - accuracy: 0.9942 - val_loss: 0.5189 - val_accuracy: 0.9283\n",
      "Epoch 456/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0165 - accuracy: 0.9960 - val_loss: 0.5982 - val_accuracy: 0.9211\n",
      "Epoch 457/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0194 - accuracy: 0.9942 - val_loss: 0.5352 - val_accuracy: 0.9211\n",
      "Epoch 458/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0152 - accuracy: 0.9946 - val_loss: 0.5396 - val_accuracy: 0.9122\n",
      "Epoch 459/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0076 - accuracy: 0.9973 - val_loss: 0.5044 - val_accuracy: 0.9229\n",
      "Epoch 460/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0146 - accuracy: 0.9946 - val_loss: 0.5272 - val_accuracy: 0.9301\n",
      "Epoch 461/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0146 - accuracy: 0.9973 - val_loss: 0.5566 - val_accuracy: 0.9158\n",
      "Epoch 462/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0192 - accuracy: 0.9928 - val_loss: 0.5496 - val_accuracy: 0.9176\n",
      "Epoch 463/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0112 - accuracy: 0.9969 - val_loss: 0.5531 - val_accuracy: 0.9158\n",
      "Epoch 464/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0146 - accuracy: 0.9933 - val_loss: 0.5437 - val_accuracy: 0.9194\n",
      "Epoch 465/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0133 - accuracy: 0.9973 - val_loss: 0.5483 - val_accuracy: 0.9176\n",
      "Epoch 466/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0108 - accuracy: 0.9969 - val_loss: 0.5534 - val_accuracy: 0.9301\n",
      "Epoch 467/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0124 - accuracy: 0.9964 - val_loss: 0.5575 - val_accuracy: 0.9176\n",
      "Epoch 468/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0103 - accuracy: 0.9964 - val_loss: 0.5631 - val_accuracy: 0.9158\n",
      "Epoch 469/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0074 - accuracy: 0.9982 - val_loss: 0.5554 - val_accuracy: 0.9194\n",
      "Epoch 470/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0116 - accuracy: 0.9960 - val_loss: 0.5420 - val_accuracy: 0.9158\n",
      "Epoch 471/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0070 - accuracy: 0.9987 - val_loss: 0.5472 - val_accuracy: 0.9158\n",
      "Epoch 472/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 0.5541 - val_accuracy: 0.9229\n",
      "Epoch 473/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0081 - accuracy: 0.9969 - val_loss: 0.5515 - val_accuracy: 0.9247\n",
      "Epoch 474/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0091 - accuracy: 0.9978 - val_loss: 0.5508 - val_accuracy: 0.9247\n",
      "Epoch 475/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0098 - accuracy: 0.9987 - val_loss: 0.5463 - val_accuracy: 0.9229\n",
      "Epoch 476/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 0.5414 - val_accuracy: 0.9247\n",
      "Epoch 477/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0046 - accuracy: 0.9987 - val_loss: 0.5344 - val_accuracy: 0.9283\n",
      "Epoch 478/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0116 - accuracy: 0.9955 - val_loss: 0.5559 - val_accuracy: 0.9229\n",
      "Epoch 479/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0066 - accuracy: 0.9973 - val_loss: 0.5721 - val_accuracy: 0.9158\n",
      "Epoch 480/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0167 - accuracy: 0.9960 - val_loss: 0.6021 - val_accuracy: 0.9140\n",
      "Epoch 481/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0124 - accuracy: 0.9946 - val_loss: 0.6211 - val_accuracy: 0.9140\n",
      "Epoch 482/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0127 - accuracy: 0.9960 - val_loss: 0.5728 - val_accuracy: 0.9176\n",
      "Epoch 483/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0078 - accuracy: 0.9978 - val_loss: 0.5608 - val_accuracy: 0.9122\n",
      "Epoch 484/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0131 - accuracy: 0.9960 - val_loss: 0.5603 - val_accuracy: 0.9283\n",
      "Epoch 485/1000\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.5958 - val_accuracy: 0.9211\n",
      "Epoch 486/1000\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0153 - accuracy: 0.9951 - val_loss: 0.5751 - val_accuracy: 0.9140\n",
      "Epoch 487/1000\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0061 - accuracy: 0.9991 - val_loss: 0.5907 - val_accuracy: 0.9211\n",
      "Epoch 488/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0158 - accuracy: 0.9964 - val_loss: 0.5717 - val_accuracy: 0.9140\n",
      "Epoch 489/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0093 - accuracy: 0.9978 - val_loss: 0.5548 - val_accuracy: 0.9122\n",
      "Epoch 490/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0109 - accuracy: 0.9964 - val_loss: 0.5511 - val_accuracy: 0.9211\n",
      "Epoch 491/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0090 - accuracy: 0.9955 - val_loss: 0.5359 - val_accuracy: 0.9229\n",
      "Epoch 492/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0082 - accuracy: 0.9978 - val_loss: 0.5273 - val_accuracy: 0.9194\n",
      "Epoch 493/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0100 - accuracy: 0.9960 - val_loss: 0.5433 - val_accuracy: 0.9158\n",
      "Epoch 494/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0099 - accuracy: 0.9973 - val_loss: 0.5692 - val_accuracy: 0.9211\n",
      "Epoch 495/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0094 - accuracy: 0.9973 - val_loss: 0.5803 - val_accuracy: 0.9194\n",
      "Epoch 496/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0039 - accuracy: 0.9991 - val_loss: 0.5833 - val_accuracy: 0.9140\n",
      "Epoch 497/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.5745 - val_accuracy: 0.9158\n",
      "Epoch 498/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0080 - accuracy: 0.9982 - val_loss: 0.5794 - val_accuracy: 0.9247\n",
      "Epoch 499/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.5953 - val_accuracy: 0.9211\n",
      "Epoch 500/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0076 - accuracy: 0.9973 - val_loss: 0.5958 - val_accuracy: 0.9176\n",
      "Epoch 501/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0079 - accuracy: 0.9973 - val_loss: 0.5871 - val_accuracy: 0.9158\n",
      "Epoch 502/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.5879 - val_accuracy: 0.9140\n",
      "Epoch 503/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0161 - accuracy: 0.9960 - val_loss: 0.5789 - val_accuracy: 0.9211\n",
      "Epoch 504/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0106 - accuracy: 0.9964 - val_loss: 0.5907 - val_accuracy: 0.9176\n",
      "Epoch 505/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0143 - accuracy: 0.9955 - val_loss: 0.6086 - val_accuracy: 0.9158\n",
      "Epoch 506/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 0.6198 - val_accuracy: 0.9158\n",
      "Epoch 507/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0106 - accuracy: 0.9969 - val_loss: 0.6386 - val_accuracy: 0.9229\n",
      "Epoch 508/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0134 - accuracy: 0.9955 - val_loss: 0.6257 - val_accuracy: 0.9283\n",
      "Epoch 509/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0117 - accuracy: 0.9964 - val_loss: 0.6009 - val_accuracy: 0.9265\n",
      "Epoch 510/1000\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0117 - accuracy: 0.9960 - val_loss: 0.5827 - val_accuracy: 0.9176\n",
      "Epoch 511/1000\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0171 - accuracy: 0.9946 - val_loss: 0.6241 - val_accuracy: 0.9032\n",
      "Epoch 512/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0120 - accuracy: 0.9969 - val_loss: 0.6660 - val_accuracy: 0.9086\n",
      "Epoch 513/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.6553 - val_accuracy: 0.9086\n",
      "Epoch 514/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.6350 - val_accuracy: 0.9176\n",
      "Epoch 515/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0165 - accuracy: 0.9928 - val_loss: 0.6281 - val_accuracy: 0.9176\n",
      "Epoch 516/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0099 - accuracy: 0.9973 - val_loss: 0.6015 - val_accuracy: 0.9176\n",
      "Epoch 517/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0134 - accuracy: 0.9955 - val_loss: 0.5872 - val_accuracy: 0.9122\n",
      "Epoch 518/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0169 - accuracy: 0.9955 - val_loss: 0.5705 - val_accuracy: 0.9176\n",
      "Epoch 519/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0084 - accuracy: 0.9960 - val_loss: 0.5587 - val_accuracy: 0.9122\n",
      "Epoch 520/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0120 - accuracy: 0.9960 - val_loss: 0.5622 - val_accuracy: 0.9176\n",
      "Epoch 521/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0092 - accuracy: 0.9973 - val_loss: 0.5721 - val_accuracy: 0.9122\n",
      "Epoch 522/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0131 - accuracy: 0.9951 - val_loss: 0.5746 - val_accuracy: 0.9176\n",
      "Epoch 523/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0083 - accuracy: 0.9969 - val_loss: 0.5724 - val_accuracy: 0.9211\n",
      "Epoch 524/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.5885 - val_accuracy: 0.9211\n",
      "Epoch 525/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0133 - accuracy: 0.9955 - val_loss: 0.5965 - val_accuracy: 0.9211\n",
      "Epoch 526/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0152 - accuracy: 0.9969 - val_loss: 0.6000 - val_accuracy: 0.9229\n",
      "Epoch 527/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0101 - accuracy: 0.9951 - val_loss: 0.5748 - val_accuracy: 0.9265\n",
      "Epoch 528/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.5595 - val_accuracy: 0.9247\n",
      "Epoch 529/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0112 - accuracy: 0.9964 - val_loss: 0.5678 - val_accuracy: 0.9229\n",
      "Epoch 530/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.5844 - val_accuracy: 0.9265\n",
      "Epoch 531/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0088 - accuracy: 0.9964 - val_loss: 0.5795 - val_accuracy: 0.9211\n",
      "Epoch 532/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0061 - accuracy: 0.9987 - val_loss: 0.5791 - val_accuracy: 0.9211\n",
      "Epoch 533/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0098 - accuracy: 0.9960 - val_loss: 0.5728 - val_accuracy: 0.9211\n",
      "Epoch 534/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0095 - accuracy: 0.9955 - val_loss: 0.5597 - val_accuracy: 0.9247\n",
      "Epoch 535/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.5660 - val_accuracy: 0.9283\n",
      "Epoch 536/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0158 - accuracy: 0.9951 - val_loss: 0.5525 - val_accuracy: 0.9265\n",
      "Epoch 537/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0089 - accuracy: 0.9964 - val_loss: 0.5513 - val_accuracy: 0.9229\n",
      "Epoch 538/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.5730 - val_accuracy: 0.9247\n",
      "Epoch 539/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0083 - accuracy: 0.9987 - val_loss: 0.5544 - val_accuracy: 0.9211\n",
      "Epoch 540/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0075 - accuracy: 0.9973 - val_loss: 0.5442 - val_accuracy: 0.9229\n",
      "Epoch 541/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0125 - accuracy: 0.9955 - val_loss: 0.5529 - val_accuracy: 0.9265\n",
      "Epoch 542/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0077 - accuracy: 0.9982 - val_loss: 0.5590 - val_accuracy: 0.9194\n",
      "Epoch 543/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0100 - accuracy: 0.9964 - val_loss: 0.5289 - val_accuracy: 0.9283\n",
      "Epoch 544/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0047 - accuracy: 0.9987 - val_loss: 0.5314 - val_accuracy: 0.9265\n",
      "Epoch 545/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0103 - accuracy: 0.9973 - val_loss: 0.5610 - val_accuracy: 0.9265\n",
      "Epoch 546/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0059 - accuracy: 0.9982 - val_loss: 0.5601 - val_accuracy: 0.9247\n",
      "Epoch 547/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0071 - accuracy: 0.9987 - val_loss: 0.5487 - val_accuracy: 0.9283\n",
      "Epoch 548/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0083 - accuracy: 0.9969 - val_loss: 0.5308 - val_accuracy: 0.9301\n",
      "Epoch 549/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0059 - accuracy: 0.9987 - val_loss: 0.5400 - val_accuracy: 0.9247\n",
      "Epoch 550/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0076 - accuracy: 0.9987 - val_loss: 0.5519 - val_accuracy: 0.9229\n",
      "Epoch 551/1000\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0071 - accuracy: 0.9991 - val_loss: 0.5444 - val_accuracy: 0.9319\n",
      "Epoch 552/1000\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0083 - accuracy: 0.9978 - val_loss: 0.5707 - val_accuracy: 0.9247\n",
      "Epoch 553/1000\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.5720 - val_accuracy: 0.9194\n",
      "Epoch 554/1000\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0067 - accuracy: 0.9982 - val_loss: 0.5478 - val_accuracy: 0.9211\n",
      "Epoch 555/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0064 - accuracy: 0.9987 - val_loss: 0.5346 - val_accuracy: 0.9229\n",
      "Epoch 556/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.5487 - val_accuracy: 0.9247\n",
      "Epoch 557/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0084 - accuracy: 0.9978 - val_loss: 0.5657 - val_accuracy: 0.9176\n",
      "Epoch 558/1000\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0081 - accuracy: 0.9964 - val_loss: 0.5635 - val_accuracy: 0.9229\n",
      "Epoch 559/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0062 - accuracy: 0.9978 - val_loss: 0.5914 - val_accuracy: 0.9211\n",
      "Epoch 560/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0088 - accuracy: 0.9973 - val_loss: 0.5821 - val_accuracy: 0.9229\n",
      "Epoch 561/1000\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.5882 - val_accuracy: 0.9283\n",
      "Epoch 562/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0081 - accuracy: 0.9969 - val_loss: 0.5844 - val_accuracy: 0.9283\n",
      "Epoch 563/1000\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0078 - accuracy: 0.9973 - val_loss: 0.5803 - val_accuracy: 0.9247\n",
      "Epoch 564/1000\n",
      "5/5 [==============================] - 0s 28ms/step - loss: 0.0079 - accuracy: 0.9964 - val_loss: 0.5699 - val_accuracy: 0.9247\n",
      "Epoch 565/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.5619 - val_accuracy: 0.9247\n",
      "Epoch 566/1000\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0076 - accuracy: 0.9964 - val_loss: 0.5540 - val_accuracy: 0.9301\n",
      "Epoch 567/1000\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0060 - accuracy: 0.9978 - val_loss: 0.5571 - val_accuracy: 0.9301\n",
      "Epoch 568/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0082 - accuracy: 0.9969 - val_loss: 0.5829 - val_accuracy: 0.9229\n",
      "Epoch 569/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0130 - accuracy: 0.9955 - val_loss: 0.5929 - val_accuracy: 0.9247\n",
      "Epoch 570/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0114 - accuracy: 0.9964 - val_loss: 0.5902 - val_accuracy: 0.9229\n",
      "Epoch 571/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0115 - accuracy: 0.9955 - val_loss: 0.5925 - val_accuracy: 0.9247\n",
      "Epoch 572/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0071 - accuracy: 0.9964 - val_loss: 0.5949 - val_accuracy: 0.9247\n",
      "Epoch 573/1000\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 0.5728 - val_accuracy: 0.9283\n",
      "Epoch 574/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0110 - accuracy: 0.9964 - val_loss: 0.5805 - val_accuracy: 0.9229\n",
      "Epoch 575/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0081 - accuracy: 0.9964 - val_loss: 0.5841 - val_accuracy: 0.9265\n",
      "Epoch 576/1000\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0145 - accuracy: 0.9978 - val_loss: 0.6127 - val_accuracy: 0.9301\n",
      "Epoch 577/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0098 - accuracy: 0.9978 - val_loss: 0.5944 - val_accuracy: 0.9247\n",
      "Epoch 578/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0071 - accuracy: 0.9964 - val_loss: 0.5853 - val_accuracy: 0.9247\n",
      "Epoch 579/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0060 - accuracy: 0.9987 - val_loss: 0.5706 - val_accuracy: 0.9301\n",
      "Epoch 580/1000\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0088 - accuracy: 0.9973 - val_loss: 0.5811 - val_accuracy: 0.9283\n",
      "Epoch 581/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0082 - accuracy: 0.9991 - val_loss: 0.6189 - val_accuracy: 0.9211\n",
      "Epoch 582/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0079 - accuracy: 0.9964 - val_loss: 0.5959 - val_accuracy: 0.9229\n",
      "Epoch 583/1000\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.6045 - val_accuracy: 0.9229\n",
      "Epoch 584/1000\n",
      "5/5 [==============================] - 0s 26ms/step - loss: 0.0113 - accuracy: 0.9969 - val_loss: 0.6294 - val_accuracy: 0.9265\n",
      "Epoch 585/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.6284 - val_accuracy: 0.9229\n",
      "Epoch 586/1000\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0127 - accuracy: 0.9973 - val_loss: 0.6093 - val_accuracy: 0.9176\n",
      "Epoch 587/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0104 - accuracy: 0.9987 - val_loss: 0.5878 - val_accuracy: 0.9211\n",
      "Epoch 588/1000\n",
      "5/5 [==============================] - 0s 24ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.5942 - val_accuracy: 0.9176\n",
      "Epoch 589/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0114 - accuracy: 0.9969 - val_loss: 0.5830 - val_accuracy: 0.9229\n",
      "Epoch 590/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0141 - accuracy: 0.9942 - val_loss: 0.5724 - val_accuracy: 0.9229\n",
      "Epoch 591/1000\n",
      "5/5 [==============================] - 0s 25ms/step - loss: 0.0108 - accuracy: 0.9964 - val_loss: 0.6047 - val_accuracy: 0.9229\n",
      "Epoch 592/1000\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.0154 - accuracy: 0.9951 - val_loss: 0.5993 - val_accuracy: 0.9122\n",
      "Epoch 593/1000\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0091 - accuracy: 0.9960 - val_loss: 0.6131 - val_accuracy: 0.9158\n",
      "Epoch 594/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0111 - accuracy: 0.9960 - val_loss: 0.5668 - val_accuracy: 0.9194\n",
      "Epoch 595/1000\n",
      "5/5 [==============================] - 0s 22ms/step - loss: 0.0094 - accuracy: 0.9964 - val_loss: 0.5692 - val_accuracy: 0.9194\n",
      "Epoch 596/1000\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.0122 - accuracy: 0.9960 - val_loss: 0.5770 - val_accuracy: 0.9229\n",
      "43/43 - 0s - loss: 0.5881 - accuracy: 0.9185 - 106ms/epoch - 2ms/step\n"
     ]
    }
   ],
   "source": [
    "input_shape = (5, 5, 1)\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=100)\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=input_shape),\n",
    "    Conv2D(filters=100, kernel_size=[2,2]), \n",
    "    Activation(\"relu\"),\n",
    "    Conv2D(filters=30, kernel_size=[2,2]),\n",
    "    Activation(\"elu\"),\n",
    "    Conv2D(filters=20, kernel_size=[2,2]),\n",
    "    Activation(\"elu\"),\n",
    "    Dense(60),\n",
    "    Activation(\"elu\"),\n",
    "    Dropout(rate=0.1),\n",
    "    Dense(10),\n",
    "    Activation(\"elu\"),\n",
    "    Dropout(rate=0.2),\n",
    "    Flatten(),\n",
    "    Dense(2)\n",
    "])\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate=1e-2,\n",
    "    decay_steps=500,\n",
    "    end_learning_rate=1e-3,\n",
    "    power=0.5)\n",
    "\n",
    "model.compile(\n",
    "    loss = keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    optimizer = keras.optimizers.Adam(lr_schedule),\n",
    "    metrics = [\"accuracy\"],\n",
    ")\n",
    "history = model.fit(X_train, y_train, batch_size=500, epochs=1000, validation_split=0.2, verbose=True, callbacks=[callback])\n",
    "test_scores = model.evaluate(X_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afc612b",
   "metadata": {},
   "source": [
    "Our plot shows that we start seeing accuracies of over $0.9$ at around epoch $100$. After this the accuracies don't improve much. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1cc8f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fdb4b7",
   "metadata": {},
   "source": [
    "## The same Keras model with $A_6$ and $D_6$ <a class=\"anchor\" id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174abe77",
   "metadata": {},
   "source": [
    "Now we look at the $b$-matrices for $A_6$ and $D_6$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e74f44dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A6\n",
    "\n",
    "with open('cluster_data_A6_depth_6.csv') as fp:\n",
    "    reader = csv.reader(fp, delimiter=\",\", quotechar='\"')\n",
    "    data = [row for row in reader]\n",
    "    \n",
    "data=data[0]\n",
    "cluster_type = data[0]\n",
    "data = [np.array(np.matrix(data[i])).ravel() for i in range(1, len(data))]                                                                           \n",
    "data = [np.append(i, np.array([1, 0])) for i in data]\n",
    "A6_data = data\n",
    "A6_array = A6_data[0]\n",
    "for i in range(1, len(A6_data)):\n",
    "    A6_array = np.vstack([A6_array, A6_data[i]])\n",
    "    \n",
    "# D6\n",
    "\n",
    "with open('cluster_data_D6_depth_6.csv') as fp:\n",
    "    reader = csv.reader(fp, delimiter=\",\", quotechar='\"')\n",
    "    data = [row for row in reader]\n",
    "    \n",
    "data=data[0]\n",
    "cluster_type = data[0]\n",
    "data = [np.array(np.matrix(data[i])).ravel() for i in range(1, len(data))]                                                                         \n",
    "data = [np.append(i, np.array([0, 1])) for i in data]\n",
    "D6_data = data\n",
    "D6_array = D6_data[0]\n",
    "for i in range(1, len(D6_data)):\n",
    "    D6_array = np.vstack([D6_array, D6_data[i]])\n",
    "\n",
    "# Features, targets\n",
    "X = np.vstack([A6_array[:,:-2], D6_array[:,:-2]])\n",
    "\n",
    "# Reshape as matrices\n",
    "Z = np.array([np.resize(X[0], (6,6))])\n",
    "for i in range(1, len(X)):\n",
    "    new = np.resize(X[i], (6,6))\n",
    "    new2 = np.array([new])\n",
    "    Z = np.append(Z, new2, axis=0)\n",
    "\n",
    "X = Z\n",
    "y = np.vstack([A6_array[:,-2:], D6_array[:,-2:]])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a6d692",
   "metadata": {},
   "source": [
    "We use a similar model to before, except with a different arrangement of dense layers. We run this for a long time but we do get very high accuracies, exceeding $0.93$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccb37dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "21/21 [==============================] - 2s 66ms/step - loss: 0.6694 - accuracy: 0.5844 - val_loss: 0.6592 - val_accuracy: 0.5958\n",
      "Epoch 2/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.6533 - accuracy: 0.6192 - val_loss: 0.6914 - val_accuracy: 0.5942\n",
      "Epoch 3/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.6805 - accuracy: 0.5778 - val_loss: 0.6623 - val_accuracy: 0.5906\n",
      "Epoch 4/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.6623 - accuracy: 0.6052 - val_loss: 0.6112 - val_accuracy: 0.6705\n",
      "Epoch 5/1000\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.6225 - accuracy: 0.6478 - val_loss: 0.5777 - val_accuracy: 0.6929\n",
      "Epoch 6/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.5936 - accuracy: 0.6758 - val_loss: 0.7544 - val_accuracy: 0.5242\n",
      "Epoch 7/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.6997 - accuracy: 0.5676 - val_loss: 0.6562 - val_accuracy: 0.6086\n",
      "Epoch 8/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.6609 - accuracy: 0.5965 - val_loss: 0.8088 - val_accuracy: 0.5078\n",
      "Epoch 9/1000\n",
      "21/21 [==============================] - 1s 52ms/step - loss: 0.6994 - accuracy: 0.5495 - val_loss: 0.6656 - val_accuracy: 0.5902\n",
      "Epoch 10/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.6384 - accuracy: 0.6278 - val_loss: 0.6166 - val_accuracy: 0.6649\n",
      "Epoch 11/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.6020 - accuracy: 0.6691 - val_loss: 0.6162 - val_accuracy: 0.6509\n",
      "Epoch 12/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.6130 - accuracy: 0.6597 - val_loss: 0.5839 - val_accuracy: 0.6633\n",
      "Epoch 13/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.5877 - accuracy: 0.6975 - val_loss: 0.5429 - val_accuracy: 0.7417\n",
      "Epoch 14/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.5450 - accuracy: 0.7221 - val_loss: 0.8345 - val_accuracy: 0.5646\n",
      "Epoch 15/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.6695 - accuracy: 0.6304 - val_loss: 0.5846 - val_accuracy: 0.6725\n",
      "Epoch 16/1000\n",
      "21/21 [==============================] - 1s 54ms/step - loss: 0.5808 - accuracy: 0.6906 - val_loss: 0.5484 - val_accuracy: 0.7269\n",
      "Epoch 17/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.5571 - accuracy: 0.7089 - val_loss: 0.5370 - val_accuracy: 0.7285\n",
      "Epoch 18/1000\n",
      "21/21 [==============================] - 1s 52ms/step - loss: 0.5548 - accuracy: 0.7105 - val_loss: 0.5401 - val_accuracy: 0.7337\n",
      "Epoch 19/1000\n",
      "21/21 [==============================] - 1s 57ms/step - loss: 0.6054 - accuracy: 0.6863 - val_loss: 0.5521 - val_accuracy: 0.7081\n",
      "Epoch 20/1000\n",
      "21/21 [==============================] - 2s 80ms/step - loss: 0.5553 - accuracy: 0.7188 - val_loss: 0.5172 - val_accuracy: 0.7393\n",
      "Epoch 21/1000\n",
      "21/21 [==============================] - 1s 59ms/step - loss: 0.5183 - accuracy: 0.7371 - val_loss: 0.4919 - val_accuracy: 0.7517\n",
      "Epoch 22/1000\n",
      "21/21 [==============================] - 1s 61ms/step - loss: 0.4964 - accuracy: 0.7489 - val_loss: 0.4839 - val_accuracy: 0.7605\n",
      "Epoch 23/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.4969 - accuracy: 0.7535 - val_loss: 0.4688 - val_accuracy: 0.7737\n",
      "Epoch 24/1000\n",
      "21/21 [==============================] - 1s 61ms/step - loss: 0.4882 - accuracy: 0.7608 - val_loss: 0.4698 - val_accuracy: 0.7665\n",
      "Epoch 25/1000\n",
      "21/21 [==============================] - 2s 72ms/step - loss: 0.4762 - accuracy: 0.7657 - val_loss: 0.4602 - val_accuracy: 0.7781\n",
      "Epoch 26/1000\n",
      "21/21 [==============================] - 1s 57ms/step - loss: 0.4747 - accuracy: 0.7675 - val_loss: 0.4566 - val_accuracy: 0.7809\n",
      "Epoch 27/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.4686 - accuracy: 0.7679 - val_loss: 0.4540 - val_accuracy: 0.7769\n",
      "Epoch 28/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.4682 - accuracy: 0.7691 - val_loss: 0.4526 - val_accuracy: 0.7797\n",
      "Epoch 29/1000\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.4696 - accuracy: 0.7727 - val_loss: 0.4588 - val_accuracy: 0.7769\n",
      "Epoch 30/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.4612 - accuracy: 0.7758 - val_loss: 0.4520 - val_accuracy: 0.7853\n",
      "Epoch 31/1000\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.4699 - accuracy: 0.7659 - val_loss: 0.4487 - val_accuracy: 0.7821\n",
      "Epoch 32/1000\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.4668 - accuracy: 0.7719 - val_loss: 0.4420 - val_accuracy: 0.7873\n",
      "Epoch 33/1000\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.4680 - accuracy: 0.7692 - val_loss: 0.4419 - val_accuracy: 0.7941\n",
      "Epoch 34/1000\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.4737 - accuracy: 0.7645 - val_loss: 0.4529 - val_accuracy: 0.7817\n",
      "Epoch 35/1000\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.4793 - accuracy: 0.7645 - val_loss: 0.4628 - val_accuracy: 0.7817\n",
      "Epoch 36/1000\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.4650 - accuracy: 0.7744 - val_loss: 0.4465 - val_accuracy: 0.7901\n",
      "Epoch 37/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.4596 - accuracy: 0.7790 - val_loss: 0.4425 - val_accuracy: 0.7917\n",
      "Epoch 38/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.4636 - accuracy: 0.7755 - val_loss: 0.4481 - val_accuracy: 0.7921\n",
      "Epoch 39/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.4599 - accuracy: 0.7734 - val_loss: 0.4428 - val_accuracy: 0.7965\n",
      "Epoch 40/1000\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.4548 - accuracy: 0.7759 - val_loss: 0.4319 - val_accuracy: 0.7945\n",
      "Epoch 41/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.4576 - accuracy: 0.7778 - val_loss: 0.4338 - val_accuracy: 0.7981\n",
      "Epoch 42/1000\n",
      "21/21 [==============================] - 1s 54ms/step - loss: 0.4454 - accuracy: 0.7811 - val_loss: 0.4260 - val_accuracy: 0.7997\n",
      "Epoch 43/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.4403 - accuracy: 0.7896 - val_loss: 0.4260 - val_accuracy: 0.8041\n",
      "Epoch 44/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.4493 - accuracy: 0.7836 - val_loss: 0.4225 - val_accuracy: 0.8105\n",
      "Epoch 45/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.4466 - accuracy: 0.7864 - val_loss: 0.4197 - val_accuracy: 0.8093\n",
      "Epoch 46/1000\n",
      "21/21 [==============================] - 1s 52ms/step - loss: 0.4395 - accuracy: 0.7881 - val_loss: 0.4154 - val_accuracy: 0.8081\n",
      "Epoch 47/1000\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.4411 - accuracy: 0.7906 - val_loss: 0.4140 - val_accuracy: 0.8077\n",
      "Epoch 48/1000\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.4405 - accuracy: 0.7847 - val_loss: 0.4182 - val_accuracy: 0.8053\n",
      "Epoch 49/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.4327 - accuracy: 0.7965 - val_loss: 0.4074 - val_accuracy: 0.8089\n",
      "Epoch 50/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.4256 - accuracy: 0.7981 - val_loss: 0.4057 - val_accuracy: 0.8133\n",
      "Epoch 51/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.4260 - accuracy: 0.7964 - val_loss: 0.4026 - val_accuracy: 0.8157\n",
      "Epoch 52/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.4340 - accuracy: 0.7928 - val_loss: 0.4063 - val_accuracy: 0.8145\n",
      "Epoch 53/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.4287 - accuracy: 0.7919 - val_loss: 0.4079 - val_accuracy: 0.8105\n",
      "Epoch 54/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.4214 - accuracy: 0.7995 - val_loss: 0.4054 - val_accuracy: 0.8145\n",
      "Epoch 55/1000\n",
      "21/21 [==============================] - 1s 65ms/step - loss: 0.4207 - accuracy: 0.7992 - val_loss: 0.3959 - val_accuracy: 0.8189\n",
      "Epoch 56/1000\n",
      "21/21 [==============================] - 2s 73ms/step - loss: 0.4168 - accuracy: 0.8049 - val_loss: 0.3925 - val_accuracy: 0.8145\n",
      "Epoch 57/1000\n",
      "21/21 [==============================] - 1s 53ms/step - loss: 0.4163 - accuracy: 0.8041 - val_loss: 0.3909 - val_accuracy: 0.8225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.4131 - accuracy: 0.8057 - val_loss: 0.4003 - val_accuracy: 0.8073\n",
      "Epoch 59/1000\n",
      "21/21 [==============================] - 1s 58ms/step - loss: 0.4350 - accuracy: 0.7933 - val_loss: 0.3968 - val_accuracy: 0.8145\n",
      "Epoch 60/1000\n",
      "21/21 [==============================] - 1s 52ms/step - loss: 0.4171 - accuracy: 0.8035 - val_loss: 0.3890 - val_accuracy: 0.8193\n",
      "Epoch 61/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.4108 - accuracy: 0.8101 - val_loss: 0.3878 - val_accuracy: 0.8209\n",
      "Epoch 62/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.4262 - accuracy: 0.7956 - val_loss: 0.4059 - val_accuracy: 0.8021\n",
      "Epoch 63/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.4147 - accuracy: 0.8034 - val_loss: 0.3909 - val_accuracy: 0.8181\n",
      "Epoch 64/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.4056 - accuracy: 0.8071 - val_loss: 0.3860 - val_accuracy: 0.8197\n",
      "Epoch 65/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.4135 - accuracy: 0.8060 - val_loss: 0.3821 - val_accuracy: 0.8293\n",
      "Epoch 66/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.3986 - accuracy: 0.8127 - val_loss: 0.3777 - val_accuracy: 0.8257\n",
      "Epoch 67/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.3990 - accuracy: 0.8150 - val_loss: 0.3754 - val_accuracy: 0.8265\n",
      "Epoch 68/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.4045 - accuracy: 0.8059 - val_loss: 0.3824 - val_accuracy: 0.8217\n",
      "Epoch 69/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.4227 - accuracy: 0.8015 - val_loss: 0.3945 - val_accuracy: 0.8201\n",
      "Epoch 70/1000\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 0.4133 - accuracy: 0.8041 - val_loss: 0.3780 - val_accuracy: 0.8325\n",
      "Epoch 71/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.4011 - accuracy: 0.8132 - val_loss: 0.3761 - val_accuracy: 0.8313\n",
      "Epoch 72/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.3978 - accuracy: 0.8144 - val_loss: 0.3758 - val_accuracy: 0.8341\n",
      "Epoch 73/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.3971 - accuracy: 0.8137 - val_loss: 0.3814 - val_accuracy: 0.8225\n",
      "Epoch 74/1000\n",
      "21/21 [==============================] - 1s 52ms/step - loss: 0.4187 - accuracy: 0.7983 - val_loss: 0.3814 - val_accuracy: 0.8245\n",
      "Epoch 75/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.3991 - accuracy: 0.8096 - val_loss: 0.3751 - val_accuracy: 0.8273\n",
      "Epoch 76/1000\n",
      "21/21 [==============================] - 1s 52ms/step - loss: 0.3995 - accuracy: 0.8132 - val_loss: 0.3723 - val_accuracy: 0.8333\n",
      "Epoch 77/1000\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 0.4002 - accuracy: 0.8152 - val_loss: 0.3748 - val_accuracy: 0.8345\n",
      "Epoch 78/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.3954 - accuracy: 0.8169 - val_loss: 0.3728 - val_accuracy: 0.8365\n",
      "Epoch 79/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.3914 - accuracy: 0.8171 - val_loss: 0.3686 - val_accuracy: 0.8353\n",
      "Epoch 80/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.4056 - accuracy: 0.8100 - val_loss: 0.3701 - val_accuracy: 0.8341\n",
      "Epoch 81/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.3894 - accuracy: 0.8201 - val_loss: 0.3638 - val_accuracy: 0.8429\n",
      "Epoch 82/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.3852 - accuracy: 0.8261 - val_loss: 0.3616 - val_accuracy: 0.8497\n",
      "Epoch 83/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.3883 - accuracy: 0.8237 - val_loss: 0.3616 - val_accuracy: 0.8453\n",
      "Epoch 84/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.3832 - accuracy: 0.8277 - val_loss: 0.3663 - val_accuracy: 0.8369\n",
      "Epoch 85/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.3838 - accuracy: 0.8262 - val_loss: 0.3657 - val_accuracy: 0.8349\n",
      "Epoch 86/1000\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 0.4104 - accuracy: 0.8109 - val_loss: 0.3733 - val_accuracy: 0.8301\n",
      "Epoch 87/1000\n",
      "21/21 [==============================] - 1s 52ms/step - loss: 0.3963 - accuracy: 0.8184 - val_loss: 0.3660 - val_accuracy: 0.8369\n",
      "Epoch 88/1000\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 0.3831 - accuracy: 0.8234 - val_loss: 0.3599 - val_accuracy: 0.8401\n",
      "Epoch 89/1000\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 0.3751 - accuracy: 0.8276 - val_loss: 0.3557 - val_accuracy: 0.8445\n",
      "Epoch 90/1000\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 0.3734 - accuracy: 0.8276 - val_loss: 0.3535 - val_accuracy: 0.8465\n",
      "Epoch 91/1000\n",
      "21/21 [==============================] - 1s 52ms/step - loss: 0.3901 - accuracy: 0.8173 - val_loss: 0.3597 - val_accuracy: 0.8401\n",
      "Epoch 92/1000\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 0.3749 - accuracy: 0.8327 - val_loss: 0.3533 - val_accuracy: 0.8445\n",
      "Epoch 93/1000\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 0.3822 - accuracy: 0.8274 - val_loss: 0.3534 - val_accuracy: 0.8445\n",
      "Epoch 94/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.3717 - accuracy: 0.8324 - val_loss: 0.3471 - val_accuracy: 0.8501\n",
      "Epoch 95/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.3624 - accuracy: 0.8383 - val_loss: 0.3453 - val_accuracy: 0.8525\n",
      "Epoch 96/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.3912 - accuracy: 0.8190 - val_loss: 0.3568 - val_accuracy: 0.8425\n",
      "Epoch 97/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.3775 - accuracy: 0.8282 - val_loss: 0.3477 - val_accuracy: 0.8517\n",
      "Epoch 98/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.3641 - accuracy: 0.8379 - val_loss: 0.3439 - val_accuracy: 0.8561\n",
      "Epoch 99/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.3656 - accuracy: 0.8366 - val_loss: 0.3429 - val_accuracy: 0.8525\n",
      "Epoch 100/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.3714 - accuracy: 0.8319 - val_loss: 0.3484 - val_accuracy: 0.8501\n",
      "Epoch 101/1000\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 0.3693 - accuracy: 0.8346 - val_loss: 0.3424 - val_accuracy: 0.8577\n",
      "Epoch 102/1000\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 0.3623 - accuracy: 0.8368 - val_loss: 0.3441 - val_accuracy: 0.8517\n",
      "Epoch 103/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.3782 - accuracy: 0.8256 - val_loss: 0.3459 - val_accuracy: 0.8485\n",
      "Epoch 104/1000\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 0.3689 - accuracy: 0.8340 - val_loss: 0.3365 - val_accuracy: 0.8573\n",
      "Epoch 105/1000\n",
      "21/21 [==============================] - 1s 52ms/step - loss: 0.3547 - accuracy: 0.8454 - val_loss: 0.3359 - val_accuracy: 0.8557\n",
      "Epoch 106/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.3832 - accuracy: 0.8264 - val_loss: 0.3370 - val_accuracy: 0.8529\n",
      "Epoch 107/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.3654 - accuracy: 0.8374 - val_loss: 0.3307 - val_accuracy: 0.8645\n",
      "Epoch 108/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.3524 - accuracy: 0.8427 - val_loss: 0.3283 - val_accuracy: 0.8633\n",
      "Epoch 109/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.3512 - accuracy: 0.8408 - val_loss: 0.3260 - val_accuracy: 0.8621\n",
      "Epoch 110/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.3668 - accuracy: 0.8325 - val_loss: 0.3380 - val_accuracy: 0.8557\n",
      "Epoch 111/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.3680 - accuracy: 0.8294 - val_loss: 0.3413 - val_accuracy: 0.8505\n",
      "Epoch 112/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.3699 - accuracy: 0.8297 - val_loss: 0.3398 - val_accuracy: 0.8521\n",
      "Epoch 113/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.3627 - accuracy: 0.8371 - val_loss: 0.3311 - val_accuracy: 0.8597\n",
      "Epoch 114/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.3689 - accuracy: 0.8313 - val_loss: 0.3378 - val_accuracy: 0.8569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.3721 - accuracy: 0.8310 - val_loss: 0.3354 - val_accuracy: 0.8565\n",
      "Epoch 116/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.3595 - accuracy: 0.8400 - val_loss: 0.3261 - val_accuracy: 0.8637\n",
      "Epoch 117/1000\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 0.3514 - accuracy: 0.8430 - val_loss: 0.3239 - val_accuracy: 0.8641\n",
      "Epoch 118/1000\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 0.3514 - accuracy: 0.8443 - val_loss: 0.3224 - val_accuracy: 0.8685\n",
      "Epoch 119/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.3513 - accuracy: 0.8425 - val_loss: 0.3193 - val_accuracy: 0.8725\n",
      "Epoch 120/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.3437 - accuracy: 0.8445 - val_loss: 0.3218 - val_accuracy: 0.8729\n",
      "Epoch 121/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.3718 - accuracy: 0.8280 - val_loss: 0.3361 - val_accuracy: 0.8533\n",
      "Epoch 122/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.3877 - accuracy: 0.8219 - val_loss: 0.3464 - val_accuracy: 0.8461\n",
      "Epoch 123/1000\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 0.3734 - accuracy: 0.8278 - val_loss: 0.3355 - val_accuracy: 0.8637\n",
      "Epoch 124/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.3762 - accuracy: 0.8270 - val_loss: 0.3336 - val_accuracy: 0.8573\n",
      "Epoch 125/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.3623 - accuracy: 0.8327 - val_loss: 0.3377 - val_accuracy: 0.8569\n",
      "Epoch 126/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.3479 - accuracy: 0.8397 - val_loss: 0.3211 - val_accuracy: 0.8649\n",
      "Epoch 127/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.3440 - accuracy: 0.8456 - val_loss: 0.3173 - val_accuracy: 0.8713\n",
      "Epoch 128/1000\n",
      "21/21 [==============================] - 1s 62ms/step - loss: 0.3470 - accuracy: 0.8481 - val_loss: 0.3192 - val_accuracy: 0.8669\n",
      "Epoch 129/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.3436 - accuracy: 0.8474 - val_loss: 0.3173 - val_accuracy: 0.8657\n",
      "Epoch 130/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.3691 - accuracy: 0.8267 - val_loss: 0.3296 - val_accuracy: 0.8593\n",
      "Epoch 131/1000\n",
      "21/21 [==============================] - 1s 54ms/step - loss: 0.3495 - accuracy: 0.8425 - val_loss: 0.3173 - val_accuracy: 0.8669\n",
      "Epoch 132/1000\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 0.3483 - accuracy: 0.8435 - val_loss: 0.3169 - val_accuracy: 0.8629\n",
      "Epoch 133/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.3409 - accuracy: 0.8472 - val_loss: 0.3152 - val_accuracy: 0.8673\n",
      "Epoch 134/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.3679 - accuracy: 0.8312 - val_loss: 0.3264 - val_accuracy: 0.8685\n",
      "Epoch 135/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.3388 - accuracy: 0.8504 - val_loss: 0.3143 - val_accuracy: 0.8729\n",
      "Epoch 136/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.3504 - accuracy: 0.8439 - val_loss: 0.3337 - val_accuracy: 0.8565\n",
      "Epoch 137/1000\n",
      "21/21 [==============================] - 1s 52ms/step - loss: 0.4264 - accuracy: 0.8009 - val_loss: 0.3878 - val_accuracy: 0.8241\n",
      "Epoch 138/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.3761 - accuracy: 0.8251 - val_loss: 0.3359 - val_accuracy: 0.8609\n",
      "Epoch 139/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.3775 - accuracy: 0.8229 - val_loss: 0.3274 - val_accuracy: 0.8613\n",
      "Epoch 140/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.3794 - accuracy: 0.8221 - val_loss: 0.3384 - val_accuracy: 0.8561\n",
      "Epoch 141/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.3659 - accuracy: 0.8334 - val_loss: 0.3358 - val_accuracy: 0.8565\n",
      "Epoch 142/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.3509 - accuracy: 0.8440 - val_loss: 0.3198 - val_accuracy: 0.8737\n",
      "Epoch 143/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.3429 - accuracy: 0.8461 - val_loss: 0.3159 - val_accuracy: 0.8669\n",
      "Epoch 144/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.3430 - accuracy: 0.8489 - val_loss: 0.3228 - val_accuracy: 0.8669\n",
      "Epoch 145/1000\n",
      "21/21 [==============================] - 1s 64ms/step - loss: 0.3495 - accuracy: 0.8446 - val_loss: 0.3366 - val_accuracy: 0.8609\n",
      "Epoch 146/1000\n",
      "21/21 [==============================] - 1s 64ms/step - loss: 0.3722 - accuracy: 0.8298 - val_loss: 0.3233 - val_accuracy: 0.8589\n",
      "Epoch 147/1000\n",
      "21/21 [==============================] - 1s 68ms/step - loss: 0.3355 - accuracy: 0.8544 - val_loss: 0.3125 - val_accuracy: 0.8717\n",
      "Epoch 148/1000\n",
      "21/21 [==============================] - 1s 58ms/step - loss: 0.3317 - accuracy: 0.8551 - val_loss: 0.3072 - val_accuracy: 0.8788\n",
      "Epoch 149/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.3319 - accuracy: 0.8585 - val_loss: 0.3059 - val_accuracy: 0.8776\n",
      "Epoch 150/1000\n",
      "21/21 [==============================] - 1s 57ms/step - loss: 0.3409 - accuracy: 0.8479 - val_loss: 0.3196 - val_accuracy: 0.8681\n",
      "Epoch 151/1000\n",
      "21/21 [==============================] - 1s 59ms/step - loss: 0.3657 - accuracy: 0.8305 - val_loss: 0.3355 - val_accuracy: 0.8609\n",
      "Epoch 152/1000\n",
      "21/21 [==============================] - 1s 52ms/step - loss: 0.3483 - accuracy: 0.8490 - val_loss: 0.3107 - val_accuracy: 0.8705\n",
      "Epoch 153/1000\n",
      "21/21 [==============================] - 1s 59ms/step - loss: 0.3368 - accuracy: 0.8539 - val_loss: 0.3081 - val_accuracy: 0.8729\n",
      "Epoch 154/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.3309 - accuracy: 0.8524 - val_loss: 0.3014 - val_accuracy: 0.8808\n",
      "Epoch 155/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.3333 - accuracy: 0.8497 - val_loss: 0.3027 - val_accuracy: 0.8800\n",
      "Epoch 156/1000\n",
      "21/21 [==============================] - 1s 59ms/step - loss: 0.3269 - accuracy: 0.8562 - val_loss: 0.3020 - val_accuracy: 0.8760\n",
      "Epoch 157/1000\n",
      "21/21 [==============================] - 1s 52ms/step - loss: 0.3308 - accuracy: 0.8536 - val_loss: 0.3072 - val_accuracy: 0.8764\n",
      "Epoch 158/1000\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 0.3234 - accuracy: 0.8575 - val_loss: 0.2979 - val_accuracy: 0.8824\n",
      "Epoch 159/1000\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.3327 - accuracy: 0.8527 - val_loss: 0.3015 - val_accuracy: 0.8836\n",
      "Epoch 160/1000\n",
      "21/21 [==============================] - 1s 55ms/step - loss: 0.3278 - accuracy: 0.8555 - val_loss: 0.3083 - val_accuracy: 0.8729\n",
      "Epoch 161/1000\n",
      "21/21 [==============================] - 1s 54ms/step - loss: 0.3682 - accuracy: 0.8338 - val_loss: 0.3289 - val_accuracy: 0.8585\n",
      "Epoch 162/1000\n",
      "21/21 [==============================] - 1s 52ms/step - loss: 0.3444 - accuracy: 0.8483 - val_loss: 0.3092 - val_accuracy: 0.8772\n",
      "Epoch 163/1000\n",
      "21/21 [==============================] - 1s 54ms/step - loss: 0.3346 - accuracy: 0.8540 - val_loss: 0.3123 - val_accuracy: 0.8745\n",
      "Epoch 164/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.3285 - accuracy: 0.8538 - val_loss: 0.3014 - val_accuracy: 0.8800\n",
      "Epoch 165/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.3279 - accuracy: 0.8552 - val_loss: 0.2957 - val_accuracy: 0.8832\n",
      "Epoch 166/1000\n",
      "21/21 [==============================] - 1s 55ms/step - loss: 0.3163 - accuracy: 0.8678 - val_loss: 0.2935 - val_accuracy: 0.8860\n",
      "Epoch 167/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.3196 - accuracy: 0.8615 - val_loss: 0.2920 - val_accuracy: 0.8840\n",
      "Epoch 168/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.3160 - accuracy: 0.8618 - val_loss: 0.2974 - val_accuracy: 0.8848\n",
      "Epoch 169/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.3563 - accuracy: 0.8384 - val_loss: 0.3134 - val_accuracy: 0.8617\n",
      "Epoch 170/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.3261 - accuracy: 0.8520 - val_loss: 0.2993 - val_accuracy: 0.8768\n",
      "Epoch 171/1000\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.3221 - accuracy: 0.8629 - val_loss: 0.2964 - val_accuracy: 0.8776\n",
      "Epoch 172/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.3144 - accuracy: 0.8627 - val_loss: 0.2888 - val_accuracy: 0.8844\n",
      "Epoch 173/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.3250 - accuracy: 0.8582 - val_loss: 0.2894 - val_accuracy: 0.8856\n",
      "Epoch 174/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.3230 - accuracy: 0.8590 - val_loss: 0.2882 - val_accuracy: 0.8824\n",
      "Epoch 175/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.3101 - accuracy: 0.8672 - val_loss: 0.2854 - val_accuracy: 0.8860\n",
      "Epoch 176/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.3120 - accuracy: 0.8665 - val_loss: 0.2847 - val_accuracy: 0.8884\n",
      "Epoch 177/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.3156 - accuracy: 0.8623 - val_loss: 0.2840 - val_accuracy: 0.8896\n",
      "Epoch 178/1000\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 0.3089 - accuracy: 0.8655 - val_loss: 0.2841 - val_accuracy: 0.8896\n",
      "Epoch 179/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.3115 - accuracy: 0.8637 - val_loss: 0.2938 - val_accuracy: 0.8824\n",
      "Epoch 180/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.3090 - accuracy: 0.8643 - val_loss: 0.2877 - val_accuracy: 0.8880\n",
      "Epoch 181/1000\n",
      "21/21 [==============================] - 1s 52ms/step - loss: 0.3185 - accuracy: 0.8621 - val_loss: 0.2892 - val_accuracy: 0.8856\n",
      "Epoch 182/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.3204 - accuracy: 0.8587 - val_loss: 0.2901 - val_accuracy: 0.8852\n",
      "Epoch 183/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.3218 - accuracy: 0.8590 - val_loss: 0.2897 - val_accuracy: 0.8872\n",
      "Epoch 184/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.3169 - accuracy: 0.8608 - val_loss: 0.2852 - val_accuracy: 0.8896\n",
      "Epoch 185/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.3127 - accuracy: 0.8650 - val_loss: 0.2823 - val_accuracy: 0.8900\n",
      "Epoch 186/1000\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.3047 - accuracy: 0.8651 - val_loss: 0.2842 - val_accuracy: 0.8872\n",
      "Epoch 187/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.3052 - accuracy: 0.8668 - val_loss: 0.2818 - val_accuracy: 0.8864\n",
      "Epoch 188/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.3042 - accuracy: 0.8662 - val_loss: 0.2859 - val_accuracy: 0.8812\n",
      "Epoch 189/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.3181 - accuracy: 0.8616 - val_loss: 0.2948 - val_accuracy: 0.8792\n",
      "Epoch 190/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.3105 - accuracy: 0.8646 - val_loss: 0.2934 - val_accuracy: 0.8749\n",
      "Epoch 191/1000\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.3242 - accuracy: 0.8568 - val_loss: 0.2996 - val_accuracy: 0.8808\n",
      "Epoch 192/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.3645 - accuracy: 0.8346 - val_loss: 0.3138 - val_accuracy: 0.8729\n",
      "Epoch 193/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.3483 - accuracy: 0.8421 - val_loss: 0.3080 - val_accuracy: 0.8681\n",
      "Epoch 194/1000\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 0.3242 - accuracy: 0.8559 - val_loss: 0.2907 - val_accuracy: 0.8824\n",
      "Epoch 195/1000\n",
      "21/21 [==============================] - 1s 56ms/step - loss: 0.3064 - accuracy: 0.8655 - val_loss: 0.2821 - val_accuracy: 0.8876\n",
      "Epoch 196/1000\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 0.3190 - accuracy: 0.8641 - val_loss: 0.2866 - val_accuracy: 0.8864\n",
      "Epoch 197/1000\n",
      "21/21 [==============================] - 1s 56ms/step - loss: 0.3104 - accuracy: 0.8632 - val_loss: 0.2829 - val_accuracy: 0.8876\n",
      "Epoch 198/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.3217 - accuracy: 0.8592 - val_loss: 0.2928 - val_accuracy: 0.8784\n",
      "Epoch 199/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.3186 - accuracy: 0.8613 - val_loss: 0.2840 - val_accuracy: 0.8868\n",
      "Epoch 200/1000\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 0.3022 - accuracy: 0.8694 - val_loss: 0.2795 - val_accuracy: 0.8920\n",
      "Epoch 201/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.3013 - accuracy: 0.8700 - val_loss: 0.2894 - val_accuracy: 0.8792\n",
      "Epoch 202/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.3586 - accuracy: 0.8382 - val_loss: 0.3043 - val_accuracy: 0.8693\n",
      "Epoch 203/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.3403 - accuracy: 0.8484 - val_loss: 0.3083 - val_accuracy: 0.8689\n",
      "Epoch 204/1000\n",
      "21/21 [==============================] - 1s 52ms/step - loss: 0.3234 - accuracy: 0.8570 - val_loss: 0.2916 - val_accuracy: 0.8749\n",
      "Epoch 205/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.3078 - accuracy: 0.8655 - val_loss: 0.2841 - val_accuracy: 0.8824\n",
      "Epoch 206/1000\n",
      "21/21 [==============================] - 1s 52ms/step - loss: 0.3020 - accuracy: 0.8697 - val_loss: 0.2830 - val_accuracy: 0.8804\n",
      "Epoch 207/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.3226 - accuracy: 0.8577 - val_loss: 0.2947 - val_accuracy: 0.8800\n",
      "Epoch 208/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.3131 - accuracy: 0.8666 - val_loss: 0.2832 - val_accuracy: 0.8844\n",
      "Epoch 209/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.3060 - accuracy: 0.8707 - val_loss: 0.2782 - val_accuracy: 0.8896\n",
      "Epoch 210/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.3015 - accuracy: 0.8703 - val_loss: 0.2757 - val_accuracy: 0.8900\n",
      "Epoch 211/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.3038 - accuracy: 0.8716 - val_loss: 0.2728 - val_accuracy: 0.8904\n",
      "Epoch 212/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2979 - accuracy: 0.8733 - val_loss: 0.2720 - val_accuracy: 0.8936\n",
      "Epoch 213/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2949 - accuracy: 0.8742 - val_loss: 0.2713 - val_accuracy: 0.8888\n",
      "Epoch 214/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.3016 - accuracy: 0.8704 - val_loss: 0.2803 - val_accuracy: 0.8844\n",
      "Epoch 215/1000\n",
      "21/21 [==============================] - 1s 58ms/step - loss: 0.3656 - accuracy: 0.8341 - val_loss: 0.3208 - val_accuracy: 0.8629\n",
      "Epoch 216/1000\n",
      "21/21 [==============================] - 2s 75ms/step - loss: 0.3292 - accuracy: 0.8520 - val_loss: 0.2990 - val_accuracy: 0.8737\n",
      "Epoch 217/1000\n",
      "21/21 [==============================] - 1s 57ms/step - loss: 0.3355 - accuracy: 0.8505 - val_loss: 0.3060 - val_accuracy: 0.8768\n",
      "Epoch 218/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.3196 - accuracy: 0.8607 - val_loss: 0.2833 - val_accuracy: 0.8888\n",
      "Epoch 219/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.3114 - accuracy: 0.8646 - val_loss: 0.2786 - val_accuracy: 0.8920\n",
      "Epoch 220/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.3096 - accuracy: 0.8661 - val_loss: 0.2749 - val_accuracy: 0.8944\n",
      "Epoch 221/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.3043 - accuracy: 0.8669 - val_loss: 0.2774 - val_accuracy: 0.8876\n",
      "Epoch 222/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.3055 - accuracy: 0.8657 - val_loss: 0.2737 - val_accuracy: 0.8912\n",
      "Epoch 223/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2960 - accuracy: 0.8720 - val_loss: 0.2719 - val_accuracy: 0.8940\n",
      "Epoch 224/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2914 - accuracy: 0.8759 - val_loss: 0.2746 - val_accuracy: 0.8872\n",
      "Epoch 225/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.3356 - accuracy: 0.8467 - val_loss: 0.3037 - val_accuracy: 0.8697\n",
      "Epoch 226/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.3275 - accuracy: 0.8555 - val_loss: 0.2867 - val_accuracy: 0.8812\n",
      "Epoch 227/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 58ms/step - loss: 0.3169 - accuracy: 0.8599 - val_loss: 0.2840 - val_accuracy: 0.8876\n",
      "Epoch 228/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.3062 - accuracy: 0.8661 - val_loss: 0.2707 - val_accuracy: 0.8916\n",
      "Epoch 229/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.3006 - accuracy: 0.8694 - val_loss: 0.2729 - val_accuracy: 0.8868\n",
      "Epoch 230/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.2976 - accuracy: 0.8718 - val_loss: 0.2674 - val_accuracy: 0.8924\n",
      "Epoch 231/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.2977 - accuracy: 0.8700 - val_loss: 0.2750 - val_accuracy: 0.8872\n",
      "Epoch 232/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.3330 - accuracy: 0.8530 - val_loss: 0.2938 - val_accuracy: 0.8737\n",
      "Epoch 233/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.3115 - accuracy: 0.8630 - val_loss: 0.2770 - val_accuracy: 0.8788\n",
      "Epoch 234/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2999 - accuracy: 0.8686 - val_loss: 0.2678 - val_accuracy: 0.8828\n",
      "Epoch 235/1000\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.3101 - accuracy: 0.8651 - val_loss: 0.2704 - val_accuracy: 0.8888\n",
      "Epoch 236/1000\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.3059 - accuracy: 0.8660 - val_loss: 0.2825 - val_accuracy: 0.8812\n",
      "Epoch 237/1000\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.3077 - accuracy: 0.8664 - val_loss: 0.2690 - val_accuracy: 0.8848\n",
      "Epoch 238/1000\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.2946 - accuracy: 0.8744 - val_loss: 0.2705 - val_accuracy: 0.8860\n",
      "Epoch 239/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2998 - accuracy: 0.8694 - val_loss: 0.2678 - val_accuracy: 0.8936\n",
      "Epoch 240/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.3096 - accuracy: 0.8663 - val_loss: 0.2787 - val_accuracy: 0.8864\n",
      "Epoch 241/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2996 - accuracy: 0.8679 - val_loss: 0.2692 - val_accuracy: 0.8904\n",
      "Epoch 242/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.3089 - accuracy: 0.8617 - val_loss: 0.2788 - val_accuracy: 0.8884\n",
      "Epoch 243/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.3056 - accuracy: 0.8706 - val_loss: 0.2725 - val_accuracy: 0.8904\n",
      "Epoch 244/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2990 - accuracy: 0.8726 - val_loss: 0.2670 - val_accuracy: 0.8956\n",
      "Epoch 245/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2906 - accuracy: 0.8772 - val_loss: 0.2655 - val_accuracy: 0.8908\n",
      "Epoch 246/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2894 - accuracy: 0.8755 - val_loss: 0.2652 - val_accuracy: 0.8932\n",
      "Epoch 247/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2824 - accuracy: 0.8775 - val_loss: 0.2650 - val_accuracy: 0.8924\n",
      "Epoch 248/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2870 - accuracy: 0.8765 - val_loss: 0.2669 - val_accuracy: 0.8948\n",
      "Epoch 249/1000\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.2819 - accuracy: 0.8784 - val_loss: 0.2643 - val_accuracy: 0.8912\n",
      "Epoch 250/1000\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.2838 - accuracy: 0.8775 - val_loss: 0.2637 - val_accuracy: 0.8928\n",
      "Epoch 251/1000\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.2894 - accuracy: 0.8770 - val_loss: 0.2618 - val_accuracy: 0.8924\n",
      "Epoch 252/1000\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.2872 - accuracy: 0.8764 - val_loss: 0.2632 - val_accuracy: 0.8932\n",
      "Epoch 253/1000\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 0.2835 - accuracy: 0.8818 - val_loss: 0.2622 - val_accuracy: 0.8912\n",
      "Epoch 254/1000\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.2808 - accuracy: 0.8768 - val_loss: 0.2627 - val_accuracy: 0.8924\n",
      "Epoch 255/1000\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.3023 - accuracy: 0.8687 - val_loss: 0.2725 - val_accuracy: 0.8900\n",
      "Epoch 256/1000\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.2983 - accuracy: 0.8724 - val_loss: 0.2802 - val_accuracy: 0.8860\n",
      "Epoch 257/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.3105 - accuracy: 0.8686 - val_loss: 0.2835 - val_accuracy: 0.8856\n",
      "Epoch 258/1000\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.3677 - accuracy: 0.8272 - val_loss: 0.3110 - val_accuracy: 0.8709\n",
      "Epoch 259/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.3165 - accuracy: 0.8568 - val_loss: 0.2768 - val_accuracy: 0.8936\n",
      "Epoch 260/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2937 - accuracy: 0.8722 - val_loss: 0.2701 - val_accuracy: 0.8908\n",
      "Epoch 261/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2863 - accuracy: 0.8770 - val_loss: 0.2714 - val_accuracy: 0.8948\n",
      "Epoch 262/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.3381 - accuracy: 0.8452 - val_loss: 0.3093 - val_accuracy: 0.8693\n",
      "Epoch 263/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.3370 - accuracy: 0.8462 - val_loss: 0.2983 - val_accuracy: 0.8705\n",
      "Epoch 264/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.3254 - accuracy: 0.8555 - val_loss: 0.2905 - val_accuracy: 0.8792\n",
      "Epoch 265/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.3064 - accuracy: 0.8681 - val_loss: 0.2729 - val_accuracy: 0.8888\n",
      "Epoch 266/1000\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.2949 - accuracy: 0.8730 - val_loss: 0.2669 - val_accuracy: 0.8948\n",
      "Epoch 267/1000\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 0.2876 - accuracy: 0.8774 - val_loss: 0.2637 - val_accuracy: 0.8972\n",
      "Epoch 268/1000\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.2850 - accuracy: 0.8811 - val_loss: 0.2621 - val_accuracy: 0.8976\n",
      "Epoch 269/1000\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.2789 - accuracy: 0.8840 - val_loss: 0.2610 - val_accuracy: 0.8968\n",
      "Epoch 270/1000\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.2830 - accuracy: 0.8804 - val_loss: 0.2596 - val_accuracy: 0.9000\n",
      "Epoch 271/1000\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.2796 - accuracy: 0.8788 - val_loss: 0.2581 - val_accuracy: 0.8944\n",
      "Epoch 272/1000\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.2932 - accuracy: 0.8709 - val_loss: 0.2613 - val_accuracy: 0.8952\n",
      "Epoch 273/1000\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.2853 - accuracy: 0.8781 - val_loss: 0.2604 - val_accuracy: 0.8952\n",
      "Epoch 274/1000\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.2823 - accuracy: 0.8788 - val_loss: 0.2569 - val_accuracy: 0.8960\n",
      "Epoch 275/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2780 - accuracy: 0.8835 - val_loss: 0.2549 - val_accuracy: 0.8960\n",
      "Epoch 276/1000\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.2722 - accuracy: 0.8850 - val_loss: 0.2544 - val_accuracy: 0.8960\n",
      "Epoch 277/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2827 - accuracy: 0.8788 - val_loss: 0.2591 - val_accuracy: 0.8896\n",
      "Epoch 278/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.3019 - accuracy: 0.8691 - val_loss: 0.2795 - val_accuracy: 0.8824\n",
      "Epoch 279/1000\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.2926 - accuracy: 0.8728 - val_loss: 0.2683 - val_accuracy: 0.8892\n",
      "Epoch 280/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2857 - accuracy: 0.8783 - val_loss: 0.2687 - val_accuracy: 0.8872\n",
      "Epoch 281/1000\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.3130 - accuracy: 0.8599 - val_loss: 0.2799 - val_accuracy: 0.8808\n",
      "Epoch 282/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2970 - accuracy: 0.8704 - val_loss: 0.2753 - val_accuracy: 0.8828\n",
      "Epoch 283/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2911 - accuracy: 0.8747 - val_loss: 0.2734 - val_accuracy: 0.8832\n",
      "Epoch 284/1000\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.3914 - accuracy: 0.8175 - val_loss: 0.3520 - val_accuracy: 0.8489\n",
      "Epoch 285/1000\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.3379 - accuracy: 0.8434 - val_loss: 0.2922 - val_accuracy: 0.8745\n",
      "Epoch 286/1000\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.3123 - accuracy: 0.8617 - val_loss: 0.2777 - val_accuracy: 0.8864\n",
      "Epoch 287/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.3179 - accuracy: 0.8627 - val_loss: 0.2872 - val_accuracy: 0.8852\n",
      "Epoch 288/1000\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.3018 - accuracy: 0.8716 - val_loss: 0.2699 - val_accuracy: 0.8944\n",
      "Epoch 289/1000\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.2895 - accuracy: 0.8741 - val_loss: 0.2650 - val_accuracy: 0.8944\n",
      "Epoch 290/1000\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 0.2851 - accuracy: 0.8812 - val_loss: 0.2624 - val_accuracy: 0.8976\n",
      "Epoch 291/1000\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.2880 - accuracy: 0.8768 - val_loss: 0.2652 - val_accuracy: 0.8956\n",
      "Epoch 292/1000\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.2917 - accuracy: 0.8770 - val_loss: 0.2609 - val_accuracy: 0.8964\n",
      "Epoch 293/1000\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.2817 - accuracy: 0.8787 - val_loss: 0.2596 - val_accuracy: 0.8952\n",
      "Epoch 294/1000\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.2900 - accuracy: 0.8759 - val_loss: 0.2611 - val_accuracy: 0.8964\n",
      "Epoch 295/1000\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.2841 - accuracy: 0.8816 - val_loss: 0.2564 - val_accuracy: 0.8964\n",
      "Epoch 296/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2790 - accuracy: 0.8795 - val_loss: 0.2558 - val_accuracy: 0.8956\n",
      "Epoch 297/1000\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.2837 - accuracy: 0.8794 - val_loss: 0.2556 - val_accuracy: 0.8936\n",
      "Epoch 298/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2830 - accuracy: 0.8796 - val_loss: 0.2550 - val_accuracy: 0.8948\n",
      "Epoch 299/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2756 - accuracy: 0.8830 - val_loss: 0.2536 - val_accuracy: 0.8968\n",
      "Epoch 300/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.2712 - accuracy: 0.8839 - val_loss: 0.2514 - val_accuracy: 0.8968\n",
      "Epoch 301/1000\n",
      "21/21 [==============================] - 1s 52ms/step - loss: 0.2748 - accuracy: 0.8812 - val_loss: 0.2493 - val_accuracy: 0.8988\n",
      "Epoch 302/1000\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.2736 - accuracy: 0.8840 - val_loss: 0.2515 - val_accuracy: 0.8972\n",
      "Epoch 303/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2793 - accuracy: 0.8776 - val_loss: 0.2538 - val_accuracy: 0.8968\n",
      "Epoch 304/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2810 - accuracy: 0.8828 - val_loss: 0.2547 - val_accuracy: 0.8948\n",
      "Epoch 305/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.3084 - accuracy: 0.8660 - val_loss: 0.2775 - val_accuracy: 0.8872\n",
      "Epoch 306/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.3014 - accuracy: 0.8677 - val_loss: 0.2808 - val_accuracy: 0.8832\n",
      "Epoch 307/1000\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.3004 - accuracy: 0.8689 - val_loss: 0.2678 - val_accuracy: 0.8956\n",
      "Epoch 308/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2840 - accuracy: 0.8767 - val_loss: 0.2617 - val_accuracy: 0.8984\n",
      "Epoch 309/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2820 - accuracy: 0.8757 - val_loss: 0.2584 - val_accuracy: 0.8936\n",
      "Epoch 310/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2843 - accuracy: 0.8765 - val_loss: 0.2641 - val_accuracy: 0.8964\n",
      "Epoch 311/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.3214 - accuracy: 0.8566 - val_loss: 0.2878 - val_accuracy: 0.8796\n",
      "Epoch 312/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.3049 - accuracy: 0.8632 - val_loss: 0.2718 - val_accuracy: 0.8884\n",
      "Epoch 313/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2861 - accuracy: 0.8745 - val_loss: 0.2630 - val_accuracy: 0.8952\n",
      "Epoch 314/1000\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 0.2833 - accuracy: 0.8747 - val_loss: 0.2563 - val_accuracy: 0.8968\n",
      "Epoch 315/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2793 - accuracy: 0.8763 - val_loss: 0.2557 - val_accuracy: 0.8912\n",
      "Epoch 316/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2830 - accuracy: 0.8790 - val_loss: 0.2511 - val_accuracy: 0.9012\n",
      "Epoch 317/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2766 - accuracy: 0.8813 - val_loss: 0.2503 - val_accuracy: 0.8988\n",
      "Epoch 318/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2910 - accuracy: 0.8735 - val_loss: 0.2527 - val_accuracy: 0.9016\n",
      "Epoch 319/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2766 - accuracy: 0.8781 - val_loss: 0.2540 - val_accuracy: 0.8948\n",
      "Epoch 320/1000\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.3040 - accuracy: 0.8659 - val_loss: 0.2702 - val_accuracy: 0.8824\n",
      "Epoch 321/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2870 - accuracy: 0.8777 - val_loss: 0.2577 - val_accuracy: 0.8924\n",
      "Epoch 322/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2854 - accuracy: 0.8738 - val_loss: 0.2548 - val_accuracy: 0.8924\n",
      "Epoch 323/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.3383 - accuracy: 0.8531 - val_loss: 0.2862 - val_accuracy: 0.8800\n",
      "Epoch 324/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2966 - accuracy: 0.8720 - val_loss: 0.2660 - val_accuracy: 0.8912\n",
      "Epoch 325/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2838 - accuracy: 0.8784 - val_loss: 0.2593 - val_accuracy: 0.8936\n",
      "Epoch 326/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2836 - accuracy: 0.8767 - val_loss: 0.2591 - val_accuracy: 0.8940\n",
      "Epoch 327/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.2932 - accuracy: 0.8696 - val_loss: 0.2752 - val_accuracy: 0.8876\n",
      "Epoch 328/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2894 - accuracy: 0.8748 - val_loss: 0.2594 - val_accuracy: 0.8928\n",
      "Epoch 329/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2806 - accuracy: 0.8784 - val_loss: 0.2597 - val_accuracy: 0.8904\n",
      "Epoch 330/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2740 - accuracy: 0.8820 - val_loss: 0.2627 - val_accuracy: 0.8872\n",
      "Epoch 331/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.3049 - accuracy: 0.8644 - val_loss: 0.2658 - val_accuracy: 0.8864\n",
      "Epoch 332/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2895 - accuracy: 0.8764 - val_loss: 0.2616 - val_accuracy: 0.8924\n",
      "Epoch 333/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.3046 - accuracy: 0.8656 - val_loss: 0.2577 - val_accuracy: 0.8916\n",
      "Epoch 334/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2840 - accuracy: 0.8778 - val_loss: 0.2500 - val_accuracy: 0.8948\n",
      "Epoch 335/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2730 - accuracy: 0.8828 - val_loss: 0.2504 - val_accuracy: 0.8980\n",
      "Epoch 336/1000\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.2774 - accuracy: 0.8827 - val_loss: 0.2486 - val_accuracy: 0.9020\n",
      "Epoch 337/1000\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.2811 - accuracy: 0.8794 - val_loss: 0.2570 - val_accuracy: 0.8944\n",
      "Epoch 338/1000\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.2823 - accuracy: 0.8776 - val_loss: 0.2518 - val_accuracy: 0.8976\n",
      "Epoch 339/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 40ms/step - loss: 0.2778 - accuracy: 0.8823 - val_loss: 0.2551 - val_accuracy: 0.8988\n",
      "Epoch 340/1000\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.2677 - accuracy: 0.8884 - val_loss: 0.2490 - val_accuracy: 0.9008\n",
      "Epoch 341/1000\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.2697 - accuracy: 0.8872 - val_loss: 0.2482 - val_accuracy: 0.8996\n",
      "Epoch 342/1000\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.2753 - accuracy: 0.8813 - val_loss: 0.2478 - val_accuracy: 0.8944\n",
      "Epoch 343/1000\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.2778 - accuracy: 0.8795 - val_loss: 0.2467 - val_accuracy: 0.8932\n",
      "Epoch 344/1000\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.2693 - accuracy: 0.8848 - val_loss: 0.2474 - val_accuracy: 0.8976\n",
      "Epoch 345/1000\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.2738 - accuracy: 0.8829 - val_loss: 0.2469 - val_accuracy: 0.8980\n",
      "Epoch 346/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2762 - accuracy: 0.8828 - val_loss: 0.2472 - val_accuracy: 0.9024\n",
      "Epoch 347/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2609 - accuracy: 0.8913 - val_loss: 0.2440 - val_accuracy: 0.9024\n",
      "Epoch 348/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2707 - accuracy: 0.8834 - val_loss: 0.2479 - val_accuracy: 0.8976\n",
      "Epoch 349/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.3079 - accuracy: 0.8602 - val_loss: 0.2723 - val_accuracy: 0.8892\n",
      "Epoch 350/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2974 - accuracy: 0.8672 - val_loss: 0.2583 - val_accuracy: 0.8928\n",
      "Epoch 351/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2847 - accuracy: 0.8768 - val_loss: 0.2716 - val_accuracy: 0.8896\n",
      "Epoch 352/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.3494 - accuracy: 0.8423 - val_loss: 0.2945 - val_accuracy: 0.8772\n",
      "Epoch 353/1000\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.3074 - accuracy: 0.8652 - val_loss: 0.2671 - val_accuracy: 0.8900\n",
      "Epoch 354/1000\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.2817 - accuracy: 0.8804 - val_loss: 0.2594 - val_accuracy: 0.8936\n",
      "Epoch 355/1000\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 0.2774 - accuracy: 0.8783 - val_loss: 0.2518 - val_accuracy: 0.9008\n",
      "Epoch 356/1000\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.2736 - accuracy: 0.8848 - val_loss: 0.2499 - val_accuracy: 0.9016\n",
      "Epoch 357/1000\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.2685 - accuracy: 0.8858 - val_loss: 0.2495 - val_accuracy: 0.9020\n",
      "Epoch 358/1000\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.2807 - accuracy: 0.8791 - val_loss: 0.2587 - val_accuracy: 0.8956\n",
      "Epoch 359/1000\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 0.2714 - accuracy: 0.8836 - val_loss: 0.2480 - val_accuracy: 0.9016\n",
      "Epoch 360/1000\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 0.2694 - accuracy: 0.8837 - val_loss: 0.2457 - val_accuracy: 0.9012\n",
      "Epoch 361/1000\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.2691 - accuracy: 0.8887 - val_loss: 0.2464 - val_accuracy: 0.9008\n",
      "Epoch 362/1000\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.2814 - accuracy: 0.8765 - val_loss: 0.2571 - val_accuracy: 0.8952\n",
      "Epoch 363/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2698 - accuracy: 0.8852 - val_loss: 0.2499 - val_accuracy: 0.9008\n",
      "Epoch 364/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2787 - accuracy: 0.8781 - val_loss: 0.2508 - val_accuracy: 0.9004\n",
      "Epoch 365/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2742 - accuracy: 0.8815 - val_loss: 0.2459 - val_accuracy: 0.8996\n",
      "Epoch 366/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2721 - accuracy: 0.8849 - val_loss: 0.2491 - val_accuracy: 0.9016\n",
      "Epoch 367/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2722 - accuracy: 0.8843 - val_loss: 0.2527 - val_accuracy: 0.8984\n",
      "Epoch 368/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2670 - accuracy: 0.8867 - val_loss: 0.2493 - val_accuracy: 0.8988\n",
      "Epoch 369/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2825 - accuracy: 0.8751 - val_loss: 0.2645 - val_accuracy: 0.8936\n",
      "Epoch 370/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2818 - accuracy: 0.8836 - val_loss: 0.2519 - val_accuracy: 0.9048\n",
      "Epoch 371/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2716 - accuracy: 0.8851 - val_loss: 0.2470 - val_accuracy: 0.9024\n",
      "Epoch 372/1000\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.2678 - accuracy: 0.8841 - val_loss: 0.2520 - val_accuracy: 0.8992\n",
      "Epoch 373/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2853 - accuracy: 0.8732 - val_loss: 0.2584 - val_accuracy: 0.8936\n",
      "Epoch 374/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.2735 - accuracy: 0.8823 - val_loss: 0.2505 - val_accuracy: 0.9024\n",
      "Epoch 375/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2773 - accuracy: 0.8860 - val_loss: 0.2522 - val_accuracy: 0.9024\n",
      "Epoch 376/1000\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.2708 - accuracy: 0.8866 - val_loss: 0.2463 - val_accuracy: 0.9020\n",
      "Epoch 377/1000\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.2628 - accuracy: 0.8904 - val_loss: 0.2454 - val_accuracy: 0.9004\n",
      "Epoch 378/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2664 - accuracy: 0.8871 - val_loss: 0.2446 - val_accuracy: 0.8976\n",
      "Epoch 379/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2642 - accuracy: 0.8909 - val_loss: 0.2451 - val_accuracy: 0.9004\n",
      "Epoch 380/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2627 - accuracy: 0.8860 - val_loss: 0.2471 - val_accuracy: 0.9004\n",
      "Epoch 381/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2612 - accuracy: 0.8884 - val_loss: 0.2471 - val_accuracy: 0.9032\n",
      "Epoch 382/1000\n",
      "21/21 [==============================] - 1s 57ms/step - loss: 0.2689 - accuracy: 0.8871 - val_loss: 0.2503 - val_accuracy: 0.8984\n",
      "Epoch 383/1000\n",
      "21/21 [==============================] - 1s 56ms/step - loss: 0.3187 - accuracy: 0.8629 - val_loss: 0.2673 - val_accuracy: 0.8880\n",
      "Epoch 384/1000\n",
      "21/21 [==============================] - 1s 53ms/step - loss: 0.2774 - accuracy: 0.8799 - val_loss: 0.2474 - val_accuracy: 0.9044\n",
      "Epoch 385/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.2711 - accuracy: 0.8847 - val_loss: 0.2447 - val_accuracy: 0.9004\n",
      "Epoch 386/1000\n",
      "21/21 [==============================] - 1s 52ms/step - loss: 0.2682 - accuracy: 0.8874 - val_loss: 0.2441 - val_accuracy: 0.9024\n",
      "Epoch 387/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.2626 - accuracy: 0.8885 - val_loss: 0.2421 - val_accuracy: 0.9016\n",
      "Epoch 388/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2680 - accuracy: 0.8865 - val_loss: 0.2401 - val_accuracy: 0.9044\n",
      "Epoch 389/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2592 - accuracy: 0.8876 - val_loss: 0.2388 - val_accuracy: 0.9020\n",
      "Epoch 390/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.2597 - accuracy: 0.8889 - val_loss: 0.2423 - val_accuracy: 0.9032\n",
      "Epoch 391/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2829 - accuracy: 0.8758 - val_loss: 0.2512 - val_accuracy: 0.8988\n",
      "Epoch 392/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2696 - accuracy: 0.8898 - val_loss: 0.2516 - val_accuracy: 0.8924\n",
      "Epoch 393/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2837 - accuracy: 0.8759 - val_loss: 0.2588 - val_accuracy: 0.8908\n",
      "Epoch 394/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2681 - accuracy: 0.8835 - val_loss: 0.2482 - val_accuracy: 0.8968\n",
      "Epoch 395/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2692 - accuracy: 0.8811 - val_loss: 0.2449 - val_accuracy: 0.9004\n",
      "Epoch 396/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2699 - accuracy: 0.8785 - val_loss: 0.2423 - val_accuracy: 0.9008\n",
      "Epoch 397/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2596 - accuracy: 0.8897 - val_loss: 0.2407 - val_accuracy: 0.9040\n",
      "Epoch 398/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2552 - accuracy: 0.8926 - val_loss: 0.2407 - val_accuracy: 0.9036\n",
      "Epoch 399/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2598 - accuracy: 0.8883 - val_loss: 0.2408 - val_accuracy: 0.9040\n",
      "Epoch 400/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2602 - accuracy: 0.8900 - val_loss: 0.2398 - val_accuracy: 0.9044\n",
      "Epoch 401/1000\n",
      "21/21 [==============================] - 1s 65ms/step - loss: 0.2576 - accuracy: 0.8911 - val_loss: 0.2400 - val_accuracy: 0.9036\n",
      "Epoch 402/1000\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 0.2703 - accuracy: 0.8879 - val_loss: 0.2488 - val_accuracy: 0.8976\n",
      "Epoch 403/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.3170 - accuracy: 0.8550 - val_loss: 0.3006 - val_accuracy: 0.8653\n",
      "Epoch 404/1000\n",
      "21/21 [==============================] - 1s 56ms/step - loss: 0.3039 - accuracy: 0.8672 - val_loss: 0.2715 - val_accuracy: 0.8852\n",
      "Epoch 405/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2787 - accuracy: 0.8810 - val_loss: 0.2533 - val_accuracy: 0.8920\n",
      "Epoch 406/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2705 - accuracy: 0.8798 - val_loss: 0.2490 - val_accuracy: 0.8944\n",
      "Epoch 407/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2657 - accuracy: 0.8855 - val_loss: 0.2435 - val_accuracy: 0.8984\n",
      "Epoch 408/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2617 - accuracy: 0.8866 - val_loss: 0.2421 - val_accuracy: 0.9008\n",
      "Epoch 409/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2585 - accuracy: 0.8872 - val_loss: 0.2387 - val_accuracy: 0.9008\n",
      "Epoch 410/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2679 - accuracy: 0.8851 - val_loss: 0.2383 - val_accuracy: 0.9076\n",
      "Epoch 411/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2608 - accuracy: 0.8877 - val_loss: 0.2370 - val_accuracy: 0.9056\n",
      "Epoch 412/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2647 - accuracy: 0.8875 - val_loss: 0.2392 - val_accuracy: 0.9032\n",
      "Epoch 413/1000\n",
      "21/21 [==============================] - 1s 61ms/step - loss: 0.2608 - accuracy: 0.8893 - val_loss: 0.2377 - val_accuracy: 0.9064\n",
      "Epoch 414/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.2589 - accuracy: 0.8892 - val_loss: 0.2373 - val_accuracy: 0.9064\n",
      "Epoch 415/1000\n",
      "21/21 [==============================] - 1s 53ms/step - loss: 0.2575 - accuracy: 0.8918 - val_loss: 0.2371 - val_accuracy: 0.9076\n",
      "Epoch 416/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.2601 - accuracy: 0.8906 - val_loss: 0.2422 - val_accuracy: 0.9076\n",
      "Epoch 417/1000\n",
      "21/21 [==============================] - 1s 53ms/step - loss: 0.2902 - accuracy: 0.8722 - val_loss: 0.2697 - val_accuracy: 0.8860\n",
      "Epoch 418/1000\n",
      "21/21 [==============================] - 1s 57ms/step - loss: 0.2763 - accuracy: 0.8805 - val_loss: 0.2524 - val_accuracy: 0.9040\n",
      "Epoch 419/1000\n",
      "21/21 [==============================] - 1s 61ms/step - loss: 0.2736 - accuracy: 0.8840 - val_loss: 0.2523 - val_accuracy: 0.8984\n",
      "Epoch 420/1000\n",
      "21/21 [==============================] - 1s 52ms/step - loss: 0.3084 - accuracy: 0.8697 - val_loss: 0.2624 - val_accuracy: 0.8936\n",
      "Epoch 421/1000\n",
      "21/21 [==============================] - 1s 59ms/step - loss: 0.2858 - accuracy: 0.8794 - val_loss: 0.2483 - val_accuracy: 0.9024\n",
      "Epoch 422/1000\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 0.2719 - accuracy: 0.8805 - val_loss: 0.2407 - val_accuracy: 0.9036\n",
      "Epoch 423/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2696 - accuracy: 0.8831 - val_loss: 0.2372 - val_accuracy: 0.9044\n",
      "Epoch 424/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2610 - accuracy: 0.8885 - val_loss: 0.2367 - val_accuracy: 0.9036\n",
      "Epoch 425/1000\n",
      "21/21 [==============================] - 1s 59ms/step - loss: 0.2624 - accuracy: 0.8887 - val_loss: 0.2360 - val_accuracy: 0.9044\n",
      "Epoch 426/1000\n",
      "21/21 [==============================] - 1s 59ms/step - loss: 0.2613 - accuracy: 0.8894 - val_loss: 0.2367 - val_accuracy: 0.9048\n",
      "Epoch 427/1000\n",
      "21/21 [==============================] - 1s 55ms/step - loss: 0.2564 - accuracy: 0.8904 - val_loss: 0.2352 - val_accuracy: 0.9044\n",
      "Epoch 428/1000\n",
      "21/21 [==============================] - 1s 59ms/step - loss: 0.2597 - accuracy: 0.8904 - val_loss: 0.2340 - val_accuracy: 0.9044\n",
      "Epoch 429/1000\n",
      "21/21 [==============================] - 1s 61ms/step - loss: 0.2568 - accuracy: 0.8887 - val_loss: 0.2360 - val_accuracy: 0.9068\n",
      "Epoch 430/1000\n",
      "21/21 [==============================] - 1s 52ms/step - loss: 0.2549 - accuracy: 0.8906 - val_loss: 0.2330 - val_accuracy: 0.9048\n",
      "Epoch 431/1000\n",
      "21/21 [==============================] - 1s 52ms/step - loss: 0.2552 - accuracy: 0.8942 - val_loss: 0.2329 - val_accuracy: 0.9036\n",
      "Epoch 432/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.2675 - accuracy: 0.8859 - val_loss: 0.2322 - val_accuracy: 0.9024\n",
      "Epoch 433/1000\n",
      "21/21 [==============================] - 1s 58ms/step - loss: 0.2727 - accuracy: 0.8830 - val_loss: 0.2414 - val_accuracy: 0.9000\n",
      "Epoch 434/1000\n",
      "21/21 [==============================] - 1s 70ms/step - loss: 0.2665 - accuracy: 0.8858 - val_loss: 0.2363 - val_accuracy: 0.9016\n",
      "Epoch 435/1000\n",
      "21/21 [==============================] - 1s 56ms/step - loss: 0.2762 - accuracy: 0.8833 - val_loss: 0.2387 - val_accuracy: 0.9048\n",
      "Epoch 436/1000\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 0.2645 - accuracy: 0.8912 - val_loss: 0.2345 - val_accuracy: 0.9096\n",
      "Epoch 437/1000\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 0.2581 - accuracy: 0.8897 - val_loss: 0.2319 - val_accuracy: 0.9100\n",
      "Epoch 438/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2670 - accuracy: 0.8866 - val_loss: 0.2425 - val_accuracy: 0.9036\n",
      "Epoch 439/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2629 - accuracy: 0.8876 - val_loss: 0.2336 - val_accuracy: 0.9048\n",
      "Epoch 440/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2647 - accuracy: 0.8889 - val_loss: 0.2417 - val_accuracy: 0.8964\n",
      "Epoch 441/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2569 - accuracy: 0.8922 - val_loss: 0.2337 - val_accuracy: 0.9040\n",
      "Epoch 442/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2545 - accuracy: 0.8943 - val_loss: 0.2318 - val_accuracy: 0.9052\n",
      "Epoch 443/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.2494 - accuracy: 0.8941 - val_loss: 0.2320 - val_accuracy: 0.9028\n",
      "Epoch 444/1000\n",
      "21/21 [==============================] - 1s 52ms/step - loss: 0.2996 - accuracy: 0.8644 - val_loss: 0.2547 - val_accuracy: 0.8916\n",
      "Epoch 445/1000\n",
      "21/21 [==============================] - 1s 54ms/step - loss: 0.2763 - accuracy: 0.8780 - val_loss: 0.2427 - val_accuracy: 0.9004\n",
      "Epoch 446/1000\n",
      "21/21 [==============================] - 1s 53ms/step - loss: 0.2647 - accuracy: 0.8873 - val_loss: 0.2354 - val_accuracy: 0.9056\n",
      "Epoch 447/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.2623 - accuracy: 0.8871 - val_loss: 0.2320 - val_accuracy: 0.9096\n",
      "Epoch 448/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2527 - accuracy: 0.8949 - val_loss: 0.2309 - val_accuracy: 0.9068\n",
      "Epoch 449/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2665 - accuracy: 0.8857 - val_loss: 0.2416 - val_accuracy: 0.8976\n",
      "Epoch 450/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2914 - accuracy: 0.8730 - val_loss: 0.2554 - val_accuracy: 0.8948\n",
      "Epoch 451/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2704 - accuracy: 0.8863 - val_loss: 0.2436 - val_accuracy: 0.9016\n",
      "Epoch 452/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2607 - accuracy: 0.8890 - val_loss: 0.2374 - val_accuracy: 0.9060\n",
      "Epoch 453/1000\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.2591 - accuracy: 0.8893 - val_loss: 0.2337 - val_accuracy: 0.9040\n",
      "Epoch 454/1000\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.2614 - accuracy: 0.8868 - val_loss: 0.2327 - val_accuracy: 0.9032\n",
      "Epoch 455/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2551 - accuracy: 0.8909 - val_loss: 0.2298 - val_accuracy: 0.9080\n",
      "Epoch 456/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2588 - accuracy: 0.8916 - val_loss: 0.2285 - val_accuracy: 0.9068\n",
      "Epoch 457/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2637 - accuracy: 0.8852 - val_loss: 0.2362 - val_accuracy: 0.9056\n",
      "Epoch 458/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2646 - accuracy: 0.8865 - val_loss: 0.2413 - val_accuracy: 0.8984\n",
      "Epoch 459/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.3067 - accuracy: 0.8674 - val_loss: 0.2632 - val_accuracy: 0.8868\n",
      "Epoch 460/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2785 - accuracy: 0.8824 - val_loss: 0.2487 - val_accuracy: 0.8952\n",
      "Epoch 461/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.2670 - accuracy: 0.8873 - val_loss: 0.2409 - val_accuracy: 0.8996\n",
      "Epoch 462/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.2673 - accuracy: 0.8841 - val_loss: 0.2410 - val_accuracy: 0.9028\n",
      "Epoch 463/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.3055 - accuracy: 0.8668 - val_loss: 0.2908 - val_accuracy: 0.8900\n",
      "Epoch 464/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.3157 - accuracy: 0.8601 - val_loss: 0.2820 - val_accuracy: 0.8892\n",
      "Epoch 465/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2932 - accuracy: 0.8745 - val_loss: 0.2619 - val_accuracy: 0.8924\n",
      "Epoch 466/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2866 - accuracy: 0.8750 - val_loss: 0.2618 - val_accuracy: 0.8892\n",
      "Epoch 467/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2886 - accuracy: 0.8757 - val_loss: 0.2672 - val_accuracy: 0.8840\n",
      "Epoch 468/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2787 - accuracy: 0.8820 - val_loss: 0.2525 - val_accuracy: 0.8960\n",
      "Epoch 469/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2728 - accuracy: 0.8816 - val_loss: 0.2563 - val_accuracy: 0.8972\n",
      "Epoch 470/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2644 - accuracy: 0.8856 - val_loss: 0.2481 - val_accuracy: 0.8984\n",
      "Epoch 471/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2592 - accuracy: 0.8911 - val_loss: 0.2533 - val_accuracy: 0.8964\n",
      "Epoch 472/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2683 - accuracy: 0.8841 - val_loss: 0.2517 - val_accuracy: 0.8924\n",
      "Epoch 473/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2636 - accuracy: 0.8873 - val_loss: 0.2463 - val_accuracy: 0.8996\n",
      "Epoch 474/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2588 - accuracy: 0.8882 - val_loss: 0.2380 - val_accuracy: 0.9008\n",
      "Epoch 475/1000\n",
      "21/21 [==============================] - 1s 56ms/step - loss: 0.2542 - accuracy: 0.8907 - val_loss: 0.2366 - val_accuracy: 0.9040\n",
      "Epoch 476/1000\n",
      "21/21 [==============================] - 1s 57ms/step - loss: 0.2544 - accuracy: 0.8911 - val_loss: 0.2338 - val_accuracy: 0.9040\n",
      "Epoch 477/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2521 - accuracy: 0.8928 - val_loss: 0.2331 - val_accuracy: 0.9036\n",
      "Epoch 478/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.2490 - accuracy: 0.8932 - val_loss: 0.2320 - val_accuracy: 0.9032\n",
      "Epoch 479/1000\n",
      "21/21 [==============================] - 1s 53ms/step - loss: 0.2737 - accuracy: 0.8825 - val_loss: 0.2586 - val_accuracy: 0.8936\n",
      "Epoch 480/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.3369 - accuracy: 0.8472 - val_loss: 0.3034 - val_accuracy: 0.8669\n",
      "Epoch 481/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.3029 - accuracy: 0.8636 - val_loss: 0.2689 - val_accuracy: 0.8820\n",
      "Epoch 482/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2843 - accuracy: 0.8724 - val_loss: 0.2516 - val_accuracy: 0.8908\n",
      "Epoch 483/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2775 - accuracy: 0.8793 - val_loss: 0.2558 - val_accuracy: 0.8872\n",
      "Epoch 484/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2734 - accuracy: 0.8840 - val_loss: 0.2478 - val_accuracy: 0.8952\n",
      "Epoch 485/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2714 - accuracy: 0.8817 - val_loss: 0.2415 - val_accuracy: 0.9000\n",
      "Epoch 486/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2676 - accuracy: 0.8852 - val_loss: 0.2379 - val_accuracy: 0.9032\n",
      "Epoch 487/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2552 - accuracy: 0.8911 - val_loss: 0.2370 - val_accuracy: 0.9052\n",
      "Epoch 488/1000\n",
      "21/21 [==============================] - 1s 57ms/step - loss: 0.2557 - accuracy: 0.8909 - val_loss: 0.2370 - val_accuracy: 0.9068\n",
      "Epoch 489/1000\n",
      "21/21 [==============================] - 1s 52ms/step - loss: 0.2544 - accuracy: 0.8928 - val_loss: 0.2338 - val_accuracy: 0.9096\n",
      "Epoch 490/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2534 - accuracy: 0.8906 - val_loss: 0.2348 - val_accuracy: 0.9104\n",
      "Epoch 491/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2510 - accuracy: 0.8922 - val_loss: 0.2328 - val_accuracy: 0.9088\n",
      "Epoch 492/1000\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 0.2506 - accuracy: 0.8939 - val_loss: 0.2336 - val_accuracy: 0.9048\n",
      "Epoch 493/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2804 - accuracy: 0.8782 - val_loss: 0.2380 - val_accuracy: 0.9052\n",
      "Epoch 494/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2549 - accuracy: 0.8930 - val_loss: 0.2392 - val_accuracy: 0.9048\n",
      "Epoch 495/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.3128 - accuracy: 0.8659 - val_loss: 0.2566 - val_accuracy: 0.8940\n",
      "Epoch 496/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2757 - accuracy: 0.8817 - val_loss: 0.2402 - val_accuracy: 0.9012\n",
      "Epoch 497/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2663 - accuracy: 0.8868 - val_loss: 0.2327 - val_accuracy: 0.9056\n",
      "Epoch 498/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2537 - accuracy: 0.8933 - val_loss: 0.2309 - val_accuracy: 0.9076\n",
      "Epoch 499/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2558 - accuracy: 0.8943 - val_loss: 0.2299 - val_accuracy: 0.9064\n",
      "Epoch 500/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2572 - accuracy: 0.8889 - val_loss: 0.2271 - val_accuracy: 0.9052\n",
      "Epoch 501/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2573 - accuracy: 0.8886 - val_loss: 0.2335 - val_accuracy: 0.9040\n",
      "Epoch 502/1000\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.2505 - accuracy: 0.8909 - val_loss: 0.2276 - val_accuracy: 0.9040\n",
      "Epoch 503/1000\n",
      "21/21 [==============================] - 1s 63ms/step - loss: 0.2500 - accuracy: 0.8919 - val_loss: 0.2248 - val_accuracy: 0.9052\n",
      "Epoch 504/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2672 - accuracy: 0.8872 - val_loss: 0.2331 - val_accuracy: 0.9048\n",
      "Epoch 505/1000\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 0.2553 - accuracy: 0.8936 - val_loss: 0.2280 - val_accuracy: 0.9088\n",
      "Epoch 506/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2474 - accuracy: 0.8951 - val_loss: 0.2270 - val_accuracy: 0.9084\n",
      "Epoch 507/1000\n",
      "21/21 [==============================] - 1s 53ms/step - loss: 0.2536 - accuracy: 0.8930 - val_loss: 0.2296 - val_accuracy: 0.9036\n",
      "Epoch 508/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2721 - accuracy: 0.8844 - val_loss: 0.2302 - val_accuracy: 0.9076\n",
      "Epoch 509/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2618 - accuracy: 0.8865 - val_loss: 0.2331 - val_accuracy: 0.9036\n",
      "Epoch 510/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2524 - accuracy: 0.8908 - val_loss: 0.2255 - val_accuracy: 0.9076\n",
      "Epoch 511/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.2496 - accuracy: 0.8950 - val_loss: 0.2255 - val_accuracy: 0.9068\n",
      "Epoch 512/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2516 - accuracy: 0.8923 - val_loss: 0.2267 - val_accuracy: 0.9040\n",
      "Epoch 513/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.2631 - accuracy: 0.8862 - val_loss: 0.2366 - val_accuracy: 0.9024\n",
      "Epoch 514/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2520 - accuracy: 0.8940 - val_loss: 0.2302 - val_accuracy: 0.9036\n",
      "Epoch 515/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2457 - accuracy: 0.8946 - val_loss: 0.2259 - val_accuracy: 0.9064\n",
      "Epoch 516/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2500 - accuracy: 0.8918 - val_loss: 0.2268 - val_accuracy: 0.9052\n",
      "Epoch 517/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2525 - accuracy: 0.8938 - val_loss: 0.2279 - val_accuracy: 0.9048\n",
      "Epoch 518/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2532 - accuracy: 0.8937 - val_loss: 0.2296 - val_accuracy: 0.9020\n",
      "Epoch 519/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2473 - accuracy: 0.8940 - val_loss: 0.2206 - val_accuracy: 0.9076\n",
      "Epoch 520/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2515 - accuracy: 0.8939 - val_loss: 0.2234 - val_accuracy: 0.9080\n",
      "Epoch 521/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2436 - accuracy: 0.8939 - val_loss: 0.2220 - val_accuracy: 0.9068\n",
      "Epoch 522/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2950 - accuracy: 0.8713 - val_loss: 0.2873 - val_accuracy: 0.8681\n",
      "Epoch 523/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2848 - accuracy: 0.8777 - val_loss: 0.2501 - val_accuracy: 0.8904\n",
      "Epoch 524/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2724 - accuracy: 0.8814 - val_loss: 0.2405 - val_accuracy: 0.8940\n",
      "Epoch 525/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.3306 - accuracy: 0.8544 - val_loss: 0.2725 - val_accuracy: 0.8840\n",
      "Epoch 526/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.3387 - accuracy: 0.8488 - val_loss: 0.2995 - val_accuracy: 0.8697\n",
      "Epoch 527/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.3250 - accuracy: 0.8507 - val_loss: 0.2867 - val_accuracy: 0.8697\n",
      "Epoch 528/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2963 - accuracy: 0.8673 - val_loss: 0.2564 - val_accuracy: 0.8904\n",
      "Epoch 529/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2822 - accuracy: 0.8762 - val_loss: 0.2505 - val_accuracy: 0.8972\n",
      "Epoch 530/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2847 - accuracy: 0.8775 - val_loss: 0.2457 - val_accuracy: 0.9004\n",
      "Epoch 531/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2667 - accuracy: 0.8876 - val_loss: 0.2411 - val_accuracy: 0.9000\n",
      "Epoch 532/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2668 - accuracy: 0.8872 - val_loss: 0.2469 - val_accuracy: 0.8960\n",
      "Epoch 533/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.3795 - accuracy: 0.8279 - val_loss: 0.3224 - val_accuracy: 0.8465\n",
      "Epoch 534/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.3122 - accuracy: 0.8558 - val_loss: 0.2573 - val_accuracy: 0.8960\n",
      "Epoch 535/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2759 - accuracy: 0.8779 - val_loss: 0.2443 - val_accuracy: 0.9024\n",
      "Epoch 536/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2837 - accuracy: 0.8762 - val_loss: 0.2499 - val_accuracy: 0.8940\n",
      "Epoch 537/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2720 - accuracy: 0.8819 - val_loss: 0.2376 - val_accuracy: 0.9056\n",
      "Epoch 538/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2621 - accuracy: 0.8867 - val_loss: 0.2334 - val_accuracy: 0.9076\n",
      "Epoch 539/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2575 - accuracy: 0.8877 - val_loss: 0.2320 - val_accuracy: 0.9044\n",
      "Epoch 540/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2599 - accuracy: 0.8902 - val_loss: 0.2296 - val_accuracy: 0.9044\n",
      "Epoch 541/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2628 - accuracy: 0.8879 - val_loss: 0.2379 - val_accuracy: 0.8976\n",
      "Epoch 542/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2608 - accuracy: 0.8867 - val_loss: 0.2347 - val_accuracy: 0.9000\n",
      "Epoch 543/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2525 - accuracy: 0.8926 - val_loss: 0.2271 - val_accuracy: 0.9064\n",
      "Epoch 544/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.2602 - accuracy: 0.8856 - val_loss: 0.2247 - val_accuracy: 0.9076\n",
      "Epoch 545/1000\n",
      "21/21 [==============================] - 1s 52ms/step - loss: 0.2565 - accuracy: 0.8872 - val_loss: 0.2222 - val_accuracy: 0.9048\n",
      "Epoch 546/1000\n",
      "21/21 [==============================] - 1s 54ms/step - loss: 0.2608 - accuracy: 0.8860 - val_loss: 0.2246 - val_accuracy: 0.8976\n",
      "Epoch 547/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2524 - accuracy: 0.8907 - val_loss: 0.2192 - val_accuracy: 0.9044\n",
      "Epoch 548/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2440 - accuracy: 0.8934 - val_loss: 0.2214 - val_accuracy: 0.9020\n",
      "Epoch 549/1000\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.2551 - accuracy: 0.8900 - val_loss: 0.2280 - val_accuracy: 0.9036\n",
      "Epoch 550/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2626 - accuracy: 0.8867 - val_loss: 0.2290 - val_accuracy: 0.9024\n",
      "Epoch 551/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2579 - accuracy: 0.8891 - val_loss: 0.2234 - val_accuracy: 0.9048\n",
      "Epoch 552/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2417 - accuracy: 0.8972 - val_loss: 0.2221 - val_accuracy: 0.9084\n",
      "Epoch 553/1000\n",
      "21/21 [==============================] - 1s 64ms/step - loss: 0.2414 - accuracy: 0.8988 - val_loss: 0.2189 - val_accuracy: 0.9088\n",
      "Epoch 554/1000\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 0.2451 - accuracy: 0.8944 - val_loss: 0.2203 - val_accuracy: 0.9088\n",
      "Epoch 555/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.2432 - accuracy: 0.8942 - val_loss: 0.2235 - val_accuracy: 0.9080\n",
      "Epoch 556/1000\n",
      "21/21 [==============================] - 1s 57ms/step - loss: 0.2555 - accuracy: 0.8906 - val_loss: 0.2250 - val_accuracy: 0.9008\n",
      "Epoch 557/1000\n",
      "21/21 [==============================] - 1s 66ms/step - loss: 0.2567 - accuracy: 0.8882 - val_loss: 0.2252 - val_accuracy: 0.9020\n",
      "Epoch 558/1000\n",
      "21/21 [==============================] - 1s 66ms/step - loss: 0.2624 - accuracy: 0.8887 - val_loss: 0.2331 - val_accuracy: 0.9020\n",
      "Epoch 559/1000\n",
      "21/21 [==============================] - 1s 67ms/step - loss: 0.2497 - accuracy: 0.8918 - val_loss: 0.2205 - val_accuracy: 0.9100\n",
      "Epoch 560/1000\n",
      "21/21 [==============================] - 2s 79ms/step - loss: 0.2393 - accuracy: 0.8992 - val_loss: 0.2208 - val_accuracy: 0.9100\n",
      "Epoch 561/1000\n",
      "21/21 [==============================] - 1s 65ms/step - loss: 0.2449 - accuracy: 0.8929 - val_loss: 0.2282 - val_accuracy: 0.9116\n",
      "Epoch 562/1000\n",
      "21/21 [==============================] - 1s 56ms/step - loss: 0.2683 - accuracy: 0.8843 - val_loss: 0.2288 - val_accuracy: 0.9052\n",
      "Epoch 563/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 64ms/step - loss: 0.2707 - accuracy: 0.8835 - val_loss: 0.2504 - val_accuracy: 0.9016\n",
      "Epoch 564/1000\n",
      "21/21 [==============================] - 1s 61ms/step - loss: 0.2618 - accuracy: 0.8895 - val_loss: 0.2311 - val_accuracy: 0.9008\n",
      "Epoch 565/1000\n",
      "21/21 [==============================] - 1s 62ms/step - loss: 0.2503 - accuracy: 0.8929 - val_loss: 0.2261 - val_accuracy: 0.9040\n",
      "Epoch 566/1000\n",
      "21/21 [==============================] - 1s 59ms/step - loss: 0.2408 - accuracy: 0.8968 - val_loss: 0.2214 - val_accuracy: 0.9084\n",
      "Epoch 567/1000\n",
      "21/21 [==============================] - 1s 63ms/step - loss: 0.2437 - accuracy: 0.8954 - val_loss: 0.2205 - val_accuracy: 0.9108\n",
      "Epoch 568/1000\n",
      "21/21 [==============================] - 1s 65ms/step - loss: 0.2425 - accuracy: 0.8959 - val_loss: 0.2179 - val_accuracy: 0.9104\n",
      "Epoch 569/1000\n",
      "21/21 [==============================] - 1s 64ms/step - loss: 0.2431 - accuracy: 0.8965 - val_loss: 0.2191 - val_accuracy: 0.9084\n",
      "Epoch 570/1000\n",
      "21/21 [==============================] - 1s 63ms/step - loss: 0.2412 - accuracy: 0.8967 - val_loss: 0.2183 - val_accuracy: 0.9120\n",
      "Epoch 571/1000\n",
      "21/21 [==============================] - 1s 63ms/step - loss: 0.2369 - accuracy: 0.8970 - val_loss: 0.2169 - val_accuracy: 0.9068\n",
      "Epoch 572/1000\n",
      "21/21 [==============================] - 1s 60ms/step - loss: 0.2492 - accuracy: 0.8950 - val_loss: 0.2210 - val_accuracy: 0.9112\n",
      "Epoch 573/1000\n",
      "21/21 [==============================] - 1s 64ms/step - loss: 0.2414 - accuracy: 0.8952 - val_loss: 0.2190 - val_accuracy: 0.9112\n",
      "Epoch 574/1000\n",
      "21/21 [==============================] - 1s 61ms/step - loss: 0.3525 - accuracy: 0.8435 - val_loss: 0.3121 - val_accuracy: 0.8625\n",
      "Epoch 575/1000\n",
      "21/21 [==============================] - 1s 54ms/step - loss: 0.3070 - accuracy: 0.8634 - val_loss: 0.2454 - val_accuracy: 0.8884\n",
      "Epoch 576/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2612 - accuracy: 0.8851 - val_loss: 0.2313 - val_accuracy: 0.8988\n",
      "Epoch 577/1000\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 0.2497 - accuracy: 0.8960 - val_loss: 0.2251 - val_accuracy: 0.9064\n",
      "Epoch 578/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2467 - accuracy: 0.8935 - val_loss: 0.2223 - val_accuracy: 0.9056\n",
      "Epoch 579/1000\n",
      "21/21 [==============================] - 1s 52ms/step - loss: 0.2634 - accuracy: 0.8853 - val_loss: 0.2288 - val_accuracy: 0.9056\n",
      "Epoch 580/1000\n",
      "21/21 [==============================] - 1s 57ms/step - loss: 0.2514 - accuracy: 0.8903 - val_loss: 0.2231 - val_accuracy: 0.9108\n",
      "Epoch 581/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.2431 - accuracy: 0.8973 - val_loss: 0.2233 - val_accuracy: 0.9100\n",
      "Epoch 582/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.2456 - accuracy: 0.8961 - val_loss: 0.2204 - val_accuracy: 0.9088\n",
      "Epoch 583/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2444 - accuracy: 0.8958 - val_loss: 0.2203 - val_accuracy: 0.9072\n",
      "Epoch 584/1000\n",
      "21/21 [==============================] - 1s 55ms/step - loss: 0.2407 - accuracy: 0.9018 - val_loss: 0.2174 - val_accuracy: 0.9116\n",
      "Epoch 585/1000\n",
      "21/21 [==============================] - 1s 56ms/step - loss: 0.2370 - accuracy: 0.9015 - val_loss: 0.2236 - val_accuracy: 0.9092\n",
      "Epoch 586/1000\n",
      "21/21 [==============================] - 1s 53ms/step - loss: 0.2474 - accuracy: 0.8977 - val_loss: 0.2221 - val_accuracy: 0.9040\n",
      "Epoch 587/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2414 - accuracy: 0.8950 - val_loss: 0.2156 - val_accuracy: 0.9116\n",
      "Epoch 588/1000\n",
      "21/21 [==============================] - 1s 54ms/step - loss: 0.2397 - accuracy: 0.8976 - val_loss: 0.2145 - val_accuracy: 0.9108\n",
      "Epoch 589/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2547 - accuracy: 0.8896 - val_loss: 0.2273 - val_accuracy: 0.9064\n",
      "Epoch 590/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2552 - accuracy: 0.8901 - val_loss: 0.2188 - val_accuracy: 0.9112\n",
      "Epoch 591/1000\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.2395 - accuracy: 0.8979 - val_loss: 0.2172 - val_accuracy: 0.9116\n",
      "Epoch 592/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2460 - accuracy: 0.8955 - val_loss: 0.2147 - val_accuracy: 0.9120\n",
      "Epoch 593/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2435 - accuracy: 0.8947 - val_loss: 0.2136 - val_accuracy: 0.9076\n",
      "Epoch 594/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2432 - accuracy: 0.8969 - val_loss: 0.2115 - val_accuracy: 0.9100\n",
      "Epoch 595/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2357 - accuracy: 0.8991 - val_loss: 0.2124 - val_accuracy: 0.9120\n",
      "Epoch 596/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2426 - accuracy: 0.8957 - val_loss: 0.2189 - val_accuracy: 0.9120\n",
      "Epoch 597/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2369 - accuracy: 0.9012 - val_loss: 0.2181 - val_accuracy: 0.9108\n",
      "Epoch 598/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.2410 - accuracy: 0.8986 - val_loss: 0.2122 - val_accuracy: 0.9136\n",
      "Epoch 599/1000\n",
      "21/21 [==============================] - 1s 56ms/step - loss: 0.2571 - accuracy: 0.8908 - val_loss: 0.2269 - val_accuracy: 0.9104\n",
      "Epoch 600/1000\n",
      "21/21 [==============================] - 1s 54ms/step - loss: 0.2468 - accuracy: 0.8964 - val_loss: 0.2184 - val_accuracy: 0.9100\n",
      "Epoch 601/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2519 - accuracy: 0.8904 - val_loss: 0.2192 - val_accuracy: 0.9128\n",
      "Epoch 602/1000\n",
      "21/21 [==============================] - 1s 64ms/step - loss: 0.2402 - accuracy: 0.8988 - val_loss: 0.2138 - val_accuracy: 0.9128\n",
      "Epoch 603/1000\n",
      "21/21 [==============================] - 1s 63ms/step - loss: 0.2442 - accuracy: 0.8937 - val_loss: 0.2106 - val_accuracy: 0.9124\n",
      "Epoch 604/1000\n",
      "21/21 [==============================] - 1s 53ms/step - loss: 0.2371 - accuracy: 0.9016 - val_loss: 0.2102 - val_accuracy: 0.9132\n",
      "Epoch 605/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2384 - accuracy: 0.8990 - val_loss: 0.2119 - val_accuracy: 0.9096\n",
      "Epoch 606/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2319 - accuracy: 0.9022 - val_loss: 0.2156 - val_accuracy: 0.9136\n",
      "Epoch 607/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2369 - accuracy: 0.9002 - val_loss: 0.2116 - val_accuracy: 0.9136\n",
      "Epoch 608/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2334 - accuracy: 0.9011 - val_loss: 0.2109 - val_accuracy: 0.9140\n",
      "Epoch 609/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2474 - accuracy: 0.8974 - val_loss: 0.2225 - val_accuracy: 0.9056\n",
      "Epoch 610/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2397 - accuracy: 0.9007 - val_loss: 0.2119 - val_accuracy: 0.9132\n",
      "Epoch 611/1000\n",
      "21/21 [==============================] - 1s 60ms/step - loss: 0.2325 - accuracy: 0.9004 - val_loss: 0.2093 - val_accuracy: 0.9152\n",
      "Epoch 612/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.2355 - accuracy: 0.9008 - val_loss: 0.2121 - val_accuracy: 0.9132\n",
      "Epoch 613/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2300 - accuracy: 0.9029 - val_loss: 0.2082 - val_accuracy: 0.9120\n",
      "Epoch 614/1000\n",
      "21/21 [==============================] - 1s 55ms/step - loss: 0.2302 - accuracy: 0.9043 - val_loss: 0.2108 - val_accuracy: 0.9088\n",
      "Epoch 615/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.2672 - accuracy: 0.8836 - val_loss: 0.2254 - val_accuracy: 0.9068\n",
      "Epoch 616/1000\n",
      "21/21 [==============================] - 1s 53ms/step - loss: 0.2475 - accuracy: 0.8950 - val_loss: 0.2158 - val_accuracy: 0.9120\n",
      "Epoch 617/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.2404 - accuracy: 0.8992 - val_loss: 0.2137 - val_accuracy: 0.9136\n",
      "Epoch 618/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2367 - accuracy: 0.9015 - val_loss: 0.2157 - val_accuracy: 0.9124\n",
      "Epoch 619/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.2544 - accuracy: 0.8924 - val_loss: 0.2309 - val_accuracy: 0.9032\n",
      "Epoch 620/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2395 - accuracy: 0.8988 - val_loss: 0.2148 - val_accuracy: 0.9148\n",
      "Epoch 621/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2360 - accuracy: 0.9015 - val_loss: 0.2265 - val_accuracy: 0.9132\n",
      "Epoch 622/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2928 - accuracy: 0.8710 - val_loss: 0.2437 - val_accuracy: 0.8944\n",
      "Epoch 623/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2702 - accuracy: 0.8861 - val_loss: 0.2242 - val_accuracy: 0.9056\n",
      "Epoch 624/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2486 - accuracy: 0.8949 - val_loss: 0.2154 - val_accuracy: 0.9144\n",
      "Epoch 625/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2519 - accuracy: 0.8911 - val_loss: 0.2249 - val_accuracy: 0.9100\n",
      "Epoch 626/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2624 - accuracy: 0.8858 - val_loss: 0.2294 - val_accuracy: 0.9036\n",
      "Epoch 627/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2439 - accuracy: 0.8937 - val_loss: 0.2187 - val_accuracy: 0.9104\n",
      "Epoch 628/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2414 - accuracy: 0.8979 - val_loss: 0.2150 - val_accuracy: 0.9152\n",
      "Epoch 629/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2352 - accuracy: 0.9026 - val_loss: 0.2160 - val_accuracy: 0.9136\n",
      "Epoch 630/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2310 - accuracy: 0.9034 - val_loss: 0.2124 - val_accuracy: 0.9164\n",
      "Epoch 631/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2393 - accuracy: 0.9000 - val_loss: 0.2128 - val_accuracy: 0.9144\n",
      "Epoch 632/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2363 - accuracy: 0.8989 - val_loss: 0.2129 - val_accuracy: 0.9148\n",
      "Epoch 633/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.2373 - accuracy: 0.9003 - val_loss: 0.2105 - val_accuracy: 0.9144\n",
      "Epoch 634/1000\n",
      "21/21 [==============================] - 1s 54ms/step - loss: 0.2309 - accuracy: 0.9020 - val_loss: 0.2114 - val_accuracy: 0.9136\n",
      "Epoch 635/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.2357 - accuracy: 0.8998 - val_loss: 0.2117 - val_accuracy: 0.9144\n",
      "Epoch 636/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2352 - accuracy: 0.9017 - val_loss: 0.2124 - val_accuracy: 0.9120\n",
      "Epoch 637/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2351 - accuracy: 0.9022 - val_loss: 0.2121 - val_accuracy: 0.9140\n",
      "Epoch 638/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2318 - accuracy: 0.9024 - val_loss: 0.2112 - val_accuracy: 0.9164\n",
      "Epoch 639/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2336 - accuracy: 0.9022 - val_loss: 0.2115 - val_accuracy: 0.9132\n",
      "Epoch 640/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2295 - accuracy: 0.9024 - val_loss: 0.2106 - val_accuracy: 0.9148\n",
      "Epoch 641/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2366 - accuracy: 0.9012 - val_loss: 0.2089 - val_accuracy: 0.9156\n",
      "Epoch 642/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2308 - accuracy: 0.8992 - val_loss: 0.2108 - val_accuracy: 0.9140\n",
      "Epoch 643/1000\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 0.2310 - accuracy: 0.9054 - val_loss: 0.2072 - val_accuracy: 0.9164\n",
      "Epoch 644/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2291 - accuracy: 0.9059 - val_loss: 0.2080 - val_accuracy: 0.9148\n",
      "Epoch 645/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2296 - accuracy: 0.9011 - val_loss: 0.2090 - val_accuracy: 0.9152\n",
      "Epoch 646/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2283 - accuracy: 0.9059 - val_loss: 0.2087 - val_accuracy: 0.9164\n",
      "Epoch 647/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2310 - accuracy: 0.9019 - val_loss: 0.2057 - val_accuracy: 0.9180\n",
      "Epoch 648/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2366 - accuracy: 0.8997 - val_loss: 0.2041 - val_accuracy: 0.9212\n",
      "Epoch 649/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2300 - accuracy: 0.9065 - val_loss: 0.2056 - val_accuracy: 0.9176\n",
      "Epoch 650/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2462 - accuracy: 0.8935 - val_loss: 0.2182 - val_accuracy: 0.9116\n",
      "Epoch 651/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2442 - accuracy: 0.8951 - val_loss: 0.2121 - val_accuracy: 0.9124\n",
      "Epoch 652/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2410 - accuracy: 0.8961 - val_loss: 0.2094 - val_accuracy: 0.9112\n",
      "Epoch 653/1000\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.2400 - accuracy: 0.8982 - val_loss: 0.2109 - val_accuracy: 0.9116\n",
      "Epoch 654/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2364 - accuracy: 0.8983 - val_loss: 0.2120 - val_accuracy: 0.9096\n",
      "Epoch 655/1000\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.2383 - accuracy: 0.8984 - val_loss: 0.2121 - val_accuracy: 0.9128\n",
      "Epoch 656/1000\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.2310 - accuracy: 0.9030 - val_loss: 0.2090 - val_accuracy: 0.9124\n",
      "Epoch 657/1000\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.2457 - accuracy: 0.8963 - val_loss: 0.2184 - val_accuracy: 0.9124\n",
      "Epoch 658/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2437 - accuracy: 0.8973 - val_loss: 0.2109 - val_accuracy: 0.9188\n",
      "Epoch 659/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2333 - accuracy: 0.9030 - val_loss: 0.2096 - val_accuracy: 0.9132\n",
      "Epoch 660/1000\n",
      "21/21 [==============================] - 1s 67ms/step - loss: 0.2705 - accuracy: 0.8823 - val_loss: 0.2278 - val_accuracy: 0.9072\n",
      "Epoch 661/1000\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 0.2424 - accuracy: 0.8964 - val_loss: 0.2223 - val_accuracy: 0.9076\n",
      "Epoch 662/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.3177 - accuracy: 0.8661 - val_loss: 0.2903 - val_accuracy: 0.8749\n",
      "Epoch 663/1000\n",
      "21/21 [==============================] - 1s 54ms/step - loss: 0.3149 - accuracy: 0.8641 - val_loss: 0.2637 - val_accuracy: 0.8780\n",
      "Epoch 664/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.2762 - accuracy: 0.8799 - val_loss: 0.2320 - val_accuracy: 0.8940\n",
      "Epoch 665/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2465 - accuracy: 0.8980 - val_loss: 0.2206 - val_accuracy: 0.8992\n",
      "Epoch 666/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2468 - accuracy: 0.8958 - val_loss: 0.2219 - val_accuracy: 0.9064\n",
      "Epoch 667/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2451 - accuracy: 0.8927 - val_loss: 0.2178 - val_accuracy: 0.9060\n",
      "Epoch 668/1000\n",
      "21/21 [==============================] - 1s 57ms/step - loss: 0.2323 - accuracy: 0.9026 - val_loss: 0.2143 - val_accuracy: 0.9084\n",
      "Epoch 669/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.2342 - accuracy: 0.8990 - val_loss: 0.2138 - val_accuracy: 0.9084\n",
      "Epoch 670/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2567 - accuracy: 0.8861 - val_loss: 0.2304 - val_accuracy: 0.9004\n",
      "Epoch 671/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2798 - accuracy: 0.8747 - val_loss: 0.2348 - val_accuracy: 0.8996\n",
      "Epoch 672/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2586 - accuracy: 0.8880 - val_loss: 0.2246 - val_accuracy: 0.8980\n",
      "Epoch 673/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2592 - accuracy: 0.8905 - val_loss: 0.2310 - val_accuracy: 0.9016\n",
      "Epoch 674/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.2491 - accuracy: 0.8940 - val_loss: 0.2230 - val_accuracy: 0.9048\n",
      "Epoch 675/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2453 - accuracy: 0.8954 - val_loss: 0.2251 - val_accuracy: 0.9076\n",
      "Epoch 676/1000\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 0.2340 - accuracy: 0.9043 - val_loss: 0.2154 - val_accuracy: 0.9084\n",
      "Epoch 677/1000\n",
      "21/21 [==============================] - 1s 61ms/step - loss: 0.2370 - accuracy: 0.9002 - val_loss: 0.2131 - val_accuracy: 0.9084\n",
      "Epoch 678/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2327 - accuracy: 0.9004 - val_loss: 0.2142 - val_accuracy: 0.9112\n",
      "Epoch 679/1000\n",
      "21/21 [==============================] - 1s 56ms/step - loss: 0.2329 - accuracy: 0.9018 - val_loss: 0.2117 - val_accuracy: 0.9112\n",
      "Epoch 680/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2320 - accuracy: 0.9032 - val_loss: 0.2124 - val_accuracy: 0.9104\n",
      "Epoch 681/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.2333 - accuracy: 0.8983 - val_loss: 0.2129 - val_accuracy: 0.9088\n",
      "Epoch 682/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.2253 - accuracy: 0.9031 - val_loss: 0.2120 - val_accuracy: 0.9120\n",
      "Epoch 683/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2440 - accuracy: 0.8936 - val_loss: 0.2260 - val_accuracy: 0.9036\n",
      "Epoch 684/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2386 - accuracy: 0.8986 - val_loss: 0.2167 - val_accuracy: 0.9108\n",
      "Epoch 685/1000\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.2324 - accuracy: 0.9012 - val_loss: 0.2125 - val_accuracy: 0.9136\n",
      "Epoch 686/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2271 - accuracy: 0.9035 - val_loss: 0.2119 - val_accuracy: 0.9136\n",
      "Epoch 687/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2214 - accuracy: 0.9052 - val_loss: 0.2102 - val_accuracy: 0.9152\n",
      "Epoch 688/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2264 - accuracy: 0.9048 - val_loss: 0.2089 - val_accuracy: 0.9200\n",
      "Epoch 689/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2197 - accuracy: 0.9095 - val_loss: 0.2190 - val_accuracy: 0.9124\n",
      "Epoch 690/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.3170 - accuracy: 0.8672 - val_loss: 0.2765 - val_accuracy: 0.8856\n",
      "Epoch 691/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2767 - accuracy: 0.8830 - val_loss: 0.2344 - val_accuracy: 0.9012\n",
      "Epoch 692/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2485 - accuracy: 0.8959 - val_loss: 0.2242 - val_accuracy: 0.9044\n",
      "Epoch 693/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2413 - accuracy: 0.8965 - val_loss: 0.2192 - val_accuracy: 0.9048\n",
      "Epoch 694/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2383 - accuracy: 0.8990 - val_loss: 0.2207 - val_accuracy: 0.9072\n",
      "Epoch 695/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2410 - accuracy: 0.8960 - val_loss: 0.2264 - val_accuracy: 0.9064\n",
      "Epoch 696/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2587 - accuracy: 0.8890 - val_loss: 0.2461 - val_accuracy: 0.8960\n",
      "Epoch 697/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2917 - accuracy: 0.8741 - val_loss: 0.2446 - val_accuracy: 0.8996\n",
      "Epoch 698/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2502 - accuracy: 0.8938 - val_loss: 0.2239 - val_accuracy: 0.9104\n",
      "Epoch 699/1000\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.2414 - accuracy: 0.8999 - val_loss: 0.2192 - val_accuracy: 0.9116\n",
      "Epoch 700/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2319 - accuracy: 0.9035 - val_loss: 0.2169 - val_accuracy: 0.9096\n",
      "Epoch 701/1000\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.2354 - accuracy: 0.9023 - val_loss: 0.2158 - val_accuracy: 0.9124\n",
      "Epoch 702/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2259 - accuracy: 0.9047 - val_loss: 0.2151 - val_accuracy: 0.9120\n",
      "Epoch 703/1000\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.2419 - accuracy: 0.8954 - val_loss: 0.2289 - val_accuracy: 0.9056\n",
      "Epoch 704/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2402 - accuracy: 0.8974 - val_loss: 0.2179 - val_accuracy: 0.9084\n",
      "Epoch 705/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2300 - accuracy: 0.9026 - val_loss: 0.2142 - val_accuracy: 0.9104\n",
      "Epoch 706/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2261 - accuracy: 0.9044 - val_loss: 0.2105 - val_accuracy: 0.9120\n",
      "Epoch 707/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2270 - accuracy: 0.9058 - val_loss: 0.2111 - val_accuracy: 0.9128\n",
      "Epoch 708/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2244 - accuracy: 0.9071 - val_loss: 0.2150 - val_accuracy: 0.9124\n",
      "Epoch 709/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2840 - accuracy: 0.8817 - val_loss: 0.2611 - val_accuracy: 0.9028\n",
      "Epoch 710/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2609 - accuracy: 0.8897 - val_loss: 0.2304 - val_accuracy: 0.9048\n",
      "Epoch 711/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2502 - accuracy: 0.8940 - val_loss: 0.2261 - val_accuracy: 0.9080\n",
      "Epoch 712/1000\n",
      "21/21 [==============================] - 1s 59ms/step - loss: 0.2825 - accuracy: 0.8768 - val_loss: 0.2426 - val_accuracy: 0.9000\n",
      "Epoch 713/1000\n",
      "21/21 [==============================] - 1s 54ms/step - loss: 0.2557 - accuracy: 0.8907 - val_loss: 0.2277 - val_accuracy: 0.9036\n",
      "Epoch 714/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.2425 - accuracy: 0.8950 - val_loss: 0.2285 - val_accuracy: 0.9064\n",
      "Epoch 715/1000\n",
      "21/21 [==============================] - 1s 52ms/step - loss: 0.3126 - accuracy: 0.8628 - val_loss: 0.2993 - val_accuracy: 0.8705\n",
      "Epoch 716/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.3724 - accuracy: 0.8359 - val_loss: 0.3017 - val_accuracy: 0.8617\n",
      "Epoch 717/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.3049 - accuracy: 0.8666 - val_loss: 0.2742 - val_accuracy: 0.8784\n",
      "Epoch 718/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2786 - accuracy: 0.8811 - val_loss: 0.2587 - val_accuracy: 0.8904\n",
      "Epoch 719/1000\n",
      "21/21 [==============================] - 1s 55ms/step - loss: 0.2690 - accuracy: 0.8842 - val_loss: 0.2367 - val_accuracy: 0.9052\n",
      "Epoch 720/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2485 - accuracy: 0.8922 - val_loss: 0.2271 - val_accuracy: 0.9088\n",
      "Epoch 721/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2546 - accuracy: 0.8894 - val_loss: 0.2300 - val_accuracy: 0.9056\n",
      "Epoch 722/1000\n",
      "21/21 [==============================] - 1s 57ms/step - loss: 0.2489 - accuracy: 0.8949 - val_loss: 0.2271 - val_accuracy: 0.9040\n",
      "Epoch 723/1000\n",
      "21/21 [==============================] - 1s 57ms/step - loss: 0.2412 - accuracy: 0.8961 - val_loss: 0.2211 - val_accuracy: 0.9092\n",
      "Epoch 724/1000\n",
      "21/21 [==============================] - 1s 62ms/step - loss: 0.2397 - accuracy: 0.8991 - val_loss: 0.2264 - val_accuracy: 0.9028\n",
      "Epoch 725/1000\n",
      "21/21 [==============================] - 1s 63ms/step - loss: 0.2980 - accuracy: 0.8675 - val_loss: 0.2556 - val_accuracy: 0.8932\n",
      "Epoch 726/1000\n",
      "21/21 [==============================] - 1s 59ms/step - loss: 0.2561 - accuracy: 0.8865 - val_loss: 0.2282 - val_accuracy: 0.9104\n",
      "Epoch 727/1000\n",
      "21/21 [==============================] - 1s 56ms/step - loss: 0.2626 - accuracy: 0.8872 - val_loss: 0.2272 - val_accuracy: 0.9028\n",
      "Epoch 728/1000\n",
      "21/21 [==============================] - 1s 54ms/step - loss: 0.2533 - accuracy: 0.8901 - val_loss: 0.2217 - val_accuracy: 0.9092\n",
      "Epoch 729/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.2395 - accuracy: 0.8957 - val_loss: 0.2182 - val_accuracy: 0.9112\n",
      "Epoch 730/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.2403 - accuracy: 0.8973 - val_loss: 0.2227 - val_accuracy: 0.9052\n",
      "Epoch 731/1000\n",
      "21/21 [==============================] - 1s 62ms/step - loss: 0.2407 - accuracy: 0.9003 - val_loss: 0.2196 - val_accuracy: 0.9064\n",
      "Epoch 732/1000\n",
      "21/21 [==============================] - 1s 62ms/step - loss: 0.2408 - accuracy: 0.8947 - val_loss: 0.2165 - val_accuracy: 0.9108\n",
      "Epoch 733/1000\n",
      "21/21 [==============================] - 1s 64ms/step - loss: 0.2338 - accuracy: 0.8990 - val_loss: 0.2175 - val_accuracy: 0.9080\n",
      "Epoch 734/1000\n",
      "21/21 [==============================] - 1s 65ms/step - loss: 0.2383 - accuracy: 0.8998 - val_loss: 0.2148 - val_accuracy: 0.9140\n",
      "Epoch 735/1000\n",
      "21/21 [==============================] - 2s 87ms/step - loss: 0.2260 - accuracy: 0.9040 - val_loss: 0.2139 - val_accuracy: 0.9148\n",
      "Epoch 736/1000\n",
      "21/21 [==============================] - 2s 76ms/step - loss: 0.2641 - accuracy: 0.8865 - val_loss: 0.2409 - val_accuracy: 0.8992\n",
      "Epoch 737/1000\n",
      "21/21 [==============================] - 1s 63ms/step - loss: 0.2481 - accuracy: 0.8930 - val_loss: 0.2236 - val_accuracy: 0.9092\n",
      "Epoch 738/1000\n",
      "21/21 [==============================] - 1s 62ms/step - loss: 0.2677 - accuracy: 0.8815 - val_loss: 0.2441 - val_accuracy: 0.8892\n",
      "Epoch 739/1000\n",
      "21/21 [==============================] - 1s 56ms/step - loss: 0.2501 - accuracy: 0.8922 - val_loss: 0.2211 - val_accuracy: 0.9052\n",
      "Epoch 740/1000\n",
      "21/21 [==============================] - 1s 57ms/step - loss: 0.2416 - accuracy: 0.8976 - val_loss: 0.2158 - val_accuracy: 0.9096\n",
      "Epoch 741/1000\n",
      "21/21 [==============================] - 1s 61ms/step - loss: 0.2475 - accuracy: 0.8927 - val_loss: 0.2183 - val_accuracy: 0.9052\n",
      "Epoch 742/1000\n",
      "21/21 [==============================] - 1s 65ms/step - loss: 0.2419 - accuracy: 0.8973 - val_loss: 0.2123 - val_accuracy: 0.9116\n",
      "Epoch 743/1000\n",
      "21/21 [==============================] - 1s 72ms/step - loss: 0.2266 - accuracy: 0.9051 - val_loss: 0.2115 - val_accuracy: 0.9104\n",
      "Epoch 744/1000\n",
      "21/21 [==============================] - 1s 61ms/step - loss: 0.2431 - accuracy: 0.8957 - val_loss: 0.2210 - val_accuracy: 0.9048\n",
      "Epoch 745/1000\n",
      "21/21 [==============================] - 1s 61ms/step - loss: 0.2482 - accuracy: 0.8958 - val_loss: 0.2205 - val_accuracy: 0.9060\n",
      "Epoch 746/1000\n",
      "21/21 [==============================] - 2s 73ms/step - loss: 0.2340 - accuracy: 0.8986 - val_loss: 0.2114 - val_accuracy: 0.9148\n",
      "Epoch 747/1000\n",
      "21/21 [==============================] - 2s 80ms/step - loss: 0.2307 - accuracy: 0.9039 - val_loss: 0.2109 - val_accuracy: 0.9148\n",
      "Epoch 748/1000\n",
      "21/21 [==============================] - 2s 74ms/step - loss: 0.2395 - accuracy: 0.8973 - val_loss: 0.2200 - val_accuracy: 0.9056\n",
      "Epoch 749/1000\n",
      "21/21 [==============================] - 1s 71ms/step - loss: 0.2357 - accuracy: 0.8978 - val_loss: 0.2104 - val_accuracy: 0.9136\n",
      "Epoch 750/1000\n",
      "21/21 [==============================] - 2s 79ms/step - loss: 0.2259 - accuracy: 0.9036 - val_loss: 0.2075 - val_accuracy: 0.9140\n",
      "Epoch 751/1000\n",
      "21/21 [==============================] - 2s 79ms/step - loss: 0.2243 - accuracy: 0.9064 - val_loss: 0.2054 - val_accuracy: 0.9140\n",
      "Epoch 752/1000\n",
      "21/21 [==============================] - 2s 83ms/step - loss: 0.2303 - accuracy: 0.9006 - val_loss: 0.2069 - val_accuracy: 0.9136\n",
      "Epoch 753/1000\n",
      "21/21 [==============================] - 2s 74ms/step - loss: 0.2276 - accuracy: 0.9025 - val_loss: 0.2067 - val_accuracy: 0.9116\n",
      "Epoch 754/1000\n",
      "21/21 [==============================] - 2s 78ms/step - loss: 0.2258 - accuracy: 0.9022 - val_loss: 0.2099 - val_accuracy: 0.9140\n",
      "Epoch 755/1000\n",
      "21/21 [==============================] - 1s 67ms/step - loss: 0.2204 - accuracy: 0.9067 - val_loss: 0.2056 - val_accuracy: 0.9128\n",
      "Epoch 756/1000\n",
      "21/21 [==============================] - 2s 73ms/step - loss: 0.2546 - accuracy: 0.8928 - val_loss: 0.2329 - val_accuracy: 0.9088\n",
      "Epoch 757/1000\n",
      "21/21 [==============================] - 1s 70ms/step - loss: 0.2345 - accuracy: 0.9000 - val_loss: 0.2132 - val_accuracy: 0.9140\n",
      "Epoch 758/1000\n",
      "21/21 [==============================] - 1s 69ms/step - loss: 0.2249 - accuracy: 0.9047 - val_loss: 0.2129 - val_accuracy: 0.9144\n",
      "Epoch 759/1000\n",
      "21/21 [==============================] - 1s 56ms/step - loss: 0.2250 - accuracy: 0.9078 - val_loss: 0.2073 - val_accuracy: 0.9168\n",
      "Epoch 760/1000\n",
      "21/21 [==============================] - 1s 55ms/step - loss: 0.2265 - accuracy: 0.9042 - val_loss: 0.2112 - val_accuracy: 0.9116\n",
      "Epoch 761/1000\n",
      "21/21 [==============================] - 1s 53ms/step - loss: 0.2261 - accuracy: 0.9034 - val_loss: 0.2074 - val_accuracy: 0.9140\n",
      "Epoch 762/1000\n",
      "21/21 [==============================] - 1s 56ms/step - loss: 0.2249 - accuracy: 0.9049 - val_loss: 0.2052 - val_accuracy: 0.9160\n",
      "Epoch 763/1000\n",
      "21/21 [==============================] - 1s 59ms/step - loss: 0.2202 - accuracy: 0.9052 - val_loss: 0.2044 - val_accuracy: 0.9148\n",
      "Epoch 764/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.2217 - accuracy: 0.9063 - val_loss: 0.2086 - val_accuracy: 0.9144\n",
      "Epoch 765/1000\n",
      "21/21 [==============================] - 1s 61ms/step - loss: 0.2243 - accuracy: 0.9085 - val_loss: 0.2086 - val_accuracy: 0.9140\n",
      "Epoch 766/1000\n",
      "21/21 [==============================] - 1s 58ms/step - loss: 0.2192 - accuracy: 0.9055 - val_loss: 0.2075 - val_accuracy: 0.9184\n",
      "Epoch 767/1000\n",
      "21/21 [==============================] - 1s 56ms/step - loss: 0.2170 - accuracy: 0.9083 - val_loss: 0.2050 - val_accuracy: 0.9148\n",
      "Epoch 768/1000\n",
      "21/21 [==============================] - 1s 56ms/step - loss: 0.2191 - accuracy: 0.9083 - val_loss: 0.2044 - val_accuracy: 0.9140\n",
      "Epoch 769/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.2257 - accuracy: 0.9063 - val_loss: 0.2019 - val_accuracy: 0.9192\n",
      "Epoch 770/1000\n",
      "21/21 [==============================] - 1s 57ms/step - loss: 0.2168 - accuracy: 0.9079 - val_loss: 0.2060 - val_accuracy: 0.9200\n",
      "Epoch 771/1000\n",
      "21/21 [==============================] - 1s 61ms/step - loss: 0.2233 - accuracy: 0.9065 - val_loss: 0.2093 - val_accuracy: 0.9164\n",
      "Epoch 772/1000\n",
      "21/21 [==============================] - 1s 54ms/step - loss: 0.2902 - accuracy: 0.8764 - val_loss: 0.2512 - val_accuracy: 0.8972\n",
      "Epoch 773/1000\n",
      "21/21 [==============================] - 1s 53ms/step - loss: 0.2579 - accuracy: 0.8899 - val_loss: 0.2260 - val_accuracy: 0.9088\n",
      "Epoch 774/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.2420 - accuracy: 0.8977 - val_loss: 0.2161 - val_accuracy: 0.9092\n",
      "Epoch 775/1000\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 0.2521 - accuracy: 0.8924 - val_loss: 0.2305 - val_accuracy: 0.9016\n",
      "Epoch 776/1000\n",
      "21/21 [==============================] - 1s 52ms/step - loss: 0.2381 - accuracy: 0.9016 - val_loss: 0.2154 - val_accuracy: 0.9144\n",
      "Epoch 777/1000\n",
      "21/21 [==============================] - 1s 61ms/step - loss: 0.2412 - accuracy: 0.8978 - val_loss: 0.2206 - val_accuracy: 0.9096\n",
      "Epoch 778/1000\n",
      "21/21 [==============================] - 1s 70ms/step - loss: 0.2460 - accuracy: 0.8957 - val_loss: 0.2275 - val_accuracy: 0.9024\n",
      "Epoch 779/1000\n",
      "21/21 [==============================] - 1s 71ms/step - loss: 0.2301 - accuracy: 0.9025 - val_loss: 0.2125 - val_accuracy: 0.9144\n",
      "Epoch 780/1000\n",
      "21/21 [==============================] - 1s 68ms/step - loss: 0.2215 - accuracy: 0.9065 - val_loss: 0.2077 - val_accuracy: 0.9144\n",
      "Epoch 781/1000\n",
      "21/21 [==============================] - 1s 68ms/step - loss: 0.2224 - accuracy: 0.9061 - val_loss: 0.2054 - val_accuracy: 0.9164\n",
      "Epoch 782/1000\n",
      "21/21 [==============================] - 2s 72ms/step - loss: 0.2166 - accuracy: 0.9091 - val_loss: 0.2051 - val_accuracy: 0.9164\n",
      "Epoch 783/1000\n",
      "21/21 [==============================] - 1s 68ms/step - loss: 0.2190 - accuracy: 0.9088 - val_loss: 0.2050 - val_accuracy: 0.9164\n",
      "Epoch 784/1000\n",
      "21/21 [==============================] - 1s 71ms/step - loss: 0.2184 - accuracy: 0.9063 - val_loss: 0.2064 - val_accuracy: 0.9136\n",
      "Epoch 785/1000\n",
      "21/21 [==============================] - 1s 64ms/step - loss: 0.2525 - accuracy: 0.8910 - val_loss: 0.2329 - val_accuracy: 0.8972\n",
      "Epoch 786/1000\n",
      "21/21 [==============================] - 1s 59ms/step - loss: 0.2477 - accuracy: 0.8933 - val_loss: 0.2228 - val_accuracy: 0.9052\n",
      "Epoch 787/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 53ms/step - loss: 0.2868 - accuracy: 0.8754 - val_loss: 0.2249 - val_accuracy: 0.9040\n",
      "Epoch 788/1000\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 0.2521 - accuracy: 0.8904 - val_loss: 0.2166 - val_accuracy: 0.9072\n",
      "Epoch 789/1000\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 0.2429 - accuracy: 0.8949 - val_loss: 0.2218 - val_accuracy: 0.9036\n",
      "Epoch 790/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.3093 - accuracy: 0.8628 - val_loss: 0.2683 - val_accuracy: 0.8896\n",
      "Epoch 791/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.2610 - accuracy: 0.8871 - val_loss: 0.2291 - val_accuracy: 0.9084\n",
      "Epoch 792/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2389 - accuracy: 0.8996 - val_loss: 0.2113 - val_accuracy: 0.9168\n",
      "Epoch 793/1000\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.2775 - accuracy: 0.8731 - val_loss: 0.2473 - val_accuracy: 0.8924\n",
      "Epoch 794/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2731 - accuracy: 0.8785 - val_loss: 0.2438 - val_accuracy: 0.8940\n",
      "Epoch 795/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2577 - accuracy: 0.8902 - val_loss: 0.2260 - val_accuracy: 0.9008\n",
      "Epoch 796/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2346 - accuracy: 0.9000 - val_loss: 0.2177 - val_accuracy: 0.9124\n",
      "Epoch 797/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2342 - accuracy: 0.9024 - val_loss: 0.2164 - val_accuracy: 0.9080\n",
      "Epoch 798/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2371 - accuracy: 0.8973 - val_loss: 0.2189 - val_accuracy: 0.9136\n",
      "Epoch 799/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.2309 - accuracy: 0.8994 - val_loss: 0.2139 - val_accuracy: 0.9152\n",
      "Epoch 800/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2291 - accuracy: 0.9030 - val_loss: 0.2146 - val_accuracy: 0.9128\n",
      "Epoch 801/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2253 - accuracy: 0.9077 - val_loss: 0.2081 - val_accuracy: 0.9184\n",
      "Epoch 802/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2218 - accuracy: 0.9051 - val_loss: 0.2050 - val_accuracy: 0.9184\n",
      "Epoch 803/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2258 - accuracy: 0.9052 - val_loss: 0.2045 - val_accuracy: 0.9160\n",
      "Epoch 804/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2220 - accuracy: 0.9075 - val_loss: 0.2050 - val_accuracy: 0.9156\n",
      "Epoch 805/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2217 - accuracy: 0.9073 - val_loss: 0.2066 - val_accuracy: 0.9152\n",
      "Epoch 806/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2228 - accuracy: 0.9074 - val_loss: 0.2045 - val_accuracy: 0.9160\n",
      "Epoch 807/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2230 - accuracy: 0.9072 - val_loss: 0.2047 - val_accuracy: 0.9128\n",
      "Epoch 808/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.2172 - accuracy: 0.9095 - val_loss: 0.2038 - val_accuracy: 0.9152\n",
      "Epoch 809/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2123 - accuracy: 0.9109 - val_loss: 0.2031 - val_accuracy: 0.9156\n",
      "Epoch 810/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2151 - accuracy: 0.9060 - val_loss: 0.2030 - val_accuracy: 0.9188\n",
      "Epoch 811/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2172 - accuracy: 0.9108 - val_loss: 0.2042 - val_accuracy: 0.9160\n",
      "Epoch 812/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2163 - accuracy: 0.9130 - val_loss: 0.2052 - val_accuracy: 0.9152\n",
      "Epoch 813/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2253 - accuracy: 0.9034 - val_loss: 0.2096 - val_accuracy: 0.9144\n",
      "Epoch 814/1000\n",
      "21/21 [==============================] - 1s 52ms/step - loss: 0.2302 - accuracy: 0.9032 - val_loss: 0.2079 - val_accuracy: 0.9192\n",
      "Epoch 815/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2166 - accuracy: 0.9093 - val_loss: 0.2036 - val_accuracy: 0.9196\n",
      "Epoch 816/1000\n",
      "21/21 [==============================] - 1s 53ms/step - loss: 0.2184 - accuracy: 0.9098 - val_loss: 0.2025 - val_accuracy: 0.9188\n",
      "Epoch 817/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2141 - accuracy: 0.9109 - val_loss: 0.1994 - val_accuracy: 0.9196\n",
      "Epoch 818/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2165 - accuracy: 0.9099 - val_loss: 0.2039 - val_accuracy: 0.9152\n",
      "Epoch 819/1000\n",
      "21/21 [==============================] - 1s 56ms/step - loss: 0.2152 - accuracy: 0.9082 - val_loss: 0.2118 - val_accuracy: 0.9116\n",
      "Epoch 820/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2478 - accuracy: 0.8953 - val_loss: 0.2222 - val_accuracy: 0.9060\n",
      "Epoch 821/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2268 - accuracy: 0.9019 - val_loss: 0.2038 - val_accuracy: 0.9196\n",
      "Epoch 822/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2189 - accuracy: 0.9107 - val_loss: 0.2078 - val_accuracy: 0.9160\n",
      "Epoch 823/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2330 - accuracy: 0.9010 - val_loss: 0.2152 - val_accuracy: 0.9056\n",
      "Epoch 824/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2276 - accuracy: 0.9025 - val_loss: 0.2035 - val_accuracy: 0.9128\n",
      "Epoch 825/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2213 - accuracy: 0.9084 - val_loss: 0.2059 - val_accuracy: 0.9164\n",
      "Epoch 826/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2219 - accuracy: 0.9038 - val_loss: 0.2020 - val_accuracy: 0.9164\n",
      "Epoch 827/1000\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.2141 - accuracy: 0.9091 - val_loss: 0.2025 - val_accuracy: 0.9192\n",
      "Epoch 828/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2129 - accuracy: 0.9127 - val_loss: 0.2021 - val_accuracy: 0.9172\n",
      "Epoch 829/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2155 - accuracy: 0.9087 - val_loss: 0.1998 - val_accuracy: 0.9192\n",
      "Epoch 830/1000\n",
      "21/21 [==============================] - 1s 56ms/step - loss: 0.2114 - accuracy: 0.9115 - val_loss: 0.1996 - val_accuracy: 0.9196\n",
      "Epoch 831/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2117 - accuracy: 0.9130 - val_loss: 0.2003 - val_accuracy: 0.9196\n",
      "Epoch 832/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2141 - accuracy: 0.9106 - val_loss: 0.2070 - val_accuracy: 0.9148\n",
      "Epoch 833/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2069 - accuracy: 0.9121 - val_loss: 0.2012 - val_accuracy: 0.9160\n",
      "Epoch 834/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.2236 - accuracy: 0.9034 - val_loss: 0.2032 - val_accuracy: 0.9160\n",
      "Epoch 835/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2231 - accuracy: 0.9048 - val_loss: 0.2034 - val_accuracy: 0.9152\n",
      "Epoch 836/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2193 - accuracy: 0.9061 - val_loss: 0.2008 - val_accuracy: 0.9224\n",
      "Epoch 837/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2146 - accuracy: 0.9100 - val_loss: 0.2001 - val_accuracy: 0.9200\n",
      "Epoch 838/1000\n",
      "21/21 [==============================] - 1s 56ms/step - loss: 0.2099 - accuracy: 0.9108 - val_loss: 0.2005 - val_accuracy: 0.9196\n",
      "Epoch 839/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2093 - accuracy: 0.9111 - val_loss: 0.1983 - val_accuracy: 0.9192\n",
      "Epoch 840/1000\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.2097 - accuracy: 0.9117 - val_loss: 0.1987 - val_accuracy: 0.9200\n",
      "Epoch 841/1000\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 0.2215 - accuracy: 0.9064 - val_loss: 0.2054 - val_accuracy: 0.9128\n",
      "Epoch 842/1000\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.2183 - accuracy: 0.9093 - val_loss: 0.2048 - val_accuracy: 0.9164\n",
      "Epoch 843/1000\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 0.2208 - accuracy: 0.9051 - val_loss: 0.2044 - val_accuracy: 0.9200\n",
      "Epoch 844/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.2153 - accuracy: 0.9118 - val_loss: 0.2015 - val_accuracy: 0.9216\n",
      "Epoch 845/1000\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.2165 - accuracy: 0.9082 - val_loss: 0.1985 - val_accuracy: 0.9216\n",
      "Epoch 846/1000\n",
      "21/21 [==============================] - 1s 54ms/step - loss: 0.2187 - accuracy: 0.9065 - val_loss: 0.2019 - val_accuracy: 0.9172\n",
      "Epoch 847/1000\n",
      "21/21 [==============================] - 1s 54ms/step - loss: 0.2128 - accuracy: 0.9107 - val_loss: 0.2047 - val_accuracy: 0.9200\n",
      "Epoch 848/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2126 - accuracy: 0.9111 - val_loss: 0.2055 - val_accuracy: 0.9160\n",
      "Epoch 849/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2176 - accuracy: 0.9091 - val_loss: 0.2083 - val_accuracy: 0.9184\n",
      "Epoch 850/1000\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.2148 - accuracy: 0.9100 - val_loss: 0.2020 - val_accuracy: 0.9204\n",
      "Epoch 851/1000\n",
      "21/21 [==============================] - 1s 54ms/step - loss: 0.2119 - accuracy: 0.9122 - val_loss: 0.2139 - val_accuracy: 0.9168\n",
      "Epoch 852/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.3468 - accuracy: 0.8550 - val_loss: 0.3248 - val_accuracy: 0.8665\n",
      "Epoch 853/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.3235 - accuracy: 0.8616 - val_loss: 0.2782 - val_accuracy: 0.8852\n",
      "Epoch 854/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2704 - accuracy: 0.8799 - val_loss: 0.2515 - val_accuracy: 0.8948\n",
      "Epoch 855/1000\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.2546 - accuracy: 0.8920 - val_loss: 0.2318 - val_accuracy: 0.9032\n",
      "Epoch 856/1000\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 0.2422 - accuracy: 0.8951 - val_loss: 0.2272 - val_accuracy: 0.9080\n",
      "Epoch 857/1000\n",
      "21/21 [==============================] - 1s 39ms/step - loss: 0.2330 - accuracy: 0.9003 - val_loss: 0.2248 - val_accuracy: 0.9064\n",
      "Epoch 858/1000\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.2387 - accuracy: 0.8996 - val_loss: 0.2170 - val_accuracy: 0.9084\n",
      "Epoch 859/1000\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.2361 - accuracy: 0.8988 - val_loss: 0.2165 - val_accuracy: 0.9072\n",
      "Epoch 860/1000\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.2243 - accuracy: 0.9082 - val_loss: 0.2144 - val_accuracy: 0.9136\n",
      "Epoch 861/1000\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.2234 - accuracy: 0.9051 - val_loss: 0.2099 - val_accuracy: 0.9168\n",
      "Epoch 862/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2246 - accuracy: 0.9056 - val_loss: 0.2137 - val_accuracy: 0.9104\n",
      "Epoch 863/1000\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.2237 - accuracy: 0.9088 - val_loss: 0.2178 - val_accuracy: 0.9116\n",
      "Epoch 864/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2195 - accuracy: 0.9073 - val_loss: 0.2098 - val_accuracy: 0.9172\n",
      "Epoch 865/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2297 - accuracy: 0.9038 - val_loss: 0.2162 - val_accuracy: 0.9144\n",
      "Epoch 866/1000\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.2214 - accuracy: 0.9073 - val_loss: 0.2071 - val_accuracy: 0.9176\n",
      "Epoch 867/1000\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.2173 - accuracy: 0.9080 - val_loss: 0.2029 - val_accuracy: 0.9188\n",
      "Epoch 868/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2156 - accuracy: 0.9105 - val_loss: 0.2022 - val_accuracy: 0.9200\n",
      "Epoch 869/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2112 - accuracy: 0.9116 - val_loss: 0.2011 - val_accuracy: 0.9172\n",
      "Epoch 870/1000\n",
      "21/21 [==============================] - 1s 62ms/step - loss: 0.2136 - accuracy: 0.9104 - val_loss: 0.2034 - val_accuracy: 0.9188\n",
      "Epoch 871/1000\n",
      "21/21 [==============================] - 1s 59ms/step - loss: 0.2160 - accuracy: 0.9105 - val_loss: 0.2017 - val_accuracy: 0.9196\n",
      "Epoch 872/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.2133 - accuracy: 0.9105 - val_loss: 0.1992 - val_accuracy: 0.9184\n",
      "Epoch 873/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.2234 - accuracy: 0.9053 - val_loss: 0.2006 - val_accuracy: 0.9184\n",
      "Epoch 874/1000\n",
      "21/21 [==============================] - 1s 59ms/step - loss: 0.2190 - accuracy: 0.9050 - val_loss: 0.2033 - val_accuracy: 0.9176\n",
      "Epoch 875/1000\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.2138 - accuracy: 0.9081 - val_loss: 0.1979 - val_accuracy: 0.9192\n",
      "Epoch 876/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2111 - accuracy: 0.9105 - val_loss: 0.1979 - val_accuracy: 0.9192\n",
      "Epoch 877/1000\n",
      "21/21 [==============================] - 1s 40ms/step - loss: 0.2100 - accuracy: 0.9112 - val_loss: 0.1958 - val_accuracy: 0.9192\n",
      "Epoch 878/1000\n",
      "21/21 [==============================] - 1s 41ms/step - loss: 0.2080 - accuracy: 0.9129 - val_loss: 0.1960 - val_accuracy: 0.9208\n",
      "Epoch 879/1000\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.2060 - accuracy: 0.9148 - val_loss: 0.1975 - val_accuracy: 0.9196\n",
      "Epoch 880/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2115 - accuracy: 0.9086 - val_loss: 0.1969 - val_accuracy: 0.9200\n",
      "Epoch 881/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2236 - accuracy: 0.9069 - val_loss: 0.2000 - val_accuracy: 0.9220\n",
      "Epoch 882/1000\n",
      "21/21 [==============================] - 1s 52ms/step - loss: 0.2097 - accuracy: 0.9104 - val_loss: 0.1985 - val_accuracy: 0.9204\n",
      "Epoch 883/1000\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 0.2244 - accuracy: 0.9030 - val_loss: 0.2066 - val_accuracy: 0.9144\n",
      "Epoch 884/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2314 - accuracy: 0.9046 - val_loss: 0.2057 - val_accuracy: 0.9160\n",
      "Epoch 885/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2322 - accuracy: 0.9021 - val_loss: 0.2103 - val_accuracy: 0.9152\n",
      "Epoch 886/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2255 - accuracy: 0.9066 - val_loss: 0.2097 - val_accuracy: 0.9188\n",
      "Epoch 887/1000\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 0.2207 - accuracy: 0.9114 - val_loss: 0.2050 - val_accuracy: 0.9208\n",
      "Epoch 888/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2198 - accuracy: 0.9084 - val_loss: 0.2003 - val_accuracy: 0.9212\n",
      "Epoch 889/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2082 - accuracy: 0.9138 - val_loss: 0.1978 - val_accuracy: 0.9232\n",
      "Epoch 890/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2142 - accuracy: 0.9107 - val_loss: 0.1988 - val_accuracy: 0.9204\n",
      "Epoch 891/1000\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 0.2095 - accuracy: 0.9132 - val_loss: 0.1978 - val_accuracy: 0.9224\n",
      "Epoch 892/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2157 - accuracy: 0.9087 - val_loss: 0.2025 - val_accuracy: 0.9244\n",
      "Epoch 893/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2126 - accuracy: 0.9097 - val_loss: 0.1981 - val_accuracy: 0.9252\n",
      "Epoch 894/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2055 - accuracy: 0.9146 - val_loss: 0.1953 - val_accuracy: 0.9224\n",
      "Epoch 895/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2034 - accuracy: 0.9142 - val_loss: 0.1961 - val_accuracy: 0.9232\n",
      "Epoch 896/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2053 - accuracy: 0.9169 - val_loss: 0.1965 - val_accuracy: 0.9232\n",
      "Epoch 897/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2095 - accuracy: 0.9132 - val_loss: 0.2009 - val_accuracy: 0.9212\n",
      "Epoch 898/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2105 - accuracy: 0.9114 - val_loss: 0.1986 - val_accuracy: 0.9224\n",
      "Epoch 899/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2177 - accuracy: 0.9077 - val_loss: 0.2037 - val_accuracy: 0.9160\n",
      "Epoch 900/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2287 - accuracy: 0.9004 - val_loss: 0.2059 - val_accuracy: 0.9176\n",
      "Epoch 901/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2113 - accuracy: 0.9106 - val_loss: 0.2040 - val_accuracy: 0.9172\n",
      "Epoch 902/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2191 - accuracy: 0.9058 - val_loss: 0.1995 - val_accuracy: 0.9180\n",
      "Epoch 903/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2135 - accuracy: 0.9109 - val_loss: 0.1984 - val_accuracy: 0.9180\n",
      "Epoch 904/1000\n",
      "21/21 [==============================] - 1s 57ms/step - loss: 0.2242 - accuracy: 0.9047 - val_loss: 0.2090 - val_accuracy: 0.9140\n",
      "Epoch 905/1000\n",
      "21/21 [==============================] - 1s 55ms/step - loss: 0.3247 - accuracy: 0.8654 - val_loss: 0.2674 - val_accuracy: 0.8852\n",
      "Epoch 906/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2652 - accuracy: 0.8834 - val_loss: 0.2400 - val_accuracy: 0.9000\n",
      "Epoch 907/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.3072 - accuracy: 0.8660 - val_loss: 0.2641 - val_accuracy: 0.8844\n",
      "Epoch 908/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2651 - accuracy: 0.8877 - val_loss: 0.2317 - val_accuracy: 0.9080\n",
      "Epoch 909/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2584 - accuracy: 0.8895 - val_loss: 0.2236 - val_accuracy: 0.9044\n",
      "Epoch 910/1000\n",
      "21/21 [==============================] - 1s 42ms/step - loss: 0.2371 - accuracy: 0.9009 - val_loss: 0.2147 - val_accuracy: 0.9096\n",
      "Epoch 911/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2207 - accuracy: 0.9077 - val_loss: 0.2082 - val_accuracy: 0.9152\n",
      "Epoch 912/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2283 - accuracy: 0.9036 - val_loss: 0.2097 - val_accuracy: 0.9156\n",
      "Epoch 913/1000\n",
      "21/21 [==============================] - 1s 56ms/step - loss: 0.2266 - accuracy: 0.9052 - val_loss: 0.2010 - val_accuracy: 0.9196\n",
      "Epoch 914/1000\n",
      "21/21 [==============================] - 1s 54ms/step - loss: 0.2189 - accuracy: 0.9082 - val_loss: 0.1998 - val_accuracy: 0.9192\n",
      "Epoch 915/1000\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 0.2106 - accuracy: 0.9120 - val_loss: 0.1991 - val_accuracy: 0.9192\n",
      "Epoch 916/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2130 - accuracy: 0.9136 - val_loss: 0.1969 - val_accuracy: 0.9224\n",
      "Epoch 917/1000\n",
      "21/21 [==============================] - 1s 54ms/step - loss: 0.2099 - accuracy: 0.9136 - val_loss: 0.1993 - val_accuracy: 0.9180\n",
      "Epoch 918/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.2174 - accuracy: 0.9099 - val_loss: 0.2006 - val_accuracy: 0.9180\n",
      "Epoch 919/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2101 - accuracy: 0.9090 - val_loss: 0.1991 - val_accuracy: 0.9168\n",
      "Epoch 920/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.2066 - accuracy: 0.9132 - val_loss: 0.1972 - val_accuracy: 0.9208\n",
      "Epoch 921/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2060 - accuracy: 0.9151 - val_loss: 0.1981 - val_accuracy: 0.9192\n",
      "Epoch 922/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2086 - accuracy: 0.9169 - val_loss: 0.1969 - val_accuracy: 0.9204\n",
      "Epoch 923/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2009 - accuracy: 0.9158 - val_loss: 0.2013 - val_accuracy: 0.9196\n",
      "Epoch 924/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2675 - accuracy: 0.8845 - val_loss: 0.2533 - val_accuracy: 0.8948\n",
      "Epoch 925/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2454 - accuracy: 0.8935 - val_loss: 0.2181 - val_accuracy: 0.9108\n",
      "Epoch 926/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2281 - accuracy: 0.9005 - val_loss: 0.2103 - val_accuracy: 0.9140\n",
      "Epoch 927/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2191 - accuracy: 0.9044 - val_loss: 0.2027 - val_accuracy: 0.9192\n",
      "Epoch 928/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2189 - accuracy: 0.9093 - val_loss: 0.2028 - val_accuracy: 0.9204\n",
      "Epoch 929/1000\n",
      "21/21 [==============================] - 1s 60ms/step - loss: 0.2233 - accuracy: 0.9079 - val_loss: 0.2030 - val_accuracy: 0.9244\n",
      "Epoch 930/1000\n",
      "21/21 [==============================] - 1s 52ms/step - loss: 0.2160 - accuracy: 0.9089 - val_loss: 0.1989 - val_accuracy: 0.9236\n",
      "Epoch 931/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2075 - accuracy: 0.9134 - val_loss: 0.1978 - val_accuracy: 0.9208\n",
      "Epoch 932/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2087 - accuracy: 0.9141 - val_loss: 0.1993 - val_accuracy: 0.9192\n",
      "Epoch 933/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2569 - accuracy: 0.8954 - val_loss: 0.2226 - val_accuracy: 0.9068\n",
      "Epoch 934/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.2320 - accuracy: 0.9026 - val_loss: 0.2116 - val_accuracy: 0.9116\n",
      "Epoch 935/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.3048 - accuracy: 0.8745 - val_loss: 0.2607 - val_accuracy: 0.8884\n",
      "Epoch 936/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.2794 - accuracy: 0.8809 - val_loss: 0.2310 - val_accuracy: 0.9032\n",
      "Epoch 937/1000\n",
      "21/21 [==============================] - 1s 60ms/step - loss: 0.2408 - accuracy: 0.8995 - val_loss: 0.2179 - val_accuracy: 0.9120\n",
      "Epoch 938/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2353 - accuracy: 0.9031 - val_loss: 0.2143 - val_accuracy: 0.9168\n",
      "Epoch 939/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2251 - accuracy: 0.9056 - val_loss: 0.2061 - val_accuracy: 0.9176\n",
      "Epoch 940/1000\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 0.2398 - accuracy: 0.8998 - val_loss: 0.2172 - val_accuracy: 0.9124\n",
      "Epoch 941/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2232 - accuracy: 0.9079 - val_loss: 0.2026 - val_accuracy: 0.9228\n",
      "Epoch 942/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2175 - accuracy: 0.9098 - val_loss: 0.2008 - val_accuracy: 0.9224\n",
      "Epoch 943/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2199 - accuracy: 0.9053 - val_loss: 0.1999 - val_accuracy: 0.9244\n",
      "Epoch 944/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2107 - accuracy: 0.9136 - val_loss: 0.1975 - val_accuracy: 0.9260\n",
      "Epoch 945/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2092 - accuracy: 0.9107 - val_loss: 0.1967 - val_accuracy: 0.9240\n",
      "Epoch 946/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2081 - accuracy: 0.9155 - val_loss: 0.2014 - val_accuracy: 0.9172\n",
      "Epoch 947/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2415 - accuracy: 0.8985 - val_loss: 0.2117 - val_accuracy: 0.9152\n",
      "Epoch 948/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2586 - accuracy: 0.8910 - val_loss: 0.2391 - val_accuracy: 0.9012\n",
      "Epoch 949/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2287 - accuracy: 0.9073 - val_loss: 0.2130 - val_accuracy: 0.9140\n",
      "Epoch 950/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.2323 - accuracy: 0.9020 - val_loss: 0.2046 - val_accuracy: 0.9188\n",
      "Epoch 951/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2090 - accuracy: 0.9121 - val_loss: 0.2047 - val_accuracy: 0.9212\n",
      "Epoch 952/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2529 - accuracy: 0.8895 - val_loss: 0.2390 - val_accuracy: 0.9040\n",
      "Epoch 953/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2824 - accuracy: 0.8751 - val_loss: 0.2321 - val_accuracy: 0.8948\n",
      "Epoch 954/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2364 - accuracy: 0.9008 - val_loss: 0.2118 - val_accuracy: 0.9156\n",
      "Epoch 955/1000\n",
      "21/21 [==============================] - 1s 53ms/step - loss: 0.2224 - accuracy: 0.9087 - val_loss: 0.2056 - val_accuracy: 0.9188\n",
      "Epoch 956/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2099 - accuracy: 0.9101 - val_loss: 0.2021 - val_accuracy: 0.9188\n",
      "Epoch 957/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2151 - accuracy: 0.9094 - val_loss: 0.2008 - val_accuracy: 0.9176\n",
      "Epoch 958/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2061 - accuracy: 0.9146 - val_loss: 0.1992 - val_accuracy: 0.9184\n",
      "Epoch 959/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2205 - accuracy: 0.9087 - val_loss: 0.2022 - val_accuracy: 0.9152\n",
      "Epoch 960/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2227 - accuracy: 0.9067 - val_loss: 0.2022 - val_accuracy: 0.9184\n",
      "Epoch 961/1000\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 0.2152 - accuracy: 0.9097 - val_loss: 0.1983 - val_accuracy: 0.9192\n",
      "Epoch 962/1000\n",
      "21/21 [==============================] - 1s 63ms/step - loss: 0.2170 - accuracy: 0.9071 - val_loss: 0.2029 - val_accuracy: 0.9176\n",
      "Epoch 963/1000\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 0.2226 - accuracy: 0.9073 - val_loss: 0.2031 - val_accuracy: 0.9172\n",
      "Epoch 964/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2186 - accuracy: 0.9065 - val_loss: 0.1967 - val_accuracy: 0.9236\n",
      "Epoch 965/1000\n",
      "21/21 [==============================] - 1s 54ms/step - loss: 0.2121 - accuracy: 0.9102 - val_loss: 0.1975 - val_accuracy: 0.9212\n",
      "Epoch 966/1000\n",
      "21/21 [==============================] - 1s 49ms/step - loss: 0.2018 - accuracy: 0.9168 - val_loss: 0.1968 - val_accuracy: 0.9200\n",
      "Epoch 967/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2071 - accuracy: 0.9185 - val_loss: 0.1947 - val_accuracy: 0.9224\n",
      "Epoch 968/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.1983 - accuracy: 0.9177 - val_loss: 0.1957 - val_accuracy: 0.9204\n",
      "Epoch 969/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2095 - accuracy: 0.9100 - val_loss: 0.1998 - val_accuracy: 0.9208\n",
      "Epoch 970/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2036 - accuracy: 0.9188 - val_loss: 0.2016 - val_accuracy: 0.9200\n",
      "Epoch 971/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2800 - accuracy: 0.8852 - val_loss: 0.2392 - val_accuracy: 0.9036\n",
      "Epoch 972/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2375 - accuracy: 0.8994 - val_loss: 0.2078 - val_accuracy: 0.9216\n",
      "Epoch 973/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2328 - accuracy: 0.8980 - val_loss: 0.2156 - val_accuracy: 0.9148\n",
      "Epoch 974/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2624 - accuracy: 0.8879 - val_loss: 0.2381 - val_accuracy: 0.8976\n",
      "Epoch 975/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2469 - accuracy: 0.8931 - val_loss: 0.2154 - val_accuracy: 0.9164\n",
      "Epoch 976/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2433 - accuracy: 0.8975 - val_loss: 0.2155 - val_accuracy: 0.9152\n",
      "Epoch 977/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2282 - accuracy: 0.9031 - val_loss: 0.2064 - val_accuracy: 0.9204\n",
      "Epoch 978/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2177 - accuracy: 0.9099 - val_loss: 0.2027 - val_accuracy: 0.9216\n",
      "Epoch 979/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2127 - accuracy: 0.9123 - val_loss: 0.2025 - val_accuracy: 0.9208\n",
      "Epoch 980/1000\n",
      "21/21 [==============================] - 1s 55ms/step - loss: 0.2085 - accuracy: 0.9161 - val_loss: 0.2011 - val_accuracy: 0.9208\n",
      "Epoch 981/1000\n",
      "21/21 [==============================] - 1s 51ms/step - loss: 0.2081 - accuracy: 0.9147 - val_loss: 0.2027 - val_accuracy: 0.9212\n",
      "Epoch 982/1000\n",
      "21/21 [==============================] - 1s 50ms/step - loss: 0.2294 - accuracy: 0.9041 - val_loss: 0.2180 - val_accuracy: 0.9136\n",
      "Epoch 983/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2202 - accuracy: 0.9064 - val_loss: 0.2058 - val_accuracy: 0.9176\n",
      "Epoch 984/1000\n",
      "21/21 [==============================] - 1s 52ms/step - loss: 0.2163 - accuracy: 0.9099 - val_loss: 0.2027 - val_accuracy: 0.9200\n",
      "Epoch 985/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2122 - accuracy: 0.9145 - val_loss: 0.2004 - val_accuracy: 0.9208\n",
      "Epoch 986/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2096 - accuracy: 0.9130 - val_loss: 0.2020 - val_accuracy: 0.9180\n",
      "Epoch 987/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2080 - accuracy: 0.9133 - val_loss: 0.1997 - val_accuracy: 0.9212\n",
      "Epoch 988/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2035 - accuracy: 0.9169 - val_loss: 0.2007 - val_accuracy: 0.9196\n",
      "Epoch 989/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2084 - accuracy: 0.9150 - val_loss: 0.1982 - val_accuracy: 0.9260\n",
      "Epoch 990/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2046 - accuracy: 0.9134 - val_loss: 0.1999 - val_accuracy: 0.9244\n",
      "Epoch 991/1000\n",
      "21/21 [==============================] - 1s 43ms/step - loss: 0.2048 - accuracy: 0.9127 - val_loss: 0.1986 - val_accuracy: 0.9244\n",
      "Epoch 992/1000\n",
      "21/21 [==============================] - 1s 44ms/step - loss: 0.2068 - accuracy: 0.9129 - val_loss: 0.1963 - val_accuracy: 0.9244\n",
      "Epoch 993/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2007 - accuracy: 0.9171 - val_loss: 0.1990 - val_accuracy: 0.9224\n",
      "Epoch 994/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2187 - accuracy: 0.9077 - val_loss: 0.2047 - val_accuracy: 0.9176\n",
      "Epoch 995/1000\n",
      "21/21 [==============================] - 1s 47ms/step - loss: 0.2158 - accuracy: 0.9129 - val_loss: 0.2002 - val_accuracy: 0.9204\n",
      "Epoch 996/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2235 - accuracy: 0.9055 - val_loss: 0.2036 - val_accuracy: 0.9200\n",
      "Epoch 997/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2107 - accuracy: 0.9129 - val_loss: 0.2007 - val_accuracy: 0.9216\n",
      "Epoch 998/1000\n",
      "21/21 [==============================] - 1s 46ms/step - loss: 0.2055 - accuracy: 0.9157 - val_loss: 0.2014 - val_accuracy: 0.9256\n",
      "Epoch 999/1000\n",
      "21/21 [==============================] - 1s 48ms/step - loss: 0.2114 - accuracy: 0.9152 - val_loss: 0.2049 - val_accuracy: 0.9216\n",
      "Epoch 1000/1000\n",
      "21/21 [==============================] - 1s 45ms/step - loss: 0.2014 - accuracy: 0.9162 - val_loss: 0.1988 - val_accuracy: 0.9248\n",
      "193/193 - 0s - loss: 0.1884 - accuracy: 0.9312 - 464ms/epoch - 2ms/step\n"
     ]
    }
   ],
   "source": [
    "input_shape = (6, 6, 1)\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=100)\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=input_shape),\n",
    "    Conv2D(filters=100, kernel_size=[2,2]), \n",
    "    Activation(\"relu\"),\n",
    "    Dense(100),\n",
    "    Activation(\"elu\"),\n",
    "    Conv2D(filters=20, kernel_size=[2,2]),\n",
    "    Dense(20),\n",
    "    Activation(\"elu\"),\n",
    "    Conv2D(filters=10, kernel_size=[2,2]),\n",
    "    Activation(\"elu\"),\n",
    "    Dropout(rate=0.1),\n",
    "    Dense(10),\n",
    "    Activation(\"elu\"),\n",
    "    Dropout(rate=0.2), \n",
    "    Flatten(),\n",
    "    Dense(2)\n",
    "])\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate=1e-2,\n",
    "    decay_steps=500,\n",
    "    end_learning_rate=1e-3,\n",
    "    power=0.5)\n",
    "\n",
    "model.compile(\n",
    "    loss = keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    optimizer = keras.optimizers.Adam(lr_schedule),\n",
    "    metrics = [\"accuracy\"],\n",
    ")\n",
    "history = model.fit(X_train, y_train, batch_size=500, epochs=1000, validation_split=0.2, verbose=True, callbacks=[callback])\n",
    "test_scores = model.evaluate(X_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e462cdd",
   "metadata": {},
   "source": [
    "In our plot here we see no overfitting, and accuracy still seems to be increasing until epoch $1000$. Possibly it will still improve for larger epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "492ab793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebe4afc",
   "metadata": {},
   "source": [
    "## Ternary classification with $A_6$, $D_6$ and $E_6$ <a class=\"anchor\" id=\"4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7ec6d7",
   "metadata": {},
   "source": [
    "Let's introduce $b$-matrices of $E_6$ type to see how our model can handle a ternary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e4d97b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cluster_data_A6_depth_6.csv') as fp:\n",
    "    reader = csv.reader(fp, delimiter=\",\", quotechar='\"')\n",
    "    data = [row for row in reader]\n",
    "    \n",
    "data=data[0]\n",
    "\n",
    "cluster_type = data[0]\n",
    "\n",
    "data = [np.array(np.matrix(data[i])).ravel() for i in range(1, len(data))]\n",
    "                                                                           \n",
    "data = [np.append(i, np.array([1, 0, 0])) for i in data] # Now we have 3 labels need to relabel targets as 3-d basis vectors\n",
    "A6_data = data\n",
    "A_array = A6_data[0]\n",
    "for i in range(1, len(A6_data)):\n",
    "    A_array = np.vstack([A_array, A6_data[i]])\n",
    "    \n",
    "\n",
    "with open('cluster_data_D6_depth_6.csv') as fp:\n",
    "    reader = csv.reader(fp, delimiter=\",\", quotechar='\"')\n",
    "    data = [row for row in reader]\n",
    "    \n",
    "data=data[0]\n",
    "\n",
    "cluster_type = data[0]\n",
    "\n",
    "data = [np.array(np.matrix(data[i])).ravel() for i in range(1, len(data))]\n",
    "                                                                           \n",
    "data = [np.append(i, np.array([0, 1, 0])) for i in data]\n",
    "D6_data = data\n",
    "D_array = D6_data[0]\n",
    "for i in range(1, len(D6_data)):\n",
    "    D_array = np.vstack([D_array, D6_data[i]])\n",
    "    \n",
    "with open('cluster_data_E6_depth_6.csv') as fp:\n",
    "    reader = csv.reader(fp, delimiter=\",\", quotechar='\"')\n",
    "    data = [row for row in reader]\n",
    "    \n",
    "data=data[0]\n",
    "\n",
    "cluster_type = data[0]\n",
    "\n",
    "data = [np.array(np.matrix(data[i])).ravel() for i in range(1, len(data))]\n",
    "                                                                           \n",
    "data = [np.append(i, np.array([0, 0, 1])) for i in data]\n",
    "E6_data = data\n",
    "E_array = E6_data[0]\n",
    "for i in range(1, len(E6_data)):\n",
    "    E_array = np.vstack([E_array, E6_data[i]])\n",
    "    \n",
    "# Features, targets\n",
    "X = np.vstack([A_array[:,:-3], D_array[:,:-3]])\n",
    "\n",
    "X = np.vstack([X, E_array[:,:-3]])\n",
    "\n",
    "y = np.vstack([A_array[:,-3:], D_array[:,-3:]])\n",
    "\n",
    "y = np.vstack([y, E_array[:,-3:]])\n",
    "\n",
    "# Reshape as matrices\n",
    "Z = np.array([np.resize(X[0], (6,6))])\n",
    "for i in range(1, len(X)):\n",
    "    new = np.resize(X[i], (6,6))\n",
    "    new2 = np.array([new])\n",
    "    Z = np.append(Z, new2, axis=0)\n",
    "\n",
    "X = Z\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9da1979",
   "metadata": {},
   "source": [
    "Now we run our model. This model is very slow to run and we see that around epoch $300$ it levels out at around accuracy $0.8$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75bcfa90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "31/31 [==============================] - 3s 50ms/step - loss: 0.6988 - accuracy: 0.3392 - val_loss: 0.6769 - val_accuracy: 0.3506\n",
      "Epoch 2/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.6410 - accuracy: 0.3691 - val_loss: 0.7316 - val_accuracy: 0.3618\n",
      "Epoch 3/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.6227 - accuracy: 0.4374 - val_loss: 0.7210 - val_accuracy: 0.4028\n",
      "Epoch 4/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.6067 - accuracy: 0.4739 - val_loss: 0.6142 - val_accuracy: 0.4596\n",
      "Epoch 5/1000\n",
      "31/31 [==============================] - 2s 53ms/step - loss: 0.5886 - accuracy: 0.5030 - val_loss: 0.6400 - val_accuracy: 0.4508\n",
      "Epoch 6/1000\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.5738 - accuracy: 0.5312 - val_loss: 0.6378 - val_accuracy: 0.4628\n",
      "Epoch 7/1000\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.5542 - accuracy: 0.5587 - val_loss: 0.6479 - val_accuracy: 0.4489\n",
      "Epoch 8/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.5409 - accuracy: 0.5787 - val_loss: 0.5445 - val_accuracy: 0.5628\n",
      "Epoch 9/1000\n",
      "31/31 [==============================] - 1s 44ms/step - loss: 0.5268 - accuracy: 0.5929 - val_loss: 0.5336 - val_accuracy: 0.5798\n",
      "Epoch 10/1000\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.5152 - accuracy: 0.6098 - val_loss: 0.5007 - val_accuracy: 0.6302\n",
      "Epoch 11/1000\n",
      "31/31 [==============================] - 2s 52ms/step - loss: 0.5051 - accuracy: 0.6244 - val_loss: 0.4964 - val_accuracy: 0.6310\n",
      "Epoch 12/1000\n",
      "31/31 [==============================] - 2s 52ms/step - loss: 0.5057 - accuracy: 0.6228 - val_loss: 0.4915 - val_accuracy: 0.6350\n",
      "Epoch 13/1000\n",
      "31/31 [==============================] - 2s 62ms/step - loss: 0.5029 - accuracy: 0.6292 - val_loss: 0.4954 - val_accuracy: 0.6321\n",
      "Epoch 14/1000\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 0.5012 - accuracy: 0.6258 - val_loss: 0.4929 - val_accuracy: 0.6468\n",
      "Epoch 15/1000\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.4989 - accuracy: 0.6325 - val_loss: 0.4867 - val_accuracy: 0.6492\n",
      "Epoch 16/1000\n",
      "31/31 [==============================] - 2s 63ms/step - loss: 0.4960 - accuracy: 0.6348 - val_loss: 0.4986 - val_accuracy: 0.6281\n",
      "Epoch 17/1000\n",
      "31/31 [==============================] - 2s 69ms/step - loss: 0.4939 - accuracy: 0.6370 - val_loss: 0.4922 - val_accuracy: 0.6372\n",
      "Epoch 18/1000\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 0.4935 - accuracy: 0.6387 - val_loss: 0.4885 - val_accuracy: 0.6377\n",
      "Epoch 19/1000\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 0.4927 - accuracy: 0.6381 - val_loss: 0.4854 - val_accuracy: 0.6332\n",
      "Epoch 20/1000\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 0.4911 - accuracy: 0.6386 - val_loss: 0.4770 - val_accuracy: 0.6569\n",
      "Epoch 21/1000\n",
      "31/31 [==============================] - 2s 57ms/step - loss: 0.4883 - accuracy: 0.6439 - val_loss: 0.4785 - val_accuracy: 0.6524\n",
      "Epoch 22/1000\n",
      "31/31 [==============================] - 2s 63ms/step - loss: 0.4879 - accuracy: 0.6452 - val_loss: 0.4848 - val_accuracy: 0.6465\n",
      "Epoch 23/1000\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 0.4846 - accuracy: 0.6466 - val_loss: 0.4749 - val_accuracy: 0.6542\n",
      "Epoch 24/1000\n",
      "31/31 [==============================] - 2s 55ms/step - loss: 0.4829 - accuracy: 0.6479 - val_loss: 0.4895 - val_accuracy: 0.6345\n",
      "Epoch 25/1000\n",
      "31/31 [==============================] - 2s 53ms/step - loss: 0.4833 - accuracy: 0.6460 - val_loss: 0.4761 - val_accuracy: 0.6510\n",
      "Epoch 26/1000\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 0.4839 - accuracy: 0.6489 - val_loss: 0.4761 - val_accuracy: 0.6508\n",
      "Epoch 27/1000\n",
      "31/31 [==============================] - 2s 52ms/step - loss: 0.4783 - accuracy: 0.6561 - val_loss: 0.4796 - val_accuracy: 0.6548\n",
      "Epoch 28/1000\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.4789 - accuracy: 0.6508 - val_loss: 0.4792 - val_accuracy: 0.6545\n",
      "Epoch 29/1000\n",
      "31/31 [==============================] - 2s 52ms/step - loss: 0.4767 - accuracy: 0.6540 - val_loss: 0.4726 - val_accuracy: 0.6505\n",
      "Epoch 30/1000\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.4759 - accuracy: 0.6551 - val_loss: 0.4667 - val_accuracy: 0.6612\n",
      "Epoch 31/1000\n",
      "31/31 [==============================] - 1s 44ms/step - loss: 0.4742 - accuracy: 0.6541 - val_loss: 0.4782 - val_accuracy: 0.6382\n",
      "Epoch 32/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.4731 - accuracy: 0.6608 - val_loss: 0.4887 - val_accuracy: 0.6329\n",
      "Epoch 33/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.4732 - accuracy: 0.6555 - val_loss: 0.4634 - val_accuracy: 0.6606\n",
      "Epoch 34/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.4732 - accuracy: 0.6562 - val_loss: 0.4738 - val_accuracy: 0.6470\n",
      "Epoch 35/1000\n",
      "31/31 [==============================] - 1s 48ms/step - loss: 0.4702 - accuracy: 0.6638 - val_loss: 0.4608 - val_accuracy: 0.6590\n",
      "Epoch 36/1000\n",
      "31/31 [==============================] - 1s 47ms/step - loss: 0.4691 - accuracy: 0.6597 - val_loss: 0.4663 - val_accuracy: 0.6545\n",
      "Epoch 37/1000\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.4693 - accuracy: 0.6590 - val_loss: 0.4691 - val_accuracy: 0.6614\n",
      "Epoch 38/1000\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.4643 - accuracy: 0.6642 - val_loss: 0.4595 - val_accuracy: 0.6630\n",
      "Epoch 39/1000\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.4644 - accuracy: 0.6674 - val_loss: 0.4607 - val_accuracy: 0.6692\n",
      "Epoch 40/1000\n",
      "31/31 [==============================] - 1s 48ms/step - loss: 0.4595 - accuracy: 0.6725 - val_loss: 0.4803 - val_accuracy: 0.6497\n",
      "Epoch 41/1000\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 0.4629 - accuracy: 0.6664 - val_loss: 0.4559 - val_accuracy: 0.6630\n",
      "Epoch 42/1000\n",
      "31/31 [==============================] - 2s 57ms/step - loss: 0.4599 - accuracy: 0.6726 - val_loss: 0.4579 - val_accuracy: 0.6654\n",
      "Epoch 43/1000\n",
      "31/31 [==============================] - 2s 69ms/step - loss: 0.4614 - accuracy: 0.6716 - val_loss: 0.4612 - val_accuracy: 0.6700\n",
      "Epoch 44/1000\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.4578 - accuracy: 0.6700 - val_loss: 0.4542 - val_accuracy: 0.6814\n",
      "Epoch 45/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.4564 - accuracy: 0.6762 - val_loss: 0.4522 - val_accuracy: 0.6700\n",
      "Epoch 46/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.4547 - accuracy: 0.6758 - val_loss: 0.4541 - val_accuracy: 0.6628\n",
      "Epoch 47/1000\n",
      "31/31 [==============================] - 1s 44ms/step - loss: 0.4523 - accuracy: 0.6818 - val_loss: 0.4498 - val_accuracy: 0.6745\n",
      "Epoch 48/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.4517 - accuracy: 0.6777 - val_loss: 0.4491 - val_accuracy: 0.6676\n",
      "Epoch 49/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.4532 - accuracy: 0.6792 - val_loss: 0.4463 - val_accuracy: 0.6700\n",
      "Epoch 50/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.4526 - accuracy: 0.6776 - val_loss: 0.4458 - val_accuracy: 0.6801\n",
      "Epoch 51/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.4496 - accuracy: 0.6832 - val_loss: 0.4661 - val_accuracy: 0.6566\n",
      "Epoch 52/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.4489 - accuracy: 0.6782 - val_loss: 0.4408 - val_accuracy: 0.6836\n",
      "Epoch 53/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.4478 - accuracy: 0.6876 - val_loss: 0.4741 - val_accuracy: 0.6481\n",
      "Epoch 54/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.4460 - accuracy: 0.6876 - val_loss: 0.4489 - val_accuracy: 0.6876\n",
      "Epoch 55/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.4456 - accuracy: 0.6864 - val_loss: 0.4526 - val_accuracy: 0.6638\n",
      "Epoch 56/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.4421 - accuracy: 0.6872 - val_loss: 0.4488 - val_accuracy: 0.6891\n",
      "Epoch 57/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.4435 - accuracy: 0.6912 - val_loss: 0.4406 - val_accuracy: 0.6745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.4428 - accuracy: 0.6849 - val_loss: 0.4409 - val_accuracy: 0.6958\n",
      "Epoch 59/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.4404 - accuracy: 0.6936 - val_loss: 0.4544 - val_accuracy: 0.6689\n",
      "Epoch 60/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.4390 - accuracy: 0.6921 - val_loss: 0.4327 - val_accuracy: 0.6931\n",
      "Epoch 61/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.4357 - accuracy: 0.7008 - val_loss: 0.4425 - val_accuracy: 0.6812\n",
      "Epoch 62/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.4376 - accuracy: 0.6962 - val_loss: 0.4402 - val_accuracy: 0.6777\n",
      "Epoch 63/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.4384 - accuracy: 0.6980 - val_loss: 0.4337 - val_accuracy: 0.6854\n",
      "Epoch 64/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.4370 - accuracy: 0.6989 - val_loss: 0.4312 - val_accuracy: 0.6902\n",
      "Epoch 65/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.4341 - accuracy: 0.6989 - val_loss: 0.4269 - val_accuracy: 0.7041\n",
      "Epoch 66/1000\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.4312 - accuracy: 0.7076 - val_loss: 0.4236 - val_accuracy: 0.7059\n",
      "Epoch 67/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.4312 - accuracy: 0.7037 - val_loss: 0.4623 - val_accuracy: 0.6678\n",
      "Epoch 68/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.4326 - accuracy: 0.6995 - val_loss: 0.4229 - val_accuracy: 0.7006\n",
      "Epoch 69/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.4285 - accuracy: 0.7097 - val_loss: 0.4277 - val_accuracy: 0.6990\n",
      "Epoch 70/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.4267 - accuracy: 0.7092 - val_loss: 0.4455 - val_accuracy: 0.6785\n",
      "Epoch 71/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.4259 - accuracy: 0.7069 - val_loss: 0.4232 - val_accuracy: 0.7009\n",
      "Epoch 72/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.4283 - accuracy: 0.7066 - val_loss: 0.4608 - val_accuracy: 0.6782\n",
      "Epoch 73/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.4286 - accuracy: 0.7049 - val_loss: 0.4316 - val_accuracy: 0.6891\n",
      "Epoch 74/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.4262 - accuracy: 0.7082 - val_loss: 0.4306 - val_accuracy: 0.6953\n",
      "Epoch 75/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.4262 - accuracy: 0.7098 - val_loss: 0.4460 - val_accuracy: 0.6774\n",
      "Epoch 76/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.4246 - accuracy: 0.7105 - val_loss: 0.4181 - val_accuracy: 0.7081\n",
      "Epoch 77/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.4254 - accuracy: 0.7057 - val_loss: 0.4347 - val_accuracy: 0.6905\n",
      "Epoch 78/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.4210 - accuracy: 0.7115 - val_loss: 0.4296 - val_accuracy: 0.7059\n",
      "Epoch 79/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.4204 - accuracy: 0.7139 - val_loss: 0.4247 - val_accuracy: 0.7022\n",
      "Epoch 80/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.4210 - accuracy: 0.7137 - val_loss: 0.4142 - val_accuracy: 0.7078\n",
      "Epoch 81/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.4194 - accuracy: 0.7152 - val_loss: 0.4468 - val_accuracy: 0.6790\n",
      "Epoch 82/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.4203 - accuracy: 0.7082 - val_loss: 0.4146 - val_accuracy: 0.7097\n",
      "Epoch 83/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.4202 - accuracy: 0.7123 - val_loss: 0.4294 - val_accuracy: 0.6961\n",
      "Epoch 84/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.4177 - accuracy: 0.7175 - val_loss: 0.4135 - val_accuracy: 0.7099\n",
      "Epoch 85/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.4113 - accuracy: 0.7181 - val_loss: 0.4300 - val_accuracy: 0.6950\n",
      "Epoch 86/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.4157 - accuracy: 0.7151 - val_loss: 0.4157 - val_accuracy: 0.7075\n",
      "Epoch 87/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.4114 - accuracy: 0.7217 - val_loss: 0.4184 - val_accuracy: 0.7054\n",
      "Epoch 88/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.4147 - accuracy: 0.7151 - val_loss: 0.4078 - val_accuracy: 0.7126\n",
      "Epoch 89/1000\n",
      "31/31 [==============================] - 1s 44ms/step - loss: 0.4144 - accuracy: 0.7166 - val_loss: 0.4581 - val_accuracy: 0.6689\n",
      "Epoch 90/1000\n",
      "31/31 [==============================] - 1s 48ms/step - loss: 0.4145 - accuracy: 0.7181 - val_loss: 0.4181 - val_accuracy: 0.7129\n",
      "Epoch 91/1000\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.4124 - accuracy: 0.7203 - val_loss: 0.4018 - val_accuracy: 0.7246\n",
      "Epoch 92/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.4086 - accuracy: 0.7252 - val_loss: 0.4088 - val_accuracy: 0.7035\n",
      "Epoch 93/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.4096 - accuracy: 0.7210 - val_loss: 0.4178 - val_accuracy: 0.6993\n",
      "Epoch 94/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.4099 - accuracy: 0.7213 - val_loss: 0.3991 - val_accuracy: 0.7217\n",
      "Epoch 95/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.4080 - accuracy: 0.7217 - val_loss: 0.4060 - val_accuracy: 0.7211\n",
      "Epoch 96/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.4055 - accuracy: 0.7251 - val_loss: 0.4034 - val_accuracy: 0.7203\n",
      "Epoch 97/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.4039 - accuracy: 0.7279 - val_loss: 0.4168 - val_accuracy: 0.7025\n",
      "Epoch 98/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.4080 - accuracy: 0.7236 - val_loss: 0.4107 - val_accuracy: 0.7089\n",
      "Epoch 99/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.4055 - accuracy: 0.7259 - val_loss: 0.4122 - val_accuracy: 0.7142\n",
      "Epoch 100/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.4039 - accuracy: 0.7321 - val_loss: 0.4035 - val_accuracy: 0.7182\n",
      "Epoch 101/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.4022 - accuracy: 0.7285 - val_loss: 0.4047 - val_accuracy: 0.7134\n",
      "Epoch 102/1000\n",
      "31/31 [==============================] - 1s 44ms/step - loss: 0.4025 - accuracy: 0.7266 - val_loss: 0.4172 - val_accuracy: 0.7065\n",
      "Epoch 103/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.4009 - accuracy: 0.7293 - val_loss: 0.4085 - val_accuracy: 0.7150\n",
      "Epoch 104/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.4012 - accuracy: 0.7297 - val_loss: 0.4066 - val_accuracy: 0.7099\n",
      "Epoch 105/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.4011 - accuracy: 0.7299 - val_loss: 0.4181 - val_accuracy: 0.7003\n",
      "Epoch 106/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.4022 - accuracy: 0.7257 - val_loss: 0.3956 - val_accuracy: 0.7262\n",
      "Epoch 107/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3968 - accuracy: 0.7327 - val_loss: 0.3967 - val_accuracy: 0.7275\n",
      "Epoch 108/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3967 - accuracy: 0.7306 - val_loss: 0.4193 - val_accuracy: 0.7054\n",
      "Epoch 109/1000\n",
      "31/31 [==============================] - 1s 47ms/step - loss: 0.4000 - accuracy: 0.7285 - val_loss: 0.4002 - val_accuracy: 0.7195\n",
      "Epoch 110/1000\n",
      "31/31 [==============================] - 2s 50ms/step - loss: 0.3964 - accuracy: 0.7355 - val_loss: 0.3959 - val_accuracy: 0.7337\n",
      "Epoch 111/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3971 - accuracy: 0.7351 - val_loss: 0.3981 - val_accuracy: 0.7203\n",
      "Epoch 112/1000\n",
      "31/31 [==============================] - 1s 44ms/step - loss: 0.3954 - accuracy: 0.7323 - val_loss: 0.4097 - val_accuracy: 0.7094\n",
      "Epoch 113/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.3980 - accuracy: 0.7313 - val_loss: 0.3989 - val_accuracy: 0.7211\n",
      "Epoch 114/1000\n",
      "31/31 [==============================] - 1s 47ms/step - loss: 0.3965 - accuracy: 0.7311 - val_loss: 0.3926 - val_accuracy: 0.7238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/1000\n",
      "31/31 [==============================] - 1s 47ms/step - loss: 0.3937 - accuracy: 0.7310 - val_loss: 0.4024 - val_accuracy: 0.7206\n",
      "Epoch 116/1000\n",
      "31/31 [==============================] - 2s 50ms/step - loss: 0.3924 - accuracy: 0.7359 - val_loss: 0.3945 - val_accuracy: 0.7267\n",
      "Epoch 117/1000\n",
      "31/31 [==============================] - 1s 47ms/step - loss: 0.3914 - accuracy: 0.7392 - val_loss: 0.3924 - val_accuracy: 0.7241\n",
      "Epoch 118/1000\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.3935 - accuracy: 0.7374 - val_loss: 0.4033 - val_accuracy: 0.7155\n",
      "Epoch 119/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.3912 - accuracy: 0.7371 - val_loss: 0.3864 - val_accuracy: 0.7310\n",
      "Epoch 120/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3885 - accuracy: 0.7425 - val_loss: 0.4085 - val_accuracy: 0.7075\n",
      "Epoch 121/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3916 - accuracy: 0.7380 - val_loss: 0.3859 - val_accuracy: 0.7331\n",
      "Epoch 122/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3906 - accuracy: 0.7381 - val_loss: 0.3987 - val_accuracy: 0.7113\n",
      "Epoch 123/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3906 - accuracy: 0.7367 - val_loss: 0.3939 - val_accuracy: 0.7318\n",
      "Epoch 124/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3912 - accuracy: 0.7377 - val_loss: 0.3939 - val_accuracy: 0.7190\n",
      "Epoch 125/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3913 - accuracy: 0.7363 - val_loss: 0.3868 - val_accuracy: 0.7329\n",
      "Epoch 126/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3886 - accuracy: 0.7418 - val_loss: 0.3971 - val_accuracy: 0.7246\n",
      "Epoch 127/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.3909 - accuracy: 0.7332 - val_loss: 0.3955 - val_accuracy: 0.7230\n",
      "Epoch 128/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.3859 - accuracy: 0.7423 - val_loss: 0.3925 - val_accuracy: 0.7254\n",
      "Epoch 129/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3878 - accuracy: 0.7406 - val_loss: 0.3897 - val_accuracy: 0.7331\n",
      "Epoch 130/1000\n",
      "31/31 [==============================] - 2s 50ms/step - loss: 0.3824 - accuracy: 0.7453 - val_loss: 0.3941 - val_accuracy: 0.7233\n",
      "Epoch 131/1000\n",
      "31/31 [==============================] - 1s 44ms/step - loss: 0.3856 - accuracy: 0.7403 - val_loss: 0.3826 - val_accuracy: 0.7459\n",
      "Epoch 132/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3867 - accuracy: 0.7405 - val_loss: 0.3896 - val_accuracy: 0.7310\n",
      "Epoch 133/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3869 - accuracy: 0.7400 - val_loss: 0.3803 - val_accuracy: 0.7457\n",
      "Epoch 134/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3853 - accuracy: 0.7401 - val_loss: 0.4073 - val_accuracy: 0.7137\n",
      "Epoch 135/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3847 - accuracy: 0.7468 - val_loss: 0.3787 - val_accuracy: 0.7451\n",
      "Epoch 136/1000\n",
      "31/31 [==============================] - 2s 50ms/step - loss: 0.3822 - accuracy: 0.7483 - val_loss: 0.3878 - val_accuracy: 0.7366\n",
      "Epoch 137/1000\n",
      "31/31 [==============================] - 1s 48ms/step - loss: 0.3800 - accuracy: 0.7458 - val_loss: 0.4036 - val_accuracy: 0.7206\n",
      "Epoch 138/1000\n",
      "31/31 [==============================] - 2s 49ms/step - loss: 0.3852 - accuracy: 0.7436 - val_loss: 0.3842 - val_accuracy: 0.7382\n",
      "Epoch 139/1000\n",
      "31/31 [==============================] - 2s 50ms/step - loss: 0.3816 - accuracy: 0.7457 - val_loss: 0.3884 - val_accuracy: 0.7259\n",
      "Epoch 140/1000\n",
      "31/31 [==============================] - 1s 44ms/step - loss: 0.3828 - accuracy: 0.7435 - val_loss: 0.4041 - val_accuracy: 0.7115\n",
      "Epoch 141/1000\n",
      "31/31 [==============================] - 1s 47ms/step - loss: 0.3818 - accuracy: 0.7437 - val_loss: 0.3769 - val_accuracy: 0.7435\n",
      "Epoch 142/1000\n",
      "31/31 [==============================] - 2s 53ms/step - loss: 0.3781 - accuracy: 0.7498 - val_loss: 0.3778 - val_accuracy: 0.7433\n",
      "Epoch 143/1000\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 0.3814 - accuracy: 0.7466 - val_loss: 0.3811 - val_accuracy: 0.7430\n",
      "Epoch 144/1000\n",
      "31/31 [==============================] - 2s 63ms/step - loss: 0.3783 - accuracy: 0.7480 - val_loss: 0.3804 - val_accuracy: 0.7419\n",
      "Epoch 145/1000\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 0.3802 - accuracy: 0.7455 - val_loss: 0.3846 - val_accuracy: 0.7377\n",
      "Epoch 146/1000\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.3799 - accuracy: 0.7495 - val_loss: 0.4069 - val_accuracy: 0.7081\n",
      "Epoch 147/1000\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.3807 - accuracy: 0.7493 - val_loss: 0.3932 - val_accuracy: 0.7246\n",
      "Epoch 148/1000\n",
      "31/31 [==============================] - 2s 52ms/step - loss: 0.3795 - accuracy: 0.7471 - val_loss: 0.3867 - val_accuracy: 0.7318\n",
      "Epoch 149/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.3780 - accuracy: 0.7493 - val_loss: 0.3852 - val_accuracy: 0.7347\n",
      "Epoch 150/1000\n",
      "31/31 [==============================] - 2s 53ms/step - loss: 0.3768 - accuracy: 0.7507 - val_loss: 0.4117 - val_accuracy: 0.7137\n",
      "Epoch 151/1000\n",
      "31/31 [==============================] - 2s 56ms/step - loss: 0.3767 - accuracy: 0.7505 - val_loss: 0.3808 - val_accuracy: 0.7385\n",
      "Epoch 152/1000\n",
      "31/31 [==============================] - 2s 63ms/step - loss: 0.3746 - accuracy: 0.7493 - val_loss: 0.3890 - val_accuracy: 0.7278\n",
      "Epoch 153/1000\n",
      "31/31 [==============================] - 2s 64ms/step - loss: 0.3780 - accuracy: 0.7459 - val_loss: 0.4172 - val_accuracy: 0.7003\n",
      "Epoch 154/1000\n",
      "31/31 [==============================] - 2s 54ms/step - loss: 0.3816 - accuracy: 0.7469 - val_loss: 0.3851 - val_accuracy: 0.7331\n",
      "Epoch 155/1000\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.3750 - accuracy: 0.7491 - val_loss: 0.4095 - val_accuracy: 0.7142\n",
      "Epoch 156/1000\n",
      "31/31 [==============================] - 2s 56ms/step - loss: 0.3746 - accuracy: 0.7516 - val_loss: 0.3965 - val_accuracy: 0.7246\n",
      "Epoch 157/1000\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.3728 - accuracy: 0.7551 - val_loss: 0.3722 - val_accuracy: 0.7473\n",
      "Epoch 158/1000\n",
      "31/31 [==============================] - 2s 54ms/step - loss: 0.3736 - accuracy: 0.7553 - val_loss: 0.3692 - val_accuracy: 0.7513\n",
      "Epoch 159/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.3732 - accuracy: 0.7527 - val_loss: 0.3952 - val_accuracy: 0.7307\n",
      "Epoch 160/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3712 - accuracy: 0.7547 - val_loss: 0.3873 - val_accuracy: 0.7275\n",
      "Epoch 161/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3762 - accuracy: 0.7527 - val_loss: 0.3764 - val_accuracy: 0.7515\n",
      "Epoch 162/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.3722 - accuracy: 0.7500 - val_loss: 0.3764 - val_accuracy: 0.7401\n",
      "Epoch 163/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.3721 - accuracy: 0.7569 - val_loss: 0.3883 - val_accuracy: 0.7382\n",
      "Epoch 164/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3698 - accuracy: 0.7539 - val_loss: 0.3921 - val_accuracy: 0.7262\n",
      "Epoch 165/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.3729 - accuracy: 0.7539 - val_loss: 0.4128 - val_accuracy: 0.7134\n",
      "Epoch 166/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3699 - accuracy: 0.7585 - val_loss: 0.3844 - val_accuracy: 0.7323\n",
      "Epoch 167/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3692 - accuracy: 0.7581 - val_loss: 0.3754 - val_accuracy: 0.7462\n",
      "Epoch 168/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3707 - accuracy: 0.7509 - val_loss: 0.3648 - val_accuracy: 0.7545\n",
      "Epoch 169/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.3670 - accuracy: 0.7581 - val_loss: 0.3606 - val_accuracy: 0.7619\n",
      "Epoch 170/1000\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.3694 - accuracy: 0.7587 - val_loss: 0.3806 - val_accuracy: 0.7374\n",
      "Epoch 171/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.3706 - accuracy: 0.7555 - val_loss: 0.3968 - val_accuracy: 0.7185\n",
      "Epoch 172/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3671 - accuracy: 0.7581 - val_loss: 0.3693 - val_accuracy: 0.7451\n",
      "Epoch 173/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3685 - accuracy: 0.7570 - val_loss: 0.4080 - val_accuracy: 0.7137\n",
      "Epoch 174/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3669 - accuracy: 0.7551 - val_loss: 0.3769 - val_accuracy: 0.7379\n",
      "Epoch 175/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3702 - accuracy: 0.7506 - val_loss: 0.3857 - val_accuracy: 0.7334\n",
      "Epoch 176/1000\n",
      "31/31 [==============================] - 1s 36ms/step - loss: 0.3655 - accuracy: 0.7606 - val_loss: 0.3705 - val_accuracy: 0.7465\n",
      "Epoch 177/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3679 - accuracy: 0.7584 - val_loss: 0.3870 - val_accuracy: 0.7313\n",
      "Epoch 178/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3643 - accuracy: 0.7631 - val_loss: 0.3808 - val_accuracy: 0.7401\n",
      "Epoch 179/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3635 - accuracy: 0.7611 - val_loss: 0.3645 - val_accuracy: 0.7513\n",
      "Epoch 180/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3632 - accuracy: 0.7609 - val_loss: 0.3757 - val_accuracy: 0.7459\n",
      "Epoch 181/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3655 - accuracy: 0.7590 - val_loss: 0.3740 - val_accuracy: 0.7446\n",
      "Epoch 182/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3681 - accuracy: 0.7562 - val_loss: 0.3672 - val_accuracy: 0.7542\n",
      "Epoch 183/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.3628 - accuracy: 0.7614 - val_loss: 0.3849 - val_accuracy: 0.7398\n",
      "Epoch 184/1000\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.3639 - accuracy: 0.7635 - val_loss: 0.3601 - val_accuracy: 0.7526\n",
      "Epoch 185/1000\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.3638 - accuracy: 0.7593 - val_loss: 0.3597 - val_accuracy: 0.7601\n",
      "Epoch 186/1000\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.3628 - accuracy: 0.7596 - val_loss: 0.3581 - val_accuracy: 0.7569\n",
      "Epoch 187/1000\n",
      "31/31 [==============================] - 2s 57ms/step - loss: 0.3597 - accuracy: 0.7624 - val_loss: 0.3690 - val_accuracy: 0.7473\n",
      "Epoch 188/1000\n",
      "31/31 [==============================] - 2s 53ms/step - loss: 0.3599 - accuracy: 0.7591 - val_loss: 0.3718 - val_accuracy: 0.7457\n",
      "Epoch 189/1000\n",
      "31/31 [==============================] - 2s 55ms/step - loss: 0.3609 - accuracy: 0.7641 - val_loss: 0.3892 - val_accuracy: 0.7334\n",
      "Epoch 190/1000\n",
      "31/31 [==============================] - 1s 48ms/step - loss: 0.3612 - accuracy: 0.7663 - val_loss: 0.3804 - val_accuracy: 0.7363\n",
      "Epoch 191/1000\n",
      "31/31 [==============================] - 1s 47ms/step - loss: 0.3642 - accuracy: 0.7603 - val_loss: 0.3637 - val_accuracy: 0.7523\n",
      "Epoch 192/1000\n",
      "31/31 [==============================] - 2s 55ms/step - loss: 0.3596 - accuracy: 0.7643 - val_loss: 0.3599 - val_accuracy: 0.7646\n",
      "Epoch 193/1000\n",
      "31/31 [==============================] - 1s 44ms/step - loss: 0.3588 - accuracy: 0.7671 - val_loss: 0.3808 - val_accuracy: 0.7403\n",
      "Epoch 194/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3624 - accuracy: 0.7606 - val_loss: 0.3563 - val_accuracy: 0.7635\n",
      "Epoch 195/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3600 - accuracy: 0.7602 - val_loss: 0.3804 - val_accuracy: 0.7363\n",
      "Epoch 196/1000\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.3602 - accuracy: 0.7608 - val_loss: 0.3655 - val_accuracy: 0.7505\n",
      "Epoch 197/1000\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.3583 - accuracy: 0.7652 - val_loss: 0.3556 - val_accuracy: 0.7603\n",
      "Epoch 198/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3588 - accuracy: 0.7651 - val_loss: 0.3609 - val_accuracy: 0.7561\n",
      "Epoch 199/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3590 - accuracy: 0.7627 - val_loss: 0.3615 - val_accuracy: 0.7563\n",
      "Epoch 200/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3578 - accuracy: 0.7631 - val_loss: 0.3651 - val_accuracy: 0.7539\n",
      "Epoch 201/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3557 - accuracy: 0.7665 - val_loss: 0.3627 - val_accuracy: 0.7539\n",
      "Epoch 202/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3547 - accuracy: 0.7675 - val_loss: 0.3746 - val_accuracy: 0.7409\n",
      "Epoch 203/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3552 - accuracy: 0.7663 - val_loss: 0.3593 - val_accuracy: 0.7582\n",
      "Epoch 204/1000\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.3585 - accuracy: 0.7664 - val_loss: 0.3946 - val_accuracy: 0.7211\n",
      "Epoch 205/1000\n",
      "31/31 [==============================] - 2s 54ms/step - loss: 0.3557 - accuracy: 0.7673 - val_loss: 0.3771 - val_accuracy: 0.7433\n",
      "Epoch 206/1000\n",
      "31/31 [==============================] - 2s 52ms/step - loss: 0.3571 - accuracy: 0.7633 - val_loss: 0.3660 - val_accuracy: 0.7521\n",
      "Epoch 207/1000\n",
      "31/31 [==============================] - 2s 50ms/step - loss: 0.3542 - accuracy: 0.7693 - val_loss: 0.3564 - val_accuracy: 0.7601\n",
      "Epoch 208/1000\n",
      "31/31 [==============================] - 2s 60ms/step - loss: 0.3554 - accuracy: 0.7679 - val_loss: 0.3625 - val_accuracy: 0.7537\n",
      "Epoch 209/1000\n",
      "31/31 [==============================] - 2s 56ms/step - loss: 0.3537 - accuracy: 0.7714 - val_loss: 0.3569 - val_accuracy: 0.7659\n",
      "Epoch 210/1000\n",
      "31/31 [==============================] - 2s 50ms/step - loss: 0.3533 - accuracy: 0.7736 - val_loss: 0.3600 - val_accuracy: 0.7571\n",
      "Epoch 211/1000\n",
      "31/31 [==============================] - 2s 53ms/step - loss: 0.3512 - accuracy: 0.7699 - val_loss: 0.3558 - val_accuracy: 0.7601\n",
      "Epoch 212/1000\n",
      "31/31 [==============================] - 2s 50ms/step - loss: 0.3546 - accuracy: 0.7651 - val_loss: 0.4645 - val_accuracy: 0.6758\n",
      "Epoch 213/1000\n",
      "31/31 [==============================] - 2s 49ms/step - loss: 0.3574 - accuracy: 0.7651 - val_loss: 0.3564 - val_accuracy: 0.7531\n",
      "Epoch 214/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.3546 - accuracy: 0.7665 - val_loss: 0.3534 - val_accuracy: 0.7675\n",
      "Epoch 215/1000\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.3504 - accuracy: 0.7753 - val_loss: 0.3642 - val_accuracy: 0.7563\n",
      "Epoch 216/1000\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.3531 - accuracy: 0.7713 - val_loss: 0.3709 - val_accuracy: 0.7510\n",
      "Epoch 217/1000\n",
      "31/31 [==============================] - 2s 49ms/step - loss: 0.3527 - accuracy: 0.7673 - val_loss: 0.3479 - val_accuracy: 0.7654\n",
      "Epoch 218/1000\n",
      "31/31 [==============================] - 2s 53ms/step - loss: 0.3529 - accuracy: 0.7686 - val_loss: 0.3878 - val_accuracy: 0.7350\n",
      "Epoch 219/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3557 - accuracy: 0.7693 - val_loss: 0.3639 - val_accuracy: 0.7555\n",
      "Epoch 220/1000\n",
      "31/31 [==============================] - 1s 44ms/step - loss: 0.3526 - accuracy: 0.7669 - val_loss: 0.3579 - val_accuracy: 0.7545\n",
      "Epoch 221/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3527 - accuracy: 0.7680 - val_loss: 0.3964 - val_accuracy: 0.7241\n",
      "Epoch 222/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3514 - accuracy: 0.7751 - val_loss: 0.3649 - val_accuracy: 0.7513\n",
      "Epoch 223/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3503 - accuracy: 0.7717 - val_loss: 0.3521 - val_accuracy: 0.7662\n",
      "Epoch 224/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.3525 - accuracy: 0.7675 - val_loss: 0.3430 - val_accuracy: 0.7726\n",
      "Epoch 225/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3473 - accuracy: 0.7749 - val_loss: 0.3513 - val_accuracy: 0.7646\n",
      "Epoch 226/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3487 - accuracy: 0.7703 - val_loss: 0.3517 - val_accuracy: 0.7633\n",
      "Epoch 227/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3506 - accuracy: 0.7731 - val_loss: 0.3707 - val_accuracy: 0.7449\n",
      "Epoch 228/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.3498 - accuracy: 0.7731 - val_loss: 0.3583 - val_accuracy: 0.7617\n",
      "Epoch 229/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3497 - accuracy: 0.7720 - val_loss: 0.3622 - val_accuracy: 0.7526\n",
      "Epoch 230/1000\n",
      "31/31 [==============================] - 1s 44ms/step - loss: 0.3484 - accuracy: 0.7755 - val_loss: 0.3651 - val_accuracy: 0.7537\n",
      "Epoch 231/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.3483 - accuracy: 0.7694 - val_loss: 0.3735 - val_accuracy: 0.7398\n",
      "Epoch 232/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3481 - accuracy: 0.7726 - val_loss: 0.3544 - val_accuracy: 0.7643\n",
      "Epoch 233/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3501 - accuracy: 0.7727 - val_loss: 0.3481 - val_accuracy: 0.7702\n",
      "Epoch 234/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3487 - accuracy: 0.7697 - val_loss: 0.3522 - val_accuracy: 0.7595\n",
      "Epoch 235/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3479 - accuracy: 0.7737 - val_loss: 0.3520 - val_accuracy: 0.7638\n",
      "Epoch 236/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3482 - accuracy: 0.7719 - val_loss: 0.3530 - val_accuracy: 0.7622\n",
      "Epoch 237/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3469 - accuracy: 0.7721 - val_loss: 0.3607 - val_accuracy: 0.7547\n",
      "Epoch 238/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.3467 - accuracy: 0.7733 - val_loss: 0.3536 - val_accuracy: 0.7659\n",
      "Epoch 239/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3461 - accuracy: 0.7763 - val_loss: 0.3487 - val_accuracy: 0.7710\n",
      "Epoch 240/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3466 - accuracy: 0.7751 - val_loss: 0.3537 - val_accuracy: 0.7617\n",
      "Epoch 241/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3479 - accuracy: 0.7724 - val_loss: 0.3531 - val_accuracy: 0.7563\n",
      "Epoch 242/1000\n",
      "31/31 [==============================] - 1s 44ms/step - loss: 0.3459 - accuracy: 0.7755 - val_loss: 0.3481 - val_accuracy: 0.7649\n",
      "Epoch 243/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3428 - accuracy: 0.7794 - val_loss: 0.3612 - val_accuracy: 0.7545\n",
      "Epoch 244/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3418 - accuracy: 0.7766 - val_loss: 0.3558 - val_accuracy: 0.7609\n",
      "Epoch 245/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3459 - accuracy: 0.7741 - val_loss: 0.3527 - val_accuracy: 0.7617\n",
      "Epoch 246/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3421 - accuracy: 0.7793 - val_loss: 0.3494 - val_accuracy: 0.7731\n",
      "Epoch 247/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3447 - accuracy: 0.7743 - val_loss: 0.3414 - val_accuracy: 0.7734\n",
      "Epoch 248/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3433 - accuracy: 0.7754 - val_loss: 0.3628 - val_accuracy: 0.7550\n",
      "Epoch 249/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3476 - accuracy: 0.7759 - val_loss: 0.3495 - val_accuracy: 0.7689\n",
      "Epoch 250/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.3437 - accuracy: 0.7751 - val_loss: 0.3569 - val_accuracy: 0.7571\n",
      "Epoch 251/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3425 - accuracy: 0.7765 - val_loss: 0.3540 - val_accuracy: 0.7571\n",
      "Epoch 252/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3430 - accuracy: 0.7775 - val_loss: 0.3794 - val_accuracy: 0.7457\n",
      "Epoch 253/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.3436 - accuracy: 0.7761 - val_loss: 0.3556 - val_accuracy: 0.7598\n",
      "Epoch 254/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3358 - accuracy: 0.7853 - val_loss: 0.3417 - val_accuracy: 0.7723\n",
      "Epoch 255/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3432 - accuracy: 0.7782 - val_loss: 0.3416 - val_accuracy: 0.7769\n",
      "Epoch 256/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3426 - accuracy: 0.7770 - val_loss: 0.3522 - val_accuracy: 0.7675\n",
      "Epoch 257/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.3398 - accuracy: 0.7781 - val_loss: 0.3422 - val_accuracy: 0.7742\n",
      "Epoch 258/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.3396 - accuracy: 0.7807 - val_loss: 0.3587 - val_accuracy: 0.7558\n",
      "Epoch 259/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3423 - accuracy: 0.7799 - val_loss: 0.3473 - val_accuracy: 0.7667\n",
      "Epoch 260/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3400 - accuracy: 0.7799 - val_loss: 0.3414 - val_accuracy: 0.7777\n",
      "Epoch 261/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3391 - accuracy: 0.7807 - val_loss: 0.3588 - val_accuracy: 0.7611\n",
      "Epoch 262/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3421 - accuracy: 0.7773 - val_loss: 0.3550 - val_accuracy: 0.7622\n",
      "Epoch 263/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3400 - accuracy: 0.7803 - val_loss: 0.3663 - val_accuracy: 0.7515\n",
      "Epoch 264/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.3415 - accuracy: 0.7781 - val_loss: 0.3600 - val_accuracy: 0.7587\n",
      "Epoch 265/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3406 - accuracy: 0.7777 - val_loss: 0.3506 - val_accuracy: 0.7611\n",
      "Epoch 266/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3390 - accuracy: 0.7812 - val_loss: 0.3492 - val_accuracy: 0.7678\n",
      "Epoch 267/1000\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.3395 - accuracy: 0.7803 - val_loss: 0.3396 - val_accuracy: 0.7742\n",
      "Epoch 268/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.3355 - accuracy: 0.7837 - val_loss: 0.3528 - val_accuracy: 0.7651\n",
      "Epoch 269/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3344 - accuracy: 0.7863 - val_loss: 0.3588 - val_accuracy: 0.7585\n",
      "Epoch 270/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.3372 - accuracy: 0.7817 - val_loss: 0.3536 - val_accuracy: 0.7702\n",
      "Epoch 271/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3349 - accuracy: 0.7829 - val_loss: 0.3709 - val_accuracy: 0.7497\n",
      "Epoch 272/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3410 - accuracy: 0.7771 - val_loss: 0.3553 - val_accuracy: 0.7566\n",
      "Epoch 273/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3345 - accuracy: 0.7876 - val_loss: 0.3435 - val_accuracy: 0.7713\n",
      "Epoch 274/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3365 - accuracy: 0.7844 - val_loss: 0.3547 - val_accuracy: 0.7625\n",
      "Epoch 275/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3394 - accuracy: 0.7815 - val_loss: 0.3456 - val_accuracy: 0.7763\n",
      "Epoch 276/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3355 - accuracy: 0.7862 - val_loss: 0.3489 - val_accuracy: 0.7697\n",
      "Epoch 277/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3356 - accuracy: 0.7872 - val_loss: 0.3514 - val_accuracy: 0.7686\n",
      "Epoch 278/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.3379 - accuracy: 0.7822 - val_loss: 0.3527 - val_accuracy: 0.7670\n",
      "Epoch 279/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3378 - accuracy: 0.7784 - val_loss: 0.3475 - val_accuracy: 0.7678\n",
      "Epoch 280/1000\n",
      "31/31 [==============================] - 1s 48ms/step - loss: 0.3371 - accuracy: 0.7804 - val_loss: 0.3479 - val_accuracy: 0.7657\n",
      "Epoch 281/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3382 - accuracy: 0.7779 - val_loss: 0.3595 - val_accuracy: 0.7569\n",
      "Epoch 282/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.3343 - accuracy: 0.7857 - val_loss: 0.3346 - val_accuracy: 0.7854\n",
      "Epoch 283/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.3368 - accuracy: 0.7795 - val_loss: 0.3384 - val_accuracy: 0.7830\n",
      "Epoch 284/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3363 - accuracy: 0.7857 - val_loss: 0.3380 - val_accuracy: 0.7758\n",
      "Epoch 285/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3361 - accuracy: 0.7847 - val_loss: 0.3798 - val_accuracy: 0.7377\n",
      "Epoch 286/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3372 - accuracy: 0.7847 - val_loss: 0.3433 - val_accuracy: 0.7731\n",
      "Epoch 287/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3348 - accuracy: 0.7841 - val_loss: 0.3402 - val_accuracy: 0.7753\n",
      "Epoch 288/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.3337 - accuracy: 0.7835 - val_loss: 0.3382 - val_accuracy: 0.7753\n",
      "Epoch 289/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3335 - accuracy: 0.7873 - val_loss: 0.3386 - val_accuracy: 0.7769\n",
      "Epoch 290/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3352 - accuracy: 0.7838 - val_loss: 0.3380 - val_accuracy: 0.7795\n",
      "Epoch 291/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3341 - accuracy: 0.7847 - val_loss: 0.3394 - val_accuracy: 0.7721\n",
      "Epoch 292/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.3323 - accuracy: 0.7865 - val_loss: 0.3420 - val_accuracy: 0.7739\n",
      "Epoch 293/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.3334 - accuracy: 0.7858 - val_loss: 0.3376 - val_accuracy: 0.7814\n",
      "Epoch 294/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.3333 - accuracy: 0.7831 - val_loss: 0.3565 - val_accuracy: 0.7662\n",
      "Epoch 295/1000\n",
      "31/31 [==============================] - 1s 44ms/step - loss: 0.3355 - accuracy: 0.7850 - val_loss: 0.3538 - val_accuracy: 0.7673\n",
      "Epoch 296/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.3320 - accuracy: 0.7881 - val_loss: 0.3406 - val_accuracy: 0.7659\n",
      "Epoch 297/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.3321 - accuracy: 0.7875 - val_loss: 0.3559 - val_accuracy: 0.7681\n",
      "Epoch 298/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.3303 - accuracy: 0.7915 - val_loss: 0.3394 - val_accuracy: 0.7747\n",
      "Epoch 299/1000\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.3337 - accuracy: 0.7833 - val_loss: 0.3738 - val_accuracy: 0.7441\n",
      "Epoch 300/1000\n",
      "31/31 [==============================] - 1s 44ms/step - loss: 0.3394 - accuracy: 0.7798 - val_loss: 0.3960 - val_accuracy: 0.7318\n",
      "Epoch 301/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.3353 - accuracy: 0.7826 - val_loss: 0.3437 - val_accuracy: 0.7705\n",
      "Epoch 302/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.3325 - accuracy: 0.7865 - val_loss: 0.3661 - val_accuracy: 0.7491\n",
      "Epoch 303/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3341 - accuracy: 0.7842 - val_loss: 0.3376 - val_accuracy: 0.7769\n",
      "Epoch 304/1000\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.3358 - accuracy: 0.7807 - val_loss: 0.3384 - val_accuracy: 0.7737\n",
      "Epoch 305/1000\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.3334 - accuracy: 0.7875 - val_loss: 0.3355 - val_accuracy: 0.7798\n",
      "Epoch 306/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.3318 - accuracy: 0.7855 - val_loss: 0.3295 - val_accuracy: 0.7857\n",
      "Epoch 307/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3316 - accuracy: 0.7886 - val_loss: 0.3321 - val_accuracy: 0.7886\n",
      "Epoch 308/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3290 - accuracy: 0.7879 - val_loss: 0.3312 - val_accuracy: 0.7883\n",
      "Epoch 309/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3297 - accuracy: 0.7874 - val_loss: 0.3356 - val_accuracy: 0.7731\n",
      "Epoch 310/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3312 - accuracy: 0.7849 - val_loss: 0.3538 - val_accuracy: 0.7651\n",
      "Epoch 311/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3292 - accuracy: 0.7878 - val_loss: 0.3539 - val_accuracy: 0.7689\n",
      "Epoch 312/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.3311 - accuracy: 0.7901 - val_loss: 0.3503 - val_accuracy: 0.7681\n",
      "Epoch 313/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3316 - accuracy: 0.7885 - val_loss: 0.3384 - val_accuracy: 0.7806\n",
      "Epoch 314/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3316 - accuracy: 0.7851 - val_loss: 0.3420 - val_accuracy: 0.7713\n",
      "Epoch 315/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3301 - accuracy: 0.7869 - val_loss: 0.3533 - val_accuracy: 0.7659\n",
      "Epoch 316/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3312 - accuracy: 0.7879 - val_loss: 0.3386 - val_accuracy: 0.7814\n",
      "Epoch 317/1000\n",
      "31/31 [==============================] - 2s 53ms/step - loss: 0.3311 - accuracy: 0.7904 - val_loss: 0.3349 - val_accuracy: 0.7849\n",
      "Epoch 318/1000\n",
      "31/31 [==============================] - 1s 44ms/step - loss: 0.3287 - accuracy: 0.7860 - val_loss: 0.3406 - val_accuracy: 0.7766\n",
      "Epoch 319/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3310 - accuracy: 0.7857 - val_loss: 0.3291 - val_accuracy: 0.7857\n",
      "Epoch 320/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3279 - accuracy: 0.7891 - val_loss: 0.3347 - val_accuracy: 0.7809\n",
      "Epoch 321/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3292 - accuracy: 0.7870 - val_loss: 0.3271 - val_accuracy: 0.7883\n",
      "Epoch 322/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3305 - accuracy: 0.7866 - val_loss: 0.3512 - val_accuracy: 0.7670\n",
      "Epoch 323/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3305 - accuracy: 0.7891 - val_loss: 0.3343 - val_accuracy: 0.7867\n",
      "Epoch 324/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3293 - accuracy: 0.7905 - val_loss: 0.3307 - val_accuracy: 0.7811\n",
      "Epoch 325/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3260 - accuracy: 0.7901 - val_loss: 0.3472 - val_accuracy: 0.7689\n",
      "Epoch 326/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3294 - accuracy: 0.7871 - val_loss: 0.3347 - val_accuracy: 0.7801\n",
      "Epoch 327/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3270 - accuracy: 0.7939 - val_loss: 0.3241 - val_accuracy: 0.7907\n",
      "Epoch 328/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3261 - accuracy: 0.7897 - val_loss: 0.3343 - val_accuracy: 0.7790\n",
      "Epoch 329/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.3269 - accuracy: 0.7912 - val_loss: 0.3438 - val_accuracy: 0.7729\n",
      "Epoch 330/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.3258 - accuracy: 0.7915 - val_loss: 0.3523 - val_accuracy: 0.7633\n",
      "Epoch 331/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3295 - accuracy: 0.7893 - val_loss: 0.3450 - val_accuracy: 0.7646\n",
      "Epoch 332/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3257 - accuracy: 0.7928 - val_loss: 0.3461 - val_accuracy: 0.7662\n",
      "Epoch 333/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3237 - accuracy: 0.7921 - val_loss: 0.3338 - val_accuracy: 0.7819\n",
      "Epoch 334/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3254 - accuracy: 0.7966 - val_loss: 0.3321 - val_accuracy: 0.7822\n",
      "Epoch 335/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3278 - accuracy: 0.7890 - val_loss: 0.3432 - val_accuracy: 0.7678\n",
      "Epoch 336/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3294 - accuracy: 0.7869 - val_loss: 0.3490 - val_accuracy: 0.7699\n",
      "Epoch 337/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3240 - accuracy: 0.7933 - val_loss: 0.3618 - val_accuracy: 0.7574\n",
      "Epoch 338/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3281 - accuracy: 0.7901 - val_loss: 0.3420 - val_accuracy: 0.7737\n",
      "Epoch 339/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3249 - accuracy: 0.7927 - val_loss: 0.3270 - val_accuracy: 0.7830\n",
      "Epoch 340/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3242 - accuracy: 0.7906 - val_loss: 0.3364 - val_accuracy: 0.7859\n",
      "Epoch 341/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3257 - accuracy: 0.7884 - val_loss: 0.3295 - val_accuracy: 0.7819\n",
      "Epoch 342/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3262 - accuracy: 0.7927 - val_loss: 0.3523 - val_accuracy: 0.7673\n",
      "Epoch 343/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3270 - accuracy: 0.7883 - val_loss: 0.3695 - val_accuracy: 0.7585\n",
      "Epoch 344/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3257 - accuracy: 0.7915 - val_loss: 0.3256 - val_accuracy: 0.7921\n",
      "Epoch 345/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3252 - accuracy: 0.7913 - val_loss: 0.3240 - val_accuracy: 0.7905\n",
      "Epoch 346/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3236 - accuracy: 0.7961 - val_loss: 0.3329 - val_accuracy: 0.7827\n",
      "Epoch 347/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3243 - accuracy: 0.7971 - val_loss: 0.3355 - val_accuracy: 0.7761\n",
      "Epoch 348/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3255 - accuracy: 0.7897 - val_loss: 0.3455 - val_accuracy: 0.7657\n",
      "Epoch 349/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3239 - accuracy: 0.7924 - val_loss: 0.3435 - val_accuracy: 0.7691\n",
      "Epoch 350/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3256 - accuracy: 0.7939 - val_loss: 0.3332 - val_accuracy: 0.7825\n",
      "Epoch 351/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3244 - accuracy: 0.7938 - val_loss: 0.3399 - val_accuracy: 0.7782\n",
      "Epoch 352/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3239 - accuracy: 0.7959 - val_loss: 0.3263 - val_accuracy: 0.7929\n",
      "Epoch 353/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3243 - accuracy: 0.7895 - val_loss: 0.3344 - val_accuracy: 0.7846\n",
      "Epoch 354/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3241 - accuracy: 0.7928 - val_loss: 0.3443 - val_accuracy: 0.7691\n",
      "Epoch 355/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3265 - accuracy: 0.7928 - val_loss: 0.3551 - val_accuracy: 0.7638\n",
      "Epoch 356/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3224 - accuracy: 0.7961 - val_loss: 0.3339 - val_accuracy: 0.7835\n",
      "Epoch 357/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3264 - accuracy: 0.7890 - val_loss: 0.3267 - val_accuracy: 0.7846\n",
      "Epoch 358/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3251 - accuracy: 0.7921 - val_loss: 0.3438 - val_accuracy: 0.7707\n",
      "Epoch 359/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3259 - accuracy: 0.7928 - val_loss: 0.3385 - val_accuracy: 0.7793\n",
      "Epoch 360/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.3246 - accuracy: 0.7978 - val_loss: 0.3382 - val_accuracy: 0.7795\n",
      "Epoch 361/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3195 - accuracy: 0.7953 - val_loss: 0.3453 - val_accuracy: 0.7686\n",
      "Epoch 362/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3242 - accuracy: 0.7934 - val_loss: 0.3520 - val_accuracy: 0.7606\n",
      "Epoch 363/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3224 - accuracy: 0.7933 - val_loss: 0.3358 - val_accuracy: 0.7806\n",
      "Epoch 364/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3209 - accuracy: 0.7946 - val_loss: 0.3247 - val_accuracy: 0.7878\n",
      "Epoch 365/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3200 - accuracy: 0.8008 - val_loss: 0.3535 - val_accuracy: 0.7646\n",
      "Epoch 366/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3214 - accuracy: 0.7967 - val_loss: 0.3396 - val_accuracy: 0.7758\n",
      "Epoch 367/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3213 - accuracy: 0.7950 - val_loss: 0.3342 - val_accuracy: 0.7785\n",
      "Epoch 368/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3251 - accuracy: 0.7893 - val_loss: 0.3723 - val_accuracy: 0.7478\n",
      "Epoch 369/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3247 - accuracy: 0.7952 - val_loss: 0.3343 - val_accuracy: 0.7846\n",
      "Epoch 370/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3244 - accuracy: 0.7896 - val_loss: 0.3417 - val_accuracy: 0.7790\n",
      "Epoch 371/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.3219 - accuracy: 0.7962 - val_loss: 0.3421 - val_accuracy: 0.7745\n",
      "Epoch 372/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3232 - accuracy: 0.7957 - val_loss: 0.3390 - val_accuracy: 0.7777\n",
      "Epoch 373/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3232 - accuracy: 0.7941 - val_loss: 0.3371 - val_accuracy: 0.7777\n",
      "Epoch 374/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3212 - accuracy: 0.7955 - val_loss: 0.3441 - val_accuracy: 0.7766\n",
      "Epoch 375/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3205 - accuracy: 0.7965 - val_loss: 0.3429 - val_accuracy: 0.7779\n",
      "Epoch 376/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3201 - accuracy: 0.7960 - val_loss: 0.3326 - val_accuracy: 0.7795\n",
      "Epoch 377/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3223 - accuracy: 0.7940 - val_loss: 0.3313 - val_accuracy: 0.7827\n",
      "Epoch 378/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3193 - accuracy: 0.7985 - val_loss: 0.3381 - val_accuracy: 0.7763\n",
      "Epoch 379/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3222 - accuracy: 0.7947 - val_loss: 0.3555 - val_accuracy: 0.7625\n",
      "Epoch 380/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3217 - accuracy: 0.7942 - val_loss: 0.3854 - val_accuracy: 0.7465\n",
      "Epoch 381/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3223 - accuracy: 0.7951 - val_loss: 0.3351 - val_accuracy: 0.7742\n",
      "Epoch 382/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3161 - accuracy: 0.8005 - val_loss: 0.3694 - val_accuracy: 0.7459\n",
      "Epoch 383/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3224 - accuracy: 0.7953 - val_loss: 0.3229 - val_accuracy: 0.7905\n",
      "Epoch 384/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3202 - accuracy: 0.7948 - val_loss: 0.3175 - val_accuracy: 0.7963\n",
      "Epoch 385/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3190 - accuracy: 0.7985 - val_loss: 0.3303 - val_accuracy: 0.7851\n",
      "Epoch 386/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3200 - accuracy: 0.7969 - val_loss: 0.3453 - val_accuracy: 0.7710\n",
      "Epoch 387/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3225 - accuracy: 0.7959 - val_loss: 0.3287 - val_accuracy: 0.7814\n",
      "Epoch 388/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3226 - accuracy: 0.7959 - val_loss: 0.3323 - val_accuracy: 0.7793\n",
      "Epoch 389/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3181 - accuracy: 0.8005 - val_loss: 0.3443 - val_accuracy: 0.7729\n",
      "Epoch 390/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3205 - accuracy: 0.7958 - val_loss: 0.3397 - val_accuracy: 0.7774\n",
      "Epoch 391/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3202 - accuracy: 0.7973 - val_loss: 0.3411 - val_accuracy: 0.7729\n",
      "Epoch 392/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3199 - accuracy: 0.7951 - val_loss: 0.3404 - val_accuracy: 0.7721\n",
      "Epoch 393/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3187 - accuracy: 0.7952 - val_loss: 0.3841 - val_accuracy: 0.7446\n",
      "Epoch 394/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3259 - accuracy: 0.7885 - val_loss: 0.3646 - val_accuracy: 0.7585\n",
      "Epoch 395/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3207 - accuracy: 0.8006 - val_loss: 0.3248 - val_accuracy: 0.7843\n",
      "Epoch 396/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3174 - accuracy: 0.7996 - val_loss: 0.3349 - val_accuracy: 0.7822\n",
      "Epoch 397/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3188 - accuracy: 0.7988 - val_loss: 0.3594 - val_accuracy: 0.7598\n",
      "Epoch 398/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3194 - accuracy: 0.7972 - val_loss: 0.4086 - val_accuracy: 0.7291\n",
      "Epoch 399/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3193 - accuracy: 0.7957 - val_loss: 0.3247 - val_accuracy: 0.7937\n",
      "Epoch 400/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3221 - accuracy: 0.7953 - val_loss: 0.3375 - val_accuracy: 0.7785\n",
      "Epoch 401/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3178 - accuracy: 0.7995 - val_loss: 0.3255 - val_accuracy: 0.7958\n",
      "Epoch 402/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3182 - accuracy: 0.7989 - val_loss: 0.3268 - val_accuracy: 0.7881\n",
      "Epoch 403/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3149 - accuracy: 0.7998 - val_loss: 0.3452 - val_accuracy: 0.7705\n",
      "Epoch 404/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3198 - accuracy: 0.7993 - val_loss: 0.3436 - val_accuracy: 0.7713\n",
      "Epoch 405/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3207 - accuracy: 0.7922 - val_loss: 0.3363 - val_accuracy: 0.7729\n",
      "Epoch 406/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3157 - accuracy: 0.7985 - val_loss: 0.3266 - val_accuracy: 0.7865\n",
      "Epoch 407/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3225 - accuracy: 0.7949 - val_loss: 0.3417 - val_accuracy: 0.7707\n",
      "Epoch 408/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3167 - accuracy: 0.7957 - val_loss: 0.3282 - val_accuracy: 0.7886\n",
      "Epoch 409/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3206 - accuracy: 0.7982 - val_loss: 0.3395 - val_accuracy: 0.7787\n",
      "Epoch 410/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3155 - accuracy: 0.8050 - val_loss: 0.3262 - val_accuracy: 0.7835\n",
      "Epoch 411/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3160 - accuracy: 0.7999 - val_loss: 0.3405 - val_accuracy: 0.7715\n",
      "Epoch 412/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3197 - accuracy: 0.7980 - val_loss: 0.3259 - val_accuracy: 0.7835\n",
      "Epoch 413/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3215 - accuracy: 0.7934 - val_loss: 0.3277 - val_accuracy: 0.7835\n",
      "Epoch 414/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3187 - accuracy: 0.7963 - val_loss: 0.3247 - val_accuracy: 0.7875\n",
      "Epoch 415/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3174 - accuracy: 0.7974 - val_loss: 0.3390 - val_accuracy: 0.7729\n",
      "Epoch 416/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3165 - accuracy: 0.7971 - val_loss: 0.3389 - val_accuracy: 0.7723\n",
      "Epoch 417/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3171 - accuracy: 0.8009 - val_loss: 0.3356 - val_accuracy: 0.7790\n",
      "Epoch 418/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3162 - accuracy: 0.7994 - val_loss: 0.3582 - val_accuracy: 0.7627\n",
      "Epoch 419/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3177 - accuracy: 0.7971 - val_loss: 0.3250 - val_accuracy: 0.7843\n",
      "Epoch 420/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3188 - accuracy: 0.8006 - val_loss: 0.3374 - val_accuracy: 0.7726\n",
      "Epoch 421/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3178 - accuracy: 0.7975 - val_loss: 0.3522 - val_accuracy: 0.7657\n",
      "Epoch 422/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3175 - accuracy: 0.7985 - val_loss: 0.3432 - val_accuracy: 0.7697\n",
      "Epoch 423/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3160 - accuracy: 0.7999 - val_loss: 0.3526 - val_accuracy: 0.7675\n",
      "Epoch 424/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.3183 - accuracy: 0.7983 - val_loss: 0.3378 - val_accuracy: 0.7859\n",
      "Epoch 425/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3187 - accuracy: 0.7947 - val_loss: 0.3322 - val_accuracy: 0.7857\n",
      "Epoch 426/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3190 - accuracy: 0.7986 - val_loss: 0.4281 - val_accuracy: 0.7155\n",
      "Epoch 427/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3246 - accuracy: 0.7953 - val_loss: 0.3482 - val_accuracy: 0.7681\n",
      "Epoch 428/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3150 - accuracy: 0.7984 - val_loss: 0.3359 - val_accuracy: 0.7761\n",
      "Epoch 429/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3149 - accuracy: 0.7998 - val_loss: 0.3520 - val_accuracy: 0.7726\n",
      "Epoch 430/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3172 - accuracy: 0.8010 - val_loss: 0.3367 - val_accuracy: 0.7755\n",
      "Epoch 431/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3140 - accuracy: 0.8018 - val_loss: 0.3299 - val_accuracy: 0.7883\n",
      "Epoch 432/1000\n",
      "31/31 [==============================] - 1s 36ms/step - loss: 0.3153 - accuracy: 0.7993 - val_loss: 0.3495 - val_accuracy: 0.7734\n",
      "Epoch 433/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3138 - accuracy: 0.8045 - val_loss: 0.3353 - val_accuracy: 0.7891\n",
      "Epoch 434/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3174 - accuracy: 0.7985 - val_loss: 0.3410 - val_accuracy: 0.7745\n",
      "Epoch 435/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3175 - accuracy: 0.7991 - val_loss: 0.3328 - val_accuracy: 0.7777\n",
      "Epoch 436/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3162 - accuracy: 0.8007 - val_loss: 0.3282 - val_accuracy: 0.7822\n",
      "Epoch 437/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3146 - accuracy: 0.8029 - val_loss: 0.3279 - val_accuracy: 0.7870\n",
      "Epoch 438/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3176 - accuracy: 0.7971 - val_loss: 0.3234 - val_accuracy: 0.7926\n",
      "Epoch 439/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3152 - accuracy: 0.8012 - val_loss: 0.3406 - val_accuracy: 0.7798\n",
      "Epoch 440/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3164 - accuracy: 0.7967 - val_loss: 0.3223 - val_accuracy: 0.7926\n",
      "Epoch 441/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3155 - accuracy: 0.7989 - val_loss: 0.3250 - val_accuracy: 0.7841\n",
      "Epoch 442/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3157 - accuracy: 0.8003 - val_loss: 0.3253 - val_accuracy: 0.7883\n",
      "Epoch 443/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3142 - accuracy: 0.8031 - val_loss: 0.3941 - val_accuracy: 0.7430\n",
      "Epoch 444/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3152 - accuracy: 0.8010 - val_loss: 0.3320 - val_accuracy: 0.7830\n",
      "Epoch 445/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3175 - accuracy: 0.7984 - val_loss: 0.3496 - val_accuracy: 0.7707\n",
      "Epoch 446/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3170 - accuracy: 0.7969 - val_loss: 0.3286 - val_accuracy: 0.7822\n",
      "Epoch 447/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3171 - accuracy: 0.7980 - val_loss: 0.3171 - val_accuracy: 0.7921\n",
      "Epoch 448/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.3168 - accuracy: 0.8023 - val_loss: 0.3406 - val_accuracy: 0.7747\n",
      "Epoch 449/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3134 - accuracy: 0.7995 - val_loss: 0.3828 - val_accuracy: 0.7449\n",
      "Epoch 450/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.3200 - accuracy: 0.7939 - val_loss: 0.3259 - val_accuracy: 0.7846\n",
      "Epoch 451/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3131 - accuracy: 0.8029 - val_loss: 0.3427 - val_accuracy: 0.7731\n",
      "Epoch 452/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3135 - accuracy: 0.7991 - val_loss: 0.3299 - val_accuracy: 0.7811\n",
      "Epoch 453/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3137 - accuracy: 0.8034 - val_loss: 0.3189 - val_accuracy: 0.7931\n",
      "Epoch 454/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3162 - accuracy: 0.7987 - val_loss: 0.3453 - val_accuracy: 0.7731\n",
      "Epoch 455/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3135 - accuracy: 0.8011 - val_loss: 0.3322 - val_accuracy: 0.7835\n",
      "Epoch 456/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3133 - accuracy: 0.8035 - val_loss: 0.3366 - val_accuracy: 0.7779\n",
      "Epoch 457/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3136 - accuracy: 0.8026 - val_loss: 0.3524 - val_accuracy: 0.7702\n",
      "Epoch 458/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3146 - accuracy: 0.8003 - val_loss: 0.3233 - val_accuracy: 0.7915\n",
      "Epoch 459/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3118 - accuracy: 0.8061 - val_loss: 0.3343 - val_accuracy: 0.7822\n",
      "Epoch 460/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3147 - accuracy: 0.7994 - val_loss: 0.3460 - val_accuracy: 0.7747\n",
      "Epoch 461/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.3152 - accuracy: 0.8018 - val_loss: 0.3162 - val_accuracy: 0.7985\n",
      "Epoch 462/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3132 - accuracy: 0.8023 - val_loss: 0.3227 - val_accuracy: 0.7851\n",
      "Epoch 463/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.3146 - accuracy: 0.8013 - val_loss: 0.3214 - val_accuracy: 0.7929\n",
      "Epoch 464/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3124 - accuracy: 0.8046 - val_loss: 0.3301 - val_accuracy: 0.7785\n",
      "Epoch 465/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3129 - accuracy: 0.8040 - val_loss: 0.3450 - val_accuracy: 0.7750\n",
      "Epoch 466/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3139 - accuracy: 0.8044 - val_loss: 0.3498 - val_accuracy: 0.7651\n",
      "Epoch 467/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3141 - accuracy: 0.8019 - val_loss: 0.3296 - val_accuracy: 0.7862\n",
      "Epoch 468/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3120 - accuracy: 0.8042 - val_loss: 0.3347 - val_accuracy: 0.7782\n",
      "Epoch 469/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3156 - accuracy: 0.7988 - val_loss: 0.3575 - val_accuracy: 0.7662\n",
      "Epoch 470/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3138 - accuracy: 0.8047 - val_loss: 0.3389 - val_accuracy: 0.7806\n",
      "Epoch 471/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3158 - accuracy: 0.8011 - val_loss: 0.3178 - val_accuracy: 0.7934\n",
      "Epoch 472/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3146 - accuracy: 0.7982 - val_loss: 0.3473 - val_accuracy: 0.7758\n",
      "Epoch 473/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3118 - accuracy: 0.8066 - val_loss: 0.3378 - val_accuracy: 0.7827\n",
      "Epoch 474/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3162 - accuracy: 0.8022 - val_loss: 0.3371 - val_accuracy: 0.7795\n",
      "Epoch 475/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3145 - accuracy: 0.7991 - val_loss: 0.3268 - val_accuracy: 0.7857\n",
      "Epoch 476/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3151 - accuracy: 0.8011 - val_loss: 0.3161 - val_accuracy: 0.7923\n",
      "Epoch 477/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3110 - accuracy: 0.8051 - val_loss: 0.3292 - val_accuracy: 0.7873\n",
      "Epoch 478/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3100 - accuracy: 0.8045 - val_loss: 0.3259 - val_accuracy: 0.7907\n",
      "Epoch 479/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3117 - accuracy: 0.8015 - val_loss: 0.3324 - val_accuracy: 0.7803\n",
      "Epoch 480/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3130 - accuracy: 0.7979 - val_loss: 0.3280 - val_accuracy: 0.7841\n",
      "Epoch 481/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3123 - accuracy: 0.8040 - val_loss: 0.3712 - val_accuracy: 0.7593\n",
      "Epoch 482/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3109 - accuracy: 0.8035 - val_loss: 0.3365 - val_accuracy: 0.7771\n",
      "Epoch 483/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3104 - accuracy: 0.8047 - val_loss: 0.3345 - val_accuracy: 0.7851\n",
      "Epoch 484/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3121 - accuracy: 0.8047 - val_loss: 0.3480 - val_accuracy: 0.7707\n",
      "Epoch 485/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3107 - accuracy: 0.8059 - val_loss: 0.3384 - val_accuracy: 0.7769\n",
      "Epoch 486/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3091 - accuracy: 0.8046 - val_loss: 0.3308 - val_accuracy: 0.7814\n",
      "Epoch 487/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3130 - accuracy: 0.8003 - val_loss: 0.3411 - val_accuracy: 0.7707\n",
      "Epoch 488/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3073 - accuracy: 0.8062 - val_loss: 0.3376 - val_accuracy: 0.7814\n",
      "Epoch 489/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3113 - accuracy: 0.8020 - val_loss: 0.3315 - val_accuracy: 0.7921\n",
      "Epoch 490/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3091 - accuracy: 0.8059 - val_loss: 0.3246 - val_accuracy: 0.7897\n",
      "Epoch 491/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3127 - accuracy: 0.8042 - val_loss: 0.3391 - val_accuracy: 0.7761\n",
      "Epoch 492/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3113 - accuracy: 0.8045 - val_loss: 0.3290 - val_accuracy: 0.7811\n",
      "Epoch 493/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3092 - accuracy: 0.8083 - val_loss: 0.3527 - val_accuracy: 0.7697\n",
      "Epoch 494/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3109 - accuracy: 0.8034 - val_loss: 0.3316 - val_accuracy: 0.7806\n",
      "Epoch 495/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3116 - accuracy: 0.8008 - val_loss: 0.3266 - val_accuracy: 0.7843\n",
      "Epoch 496/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3098 - accuracy: 0.8026 - val_loss: 0.3469 - val_accuracy: 0.7654\n",
      "Epoch 497/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3142 - accuracy: 0.8017 - val_loss: 0.3339 - val_accuracy: 0.7854\n",
      "Epoch 498/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3103 - accuracy: 0.8025 - val_loss: 0.3309 - val_accuracy: 0.7830\n",
      "Epoch 499/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3110 - accuracy: 0.8027 - val_loss: 0.3356 - val_accuracy: 0.7766\n",
      "Epoch 500/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3149 - accuracy: 0.8031 - val_loss: 0.3502 - val_accuracy: 0.7721\n",
      "Epoch 501/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3139 - accuracy: 0.7987 - val_loss: 0.3365 - val_accuracy: 0.7811\n",
      "Epoch 502/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3110 - accuracy: 0.8052 - val_loss: 0.3280 - val_accuracy: 0.7825\n",
      "Epoch 503/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.3100 - accuracy: 0.8040 - val_loss: 0.3194 - val_accuracy: 0.7921\n",
      "Epoch 504/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3116 - accuracy: 0.8041 - val_loss: 0.3232 - val_accuracy: 0.7889\n",
      "Epoch 505/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3122 - accuracy: 0.8046 - val_loss: 0.3434 - val_accuracy: 0.7721\n",
      "Epoch 506/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3103 - accuracy: 0.8040 - val_loss: 0.3258 - val_accuracy: 0.7843\n",
      "Epoch 507/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3111 - accuracy: 0.8031 - val_loss: 0.3186 - val_accuracy: 0.7899\n",
      "Epoch 508/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3109 - accuracy: 0.8053 - val_loss: 0.3315 - val_accuracy: 0.7838\n",
      "Epoch 509/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3111 - accuracy: 0.8029 - val_loss: 0.3462 - val_accuracy: 0.7763\n",
      "Epoch 510/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3119 - accuracy: 0.8059 - val_loss: 0.3515 - val_accuracy: 0.7747\n",
      "Epoch 511/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3097 - accuracy: 0.8058 - val_loss: 0.3227 - val_accuracy: 0.7894\n",
      "Epoch 512/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3103 - accuracy: 0.8021 - val_loss: 0.3443 - val_accuracy: 0.7702\n",
      "Epoch 513/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3124 - accuracy: 0.8011 - val_loss: 0.3236 - val_accuracy: 0.7878\n",
      "Epoch 514/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3086 - accuracy: 0.8074 - val_loss: 0.3330 - val_accuracy: 0.7846\n",
      "Epoch 515/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.3088 - accuracy: 0.8067 - val_loss: 0.3323 - val_accuracy: 0.7771\n",
      "Epoch 516/1000\n",
      "31/31 [==============================] - 1s 44ms/step - loss: 0.3094 - accuracy: 0.8031 - val_loss: 0.3294 - val_accuracy: 0.7825\n",
      "Epoch 517/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3088 - accuracy: 0.8079 - val_loss: 0.3216 - val_accuracy: 0.7899\n",
      "Epoch 518/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3101 - accuracy: 0.7990 - val_loss: 0.3270 - val_accuracy: 0.7862\n",
      "Epoch 519/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3102 - accuracy: 0.8027 - val_loss: 0.3657 - val_accuracy: 0.7595\n",
      "Epoch 520/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3096 - accuracy: 0.8051 - val_loss: 0.3252 - val_accuracy: 0.7891\n",
      "Epoch 521/1000\n",
      "31/31 [==============================] - 1s 36ms/step - loss: 0.3079 - accuracy: 0.8055 - val_loss: 0.3253 - val_accuracy: 0.7822\n",
      "Epoch 522/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3079 - accuracy: 0.8071 - val_loss: 0.3336 - val_accuracy: 0.7819\n",
      "Epoch 523/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3125 - accuracy: 0.8000 - val_loss: 0.3380 - val_accuracy: 0.7699\n",
      "Epoch 524/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3089 - accuracy: 0.8025 - val_loss: 0.3203 - val_accuracy: 0.7897\n",
      "Epoch 525/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3085 - accuracy: 0.8071 - val_loss: 0.3606 - val_accuracy: 0.7686\n",
      "Epoch 526/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3092 - accuracy: 0.8051 - val_loss: 0.3300 - val_accuracy: 0.7841\n",
      "Epoch 527/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.3100 - accuracy: 0.8041 - val_loss: 0.3301 - val_accuracy: 0.7785\n",
      "Epoch 528/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3136 - accuracy: 0.8017 - val_loss: 0.3300 - val_accuracy: 0.7915\n",
      "Epoch 529/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.3080 - accuracy: 0.8053 - val_loss: 0.3452 - val_accuracy: 0.7801\n",
      "Epoch 530/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3080 - accuracy: 0.8063 - val_loss: 0.3312 - val_accuracy: 0.7793\n",
      "Epoch 531/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3093 - accuracy: 0.8032 - val_loss: 0.3307 - val_accuracy: 0.7841\n",
      "Epoch 532/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3100 - accuracy: 0.8032 - val_loss: 0.3334 - val_accuracy: 0.7819\n",
      "Epoch 533/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3087 - accuracy: 0.8064 - val_loss: 0.3248 - val_accuracy: 0.7843\n",
      "Epoch 534/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3065 - accuracy: 0.8071 - val_loss: 0.3267 - val_accuracy: 0.7897\n",
      "Epoch 535/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3076 - accuracy: 0.8059 - val_loss: 0.3346 - val_accuracy: 0.7801\n",
      "Epoch 536/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3045 - accuracy: 0.8120 - val_loss: 0.3161 - val_accuracy: 0.7955\n",
      "Epoch 537/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3067 - accuracy: 0.8086 - val_loss: 0.3317 - val_accuracy: 0.7897\n",
      "Epoch 538/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3073 - accuracy: 0.8033 - val_loss: 0.3355 - val_accuracy: 0.7779\n",
      "Epoch 539/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.3112 - accuracy: 0.8059 - val_loss: 0.3228 - val_accuracy: 0.7873\n",
      "Epoch 540/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3091 - accuracy: 0.8035 - val_loss: 0.3487 - val_accuracy: 0.7734\n",
      "Epoch 541/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3077 - accuracy: 0.8058 - val_loss: 0.3346 - val_accuracy: 0.7835\n",
      "Epoch 542/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3067 - accuracy: 0.8032 - val_loss: 0.3457 - val_accuracy: 0.7665\n",
      "Epoch 543/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3095 - accuracy: 0.8057 - val_loss: 0.3314 - val_accuracy: 0.7779\n",
      "Epoch 544/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3052 - accuracy: 0.8096 - val_loss: 0.3298 - val_accuracy: 0.7801\n",
      "Epoch 545/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3084 - accuracy: 0.8047 - val_loss: 0.3370 - val_accuracy: 0.7707\n",
      "Epoch 546/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3085 - accuracy: 0.8087 - val_loss: 0.3223 - val_accuracy: 0.7889\n",
      "Epoch 547/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3065 - accuracy: 0.8082 - val_loss: 0.3581 - val_accuracy: 0.7598\n",
      "Epoch 548/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3090 - accuracy: 0.8034 - val_loss: 0.3271 - val_accuracy: 0.7841\n",
      "Epoch 549/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3099 - accuracy: 0.8099 - val_loss: 0.3243 - val_accuracy: 0.7825\n",
      "Epoch 550/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3078 - accuracy: 0.8052 - val_loss: 0.3232 - val_accuracy: 0.7889\n",
      "Epoch 551/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3069 - accuracy: 0.8093 - val_loss: 0.3210 - val_accuracy: 0.7915\n",
      "Epoch 552/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.3053 - accuracy: 0.8133 - val_loss: 0.3247 - val_accuracy: 0.7851\n",
      "Epoch 553/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3057 - accuracy: 0.8085 - val_loss: 0.3328 - val_accuracy: 0.7843\n",
      "Epoch 554/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3050 - accuracy: 0.8061 - val_loss: 0.3320 - val_accuracy: 0.7830\n",
      "Epoch 555/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.3023 - accuracy: 0.8116 - val_loss: 0.3222 - val_accuracy: 0.7934\n",
      "Epoch 556/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3090 - accuracy: 0.8064 - val_loss: 0.3449 - val_accuracy: 0.7747\n",
      "Epoch 557/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3059 - accuracy: 0.8081 - val_loss: 0.3258 - val_accuracy: 0.7918\n",
      "Epoch 558/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3041 - accuracy: 0.8078 - val_loss: 0.3535 - val_accuracy: 0.7641\n",
      "Epoch 559/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3070 - accuracy: 0.8083 - val_loss: 0.3332 - val_accuracy: 0.7806\n",
      "Epoch 560/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3075 - accuracy: 0.8079 - val_loss: 0.3504 - val_accuracy: 0.7641\n",
      "Epoch 561/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3061 - accuracy: 0.8085 - val_loss: 0.3182 - val_accuracy: 0.7921\n",
      "Epoch 562/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3010 - accuracy: 0.8111 - val_loss: 0.3158 - val_accuracy: 0.7950\n",
      "Epoch 563/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3052 - accuracy: 0.8081 - val_loss: 0.3304 - val_accuracy: 0.7787\n",
      "Epoch 564/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3071 - accuracy: 0.8069 - val_loss: 0.3356 - val_accuracy: 0.7822\n",
      "Epoch 565/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3095 - accuracy: 0.8032 - val_loss: 0.3255 - val_accuracy: 0.7843\n",
      "Epoch 566/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3066 - accuracy: 0.8091 - val_loss: 0.3237 - val_accuracy: 0.7835\n",
      "Epoch 567/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3050 - accuracy: 0.8102 - val_loss: 0.3201 - val_accuracy: 0.7945\n",
      "Epoch 568/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3057 - accuracy: 0.8081 - val_loss: 0.3311 - val_accuracy: 0.7841\n",
      "Epoch 569/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.3039 - accuracy: 0.8113 - val_loss: 0.3276 - val_accuracy: 0.7883\n",
      "Epoch 570/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3050 - accuracy: 0.8100 - val_loss: 0.3303 - val_accuracy: 0.7787\n",
      "Epoch 571/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3056 - accuracy: 0.8071 - val_loss: 0.3326 - val_accuracy: 0.7766\n",
      "Epoch 572/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3046 - accuracy: 0.8083 - val_loss: 0.3229 - val_accuracy: 0.7899\n",
      "Epoch 573/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3082 - accuracy: 0.8078 - val_loss: 0.3213 - val_accuracy: 0.7886\n",
      "Epoch 574/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3024 - accuracy: 0.8110 - val_loss: 0.3557 - val_accuracy: 0.7694\n",
      "Epoch 575/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3061 - accuracy: 0.8078 - val_loss: 0.3249 - val_accuracy: 0.7843\n",
      "Epoch 576/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3089 - accuracy: 0.8066 - val_loss: 0.3398 - val_accuracy: 0.7739\n",
      "Epoch 577/1000\n",
      "31/31 [==============================] - 1s 36ms/step - loss: 0.3045 - accuracy: 0.8076 - val_loss: 0.3200 - val_accuracy: 0.7926\n",
      "Epoch 578/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3035 - accuracy: 0.8129 - val_loss: 0.3212 - val_accuracy: 0.7939\n",
      "Epoch 579/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3060 - accuracy: 0.8084 - val_loss: 0.3308 - val_accuracy: 0.7779\n",
      "Epoch 580/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3087 - accuracy: 0.8046 - val_loss: 0.3184 - val_accuracy: 0.7955\n",
      "Epoch 581/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3024 - accuracy: 0.8135 - val_loss: 0.3269 - val_accuracy: 0.7875\n",
      "Epoch 582/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3053 - accuracy: 0.8085 - val_loss: 0.3233 - val_accuracy: 0.7934\n",
      "Epoch 583/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3049 - accuracy: 0.8104 - val_loss: 0.3256 - val_accuracy: 0.7835\n",
      "Epoch 584/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3058 - accuracy: 0.8086 - val_loss: 0.3159 - val_accuracy: 0.7977\n",
      "Epoch 585/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3033 - accuracy: 0.8122 - val_loss: 0.3528 - val_accuracy: 0.7750\n",
      "Epoch 586/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3040 - accuracy: 0.8091 - val_loss: 0.3378 - val_accuracy: 0.7798\n",
      "Epoch 587/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3059 - accuracy: 0.8063 - val_loss: 0.3362 - val_accuracy: 0.7742\n",
      "Epoch 588/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3056 - accuracy: 0.8083 - val_loss: 0.3335 - val_accuracy: 0.7806\n",
      "Epoch 589/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3030 - accuracy: 0.8105 - val_loss: 0.3331 - val_accuracy: 0.7782\n",
      "Epoch 590/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3062 - accuracy: 0.8069 - val_loss: 0.3213 - val_accuracy: 0.7913\n",
      "Epoch 591/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3052 - accuracy: 0.8077 - val_loss: 0.3222 - val_accuracy: 0.7945\n",
      "Epoch 592/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3050 - accuracy: 0.8089 - val_loss: 0.3134 - val_accuracy: 0.7934\n",
      "Epoch 593/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3049 - accuracy: 0.8052 - val_loss: 0.3202 - val_accuracy: 0.7867\n",
      "Epoch 594/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3017 - accuracy: 0.8100 - val_loss: 0.3272 - val_accuracy: 0.7875\n",
      "Epoch 595/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3033 - accuracy: 0.8073 - val_loss: 0.3188 - val_accuracy: 0.7886\n",
      "Epoch 596/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3036 - accuracy: 0.8082 - val_loss: 0.3486 - val_accuracy: 0.7638\n",
      "Epoch 597/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3044 - accuracy: 0.8103 - val_loss: 0.3605 - val_accuracy: 0.7723\n",
      "Epoch 598/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3101 - accuracy: 0.8010 - val_loss: 0.3212 - val_accuracy: 0.7897\n",
      "Epoch 599/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3056 - accuracy: 0.8071 - val_loss: 0.3303 - val_accuracy: 0.7827\n",
      "Epoch 600/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3017 - accuracy: 0.8100 - val_loss: 0.3178 - val_accuracy: 0.7931\n",
      "Epoch 601/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3051 - accuracy: 0.8099 - val_loss: 0.3331 - val_accuracy: 0.7838\n",
      "Epoch 602/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3048 - accuracy: 0.8075 - val_loss: 0.3230 - val_accuracy: 0.7910\n",
      "Epoch 603/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3044 - accuracy: 0.8105 - val_loss: 0.3159 - val_accuracy: 0.7974\n",
      "Epoch 604/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3045 - accuracy: 0.8106 - val_loss: 0.3294 - val_accuracy: 0.7865\n",
      "Epoch 605/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3042 - accuracy: 0.8077 - val_loss: 0.3192 - val_accuracy: 0.7953\n",
      "Epoch 606/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3063 - accuracy: 0.8069 - val_loss: 0.3260 - val_accuracy: 0.7878\n",
      "Epoch 607/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3024 - accuracy: 0.8107 - val_loss: 0.3267 - val_accuracy: 0.7889\n",
      "Epoch 608/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3081 - accuracy: 0.8023 - val_loss: 0.3247 - val_accuracy: 0.7886\n",
      "Epoch 609/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3021 - accuracy: 0.8093 - val_loss: 0.3363 - val_accuracy: 0.7739\n",
      "Epoch 610/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3017 - accuracy: 0.8141 - val_loss: 0.3295 - val_accuracy: 0.7889\n",
      "Epoch 611/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.2990 - accuracy: 0.8123 - val_loss: 0.3331 - val_accuracy: 0.7875\n",
      "Epoch 612/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3020 - accuracy: 0.8116 - val_loss: 0.3328 - val_accuracy: 0.7811\n",
      "Epoch 613/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3055 - accuracy: 0.8083 - val_loss: 0.3354 - val_accuracy: 0.7827\n",
      "Epoch 614/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3011 - accuracy: 0.8099 - val_loss: 0.3193 - val_accuracy: 0.7990\n",
      "Epoch 615/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3026 - accuracy: 0.8103 - val_loss: 0.3211 - val_accuracy: 0.7873\n",
      "Epoch 616/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.2999 - accuracy: 0.8115 - val_loss: 0.3263 - val_accuracy: 0.7846\n",
      "Epoch 617/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3043 - accuracy: 0.8089 - val_loss: 0.3202 - val_accuracy: 0.7934\n",
      "Epoch 618/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3018 - accuracy: 0.8106 - val_loss: 0.3247 - val_accuracy: 0.7899\n",
      "Epoch 619/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3055 - accuracy: 0.8091 - val_loss: 0.3260 - val_accuracy: 0.7942\n",
      "Epoch 620/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.2995 - accuracy: 0.8124 - val_loss: 0.3247 - val_accuracy: 0.7886\n",
      "Epoch 621/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3012 - accuracy: 0.8103 - val_loss: 0.3260 - val_accuracy: 0.7817\n",
      "Epoch 622/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3043 - accuracy: 0.8068 - val_loss: 0.3326 - val_accuracy: 0.7806\n",
      "Epoch 623/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3041 - accuracy: 0.8097 - val_loss: 0.3459 - val_accuracy: 0.7838\n",
      "Epoch 624/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3005 - accuracy: 0.8134 - val_loss: 0.3323 - val_accuracy: 0.7814\n",
      "Epoch 625/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3028 - accuracy: 0.8089 - val_loss: 0.3269 - val_accuracy: 0.7833\n",
      "Epoch 626/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3045 - accuracy: 0.8086 - val_loss: 0.3320 - val_accuracy: 0.7883\n",
      "Epoch 627/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3039 - accuracy: 0.8121 - val_loss: 0.3163 - val_accuracy: 0.7921\n",
      "Epoch 628/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3027 - accuracy: 0.8104 - val_loss: 0.3151 - val_accuracy: 0.7974\n",
      "Epoch 629/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3010 - accuracy: 0.8120 - val_loss: 0.3457 - val_accuracy: 0.7710\n",
      "Epoch 630/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3052 - accuracy: 0.8093 - val_loss: 0.3481 - val_accuracy: 0.7742\n",
      "Epoch 631/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3033 - accuracy: 0.8111 - val_loss: 0.3301 - val_accuracy: 0.7809\n",
      "Epoch 632/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3008 - accuracy: 0.8148 - val_loss: 0.3217 - val_accuracy: 0.7913\n",
      "Epoch 633/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3017 - accuracy: 0.8114 - val_loss: 0.3206 - val_accuracy: 0.7910\n",
      "Epoch 634/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3033 - accuracy: 0.8105 - val_loss: 0.3227 - val_accuracy: 0.7862\n",
      "Epoch 635/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3033 - accuracy: 0.8091 - val_loss: 0.3484 - val_accuracy: 0.7665\n",
      "Epoch 636/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3004 - accuracy: 0.8111 - val_loss: 0.3574 - val_accuracy: 0.7718\n",
      "Epoch 637/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3016 - accuracy: 0.8109 - val_loss: 0.3352 - val_accuracy: 0.7769\n",
      "Epoch 638/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3015 - accuracy: 0.8115 - val_loss: 0.3169 - val_accuracy: 0.7979\n",
      "Epoch 639/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3007 - accuracy: 0.8110 - val_loss: 0.3124 - val_accuracy: 0.8033\n",
      "Epoch 640/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.2991 - accuracy: 0.8142 - val_loss: 0.3306 - val_accuracy: 0.7843\n",
      "Epoch 641/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3041 - accuracy: 0.8067 - val_loss: 0.3603 - val_accuracy: 0.7625\n",
      "Epoch 642/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3008 - accuracy: 0.8119 - val_loss: 0.3209 - val_accuracy: 0.7907\n",
      "Epoch 643/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.2992 - accuracy: 0.8125 - val_loss: 0.3166 - val_accuracy: 0.7934\n",
      "Epoch 644/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3034 - accuracy: 0.8079 - val_loss: 0.3429 - val_accuracy: 0.7803\n",
      "Epoch 645/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3029 - accuracy: 0.8100 - val_loss: 0.3221 - val_accuracy: 0.7915\n",
      "Epoch 646/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3005 - accuracy: 0.8098 - val_loss: 0.3463 - val_accuracy: 0.7747\n",
      "Epoch 647/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3030 - accuracy: 0.8103 - val_loss: 0.3419 - val_accuracy: 0.7667\n",
      "Epoch 648/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2995 - accuracy: 0.8145 - val_loss: 0.3224 - val_accuracy: 0.7865\n",
      "Epoch 649/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3032 - accuracy: 0.8118 - val_loss: 0.3275 - val_accuracy: 0.7907\n",
      "Epoch 650/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3022 - accuracy: 0.8103 - val_loss: 0.3204 - val_accuracy: 0.7886\n",
      "Epoch 651/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3017 - accuracy: 0.8085 - val_loss: 0.3356 - val_accuracy: 0.7814\n",
      "Epoch 652/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3017 - accuracy: 0.8112 - val_loss: 0.3342 - val_accuracy: 0.7881\n",
      "Epoch 653/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3017 - accuracy: 0.8127 - val_loss: 0.3505 - val_accuracy: 0.7771\n",
      "Epoch 654/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3038 - accuracy: 0.8112 - val_loss: 0.3211 - val_accuracy: 0.7926\n",
      "Epoch 655/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3038 - accuracy: 0.8084 - val_loss: 0.3233 - val_accuracy: 0.7867\n",
      "Epoch 656/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.2985 - accuracy: 0.8111 - val_loss: 0.3531 - val_accuracy: 0.7670\n",
      "Epoch 657/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3050 - accuracy: 0.8103 - val_loss: 0.3294 - val_accuracy: 0.7849\n",
      "Epoch 658/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3028 - accuracy: 0.8090 - val_loss: 0.3535 - val_accuracy: 0.7742\n",
      "Epoch 659/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2990 - accuracy: 0.8101 - val_loss: 0.3186 - val_accuracy: 0.7966\n",
      "Epoch 660/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3013 - accuracy: 0.8114 - val_loss: 0.3327 - val_accuracy: 0.7865\n",
      "Epoch 661/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2998 - accuracy: 0.8115 - val_loss: 0.3275 - val_accuracy: 0.7830\n",
      "Epoch 662/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3038 - accuracy: 0.8099 - val_loss: 0.3224 - val_accuracy: 0.7875\n",
      "Epoch 663/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.2996 - accuracy: 0.8104 - val_loss: 0.3222 - val_accuracy: 0.7966\n",
      "Epoch 664/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3017 - accuracy: 0.8103 - val_loss: 0.3206 - val_accuracy: 0.7942\n",
      "Epoch 665/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3019 - accuracy: 0.8097 - val_loss: 0.3376 - val_accuracy: 0.7814\n",
      "Epoch 666/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3013 - accuracy: 0.8080 - val_loss: 0.3153 - val_accuracy: 0.7966\n",
      "Epoch 667/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.2977 - accuracy: 0.8169 - val_loss: 0.3258 - val_accuracy: 0.7905\n",
      "Epoch 668/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3037 - accuracy: 0.8087 - val_loss: 0.3303 - val_accuracy: 0.7811\n",
      "Epoch 669/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3057 - accuracy: 0.8063 - val_loss: 0.3314 - val_accuracy: 0.7825\n",
      "Epoch 670/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3000 - accuracy: 0.8115 - val_loss: 0.3197 - val_accuracy: 0.7926\n",
      "Epoch 671/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2999 - accuracy: 0.8126 - val_loss: 0.3151 - val_accuracy: 0.7958\n",
      "Epoch 672/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3018 - accuracy: 0.8111 - val_loss: 0.3165 - val_accuracy: 0.7958\n",
      "Epoch 673/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.2994 - accuracy: 0.8106 - val_loss: 0.3204 - val_accuracy: 0.7985\n",
      "Epoch 674/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3001 - accuracy: 0.8123 - val_loss: 0.3277 - val_accuracy: 0.7934\n",
      "Epoch 675/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2976 - accuracy: 0.8148 - val_loss: 0.3409 - val_accuracy: 0.7726\n",
      "Epoch 676/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.2992 - accuracy: 0.8129 - val_loss: 0.3212 - val_accuracy: 0.7971\n",
      "Epoch 677/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3009 - accuracy: 0.8115 - val_loss: 0.3196 - val_accuracy: 0.7849\n",
      "Epoch 678/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.2987 - accuracy: 0.8136 - val_loss: 0.3161 - val_accuracy: 0.8019\n",
      "Epoch 679/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3040 - accuracy: 0.8079 - val_loss: 0.3204 - val_accuracy: 0.7985\n",
      "Epoch 680/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.2998 - accuracy: 0.8136 - val_loss: 0.3253 - val_accuracy: 0.7921\n",
      "Epoch 681/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.2985 - accuracy: 0.8135 - val_loss: 0.3551 - val_accuracy: 0.7619\n",
      "Epoch 682/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.2987 - accuracy: 0.8127 - val_loss: 0.3392 - val_accuracy: 0.7841\n",
      "Epoch 683/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3010 - accuracy: 0.8154 - val_loss: 0.3274 - val_accuracy: 0.7859\n",
      "Epoch 684/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3011 - accuracy: 0.8092 - val_loss: 0.3453 - val_accuracy: 0.7705\n",
      "Epoch 685/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.3020 - accuracy: 0.8102 - val_loss: 0.3200 - val_accuracy: 0.7910\n",
      "Epoch 686/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2997 - accuracy: 0.8107 - val_loss: 0.3312 - val_accuracy: 0.7827\n",
      "Epoch 687/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3025 - accuracy: 0.8121 - val_loss: 0.3238 - val_accuracy: 0.7870\n",
      "Epoch 688/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.2997 - accuracy: 0.8148 - val_loss: 0.3385 - val_accuracy: 0.7809\n",
      "Epoch 689/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.3021 - accuracy: 0.8132 - val_loss: 0.3743 - val_accuracy: 0.7577\n",
      "Epoch 690/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3028 - accuracy: 0.8103 - val_loss: 0.3310 - val_accuracy: 0.7811\n",
      "Epoch 691/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2977 - accuracy: 0.8176 - val_loss: 0.3221 - val_accuracy: 0.7931\n",
      "Epoch 692/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2991 - accuracy: 0.8147 - val_loss: 0.3213 - val_accuracy: 0.7953\n",
      "Epoch 693/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.2979 - accuracy: 0.8156 - val_loss: 0.3205 - val_accuracy: 0.7966\n",
      "Epoch 694/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.2984 - accuracy: 0.8115 - val_loss: 0.3271 - val_accuracy: 0.7873\n",
      "Epoch 695/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.2955 - accuracy: 0.8169 - val_loss: 0.3245 - val_accuracy: 0.7891\n",
      "Epoch 696/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.2965 - accuracy: 0.8151 - val_loss: 0.3202 - val_accuracy: 0.7902\n",
      "Epoch 697/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.2986 - accuracy: 0.8148 - val_loss: 0.3348 - val_accuracy: 0.7787\n",
      "Epoch 698/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.2981 - accuracy: 0.8127 - val_loss: 0.3576 - val_accuracy: 0.7705\n",
      "Epoch 699/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.3008 - accuracy: 0.8146 - val_loss: 0.3249 - val_accuracy: 0.7846\n",
      "Epoch 700/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3013 - accuracy: 0.8136 - val_loss: 0.3220 - val_accuracy: 0.7926\n",
      "Epoch 701/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.3023 - accuracy: 0.8144 - val_loss: 0.3287 - val_accuracy: 0.7923\n",
      "Epoch 702/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3008 - accuracy: 0.8137 - val_loss: 0.3249 - val_accuracy: 0.7835\n",
      "Epoch 703/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.2967 - accuracy: 0.8175 - val_loss: 0.3274 - val_accuracy: 0.7883\n",
      "Epoch 704/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.3033 - accuracy: 0.8084 - val_loss: 0.3216 - val_accuracy: 0.7902\n",
      "Epoch 705/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.2987 - accuracy: 0.8123 - val_loss: 0.3191 - val_accuracy: 0.7966\n",
      "Epoch 706/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.2987 - accuracy: 0.8144 - val_loss: 0.3254 - val_accuracy: 0.7838\n",
      "Epoch 707/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.2964 - accuracy: 0.8147 - val_loss: 0.3326 - val_accuracy: 0.7894\n",
      "Epoch 708/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.2985 - accuracy: 0.8113 - val_loss: 0.3517 - val_accuracy: 0.7699\n",
      "Epoch 709/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.2992 - accuracy: 0.8139 - val_loss: 0.3462 - val_accuracy: 0.7771\n",
      "Epoch 710/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.2979 - accuracy: 0.8146 - val_loss: 0.3237 - val_accuracy: 0.7905\n",
      "Epoch 711/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.2983 - accuracy: 0.8148 - val_loss: 0.3302 - val_accuracy: 0.7814\n",
      "Epoch 712/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2981 - accuracy: 0.8145 - val_loss: 0.3279 - val_accuracy: 0.7859\n",
      "Epoch 713/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.3026 - accuracy: 0.8138 - val_loss: 0.3380 - val_accuracy: 0.7846\n",
      "Epoch 714/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.2983 - accuracy: 0.8156 - val_loss: 0.3265 - val_accuracy: 0.7870\n",
      "Epoch 715/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.2946 - accuracy: 0.8159 - val_loss: 0.3219 - val_accuracy: 0.7934\n",
      "Epoch 716/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3006 - accuracy: 0.8131 - val_loss: 0.3344 - val_accuracy: 0.7817\n",
      "Epoch 717/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3003 - accuracy: 0.8140 - val_loss: 0.3351 - val_accuracy: 0.7761\n",
      "Epoch 718/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.2946 - accuracy: 0.8146 - val_loss: 0.3278 - val_accuracy: 0.7851\n",
      "Epoch 719/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.2981 - accuracy: 0.8163 - val_loss: 0.3281 - val_accuracy: 0.7870\n",
      "Epoch 720/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.2985 - accuracy: 0.8138 - val_loss: 0.3385 - val_accuracy: 0.7718\n",
      "Epoch 721/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.2980 - accuracy: 0.8142 - val_loss: 0.3327 - val_accuracy: 0.7825\n",
      "Epoch 722/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.2970 - accuracy: 0.8134 - val_loss: 0.3243 - val_accuracy: 0.7865\n",
      "Epoch 723/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2991 - accuracy: 0.8128 - val_loss: 0.3442 - val_accuracy: 0.7731\n",
      "Epoch 724/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.2992 - accuracy: 0.8122 - val_loss: 0.3313 - val_accuracy: 0.7830\n",
      "Epoch 725/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.2994 - accuracy: 0.8119 - val_loss: 0.3178 - val_accuracy: 0.7902\n",
      "Epoch 726/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2966 - accuracy: 0.8111 - val_loss: 0.3228 - val_accuracy: 0.7883\n",
      "Epoch 727/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2993 - accuracy: 0.8100 - val_loss: 0.3284 - val_accuracy: 0.7787\n",
      "Epoch 728/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.2994 - accuracy: 0.8146 - val_loss: 0.3880 - val_accuracy: 0.7582\n",
      "Epoch 729/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.3014 - accuracy: 0.8123 - val_loss: 0.3394 - val_accuracy: 0.7801\n",
      "Epoch 730/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.2973 - accuracy: 0.8152 - val_loss: 0.3288 - val_accuracy: 0.7843\n",
      "Epoch 731/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.2960 - accuracy: 0.8169 - val_loss: 0.3370 - val_accuracy: 0.7811\n",
      "Epoch 732/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.2960 - accuracy: 0.8160 - val_loss: 0.3352 - val_accuracy: 0.7774\n",
      "Epoch 733/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.2978 - accuracy: 0.8139 - val_loss: 0.3271 - val_accuracy: 0.7883\n",
      "Epoch 734/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.2986 - accuracy: 0.8147 - val_loss: 0.3220 - val_accuracy: 0.7942\n",
      "Epoch 735/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.2955 - accuracy: 0.8178 - val_loss: 0.3206 - val_accuracy: 0.7977\n",
      "Epoch 736/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2976 - accuracy: 0.8139 - val_loss: 0.3317 - val_accuracy: 0.7961\n",
      "Epoch 737/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2985 - accuracy: 0.8144 - val_loss: 0.3249 - val_accuracy: 0.7913\n",
      "Epoch 738/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.2974 - accuracy: 0.8164 - val_loss: 0.3230 - val_accuracy: 0.7870\n",
      "Epoch 739/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.2985 - accuracy: 0.8119 - val_loss: 0.3376 - val_accuracy: 0.7793\n",
      "Epoch 740/1000\n",
      "31/31 [==============================] - 1s 47ms/step - loss: 0.2975 - accuracy: 0.8143 - val_loss: 0.3245 - val_accuracy: 0.7886\n",
      "Epoch 741/1000\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.2960 - accuracy: 0.8175 - val_loss: 0.3612 - val_accuracy: 0.7633\n",
      "Epoch 742/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.2973 - accuracy: 0.8163 - val_loss: 0.3225 - val_accuracy: 0.7934\n",
      "Epoch 743/1000\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.3002 - accuracy: 0.8099 - val_loss: 0.3233 - val_accuracy: 0.7910\n",
      "Epoch 744/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.2950 - accuracy: 0.8167 - val_loss: 0.3406 - val_accuracy: 0.7846\n",
      "Epoch 745/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.2993 - accuracy: 0.8133 - val_loss: 0.3195 - val_accuracy: 0.7921\n",
      "Epoch 746/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.2991 - accuracy: 0.8126 - val_loss: 0.3253 - val_accuracy: 0.7865\n",
      "Epoch 747/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2959 - accuracy: 0.8154 - val_loss: 0.3265 - val_accuracy: 0.7857\n",
      "Epoch 748/1000\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.2982 - accuracy: 0.8167 - val_loss: 0.3274 - val_accuracy: 0.7873\n",
      "Epoch 749/1000\n",
      "31/31 [==============================] - 1s 47ms/step - loss: 0.2979 - accuracy: 0.8160 - val_loss: 0.3265 - val_accuracy: 0.7803\n",
      "Epoch 750/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2957 - accuracy: 0.8162 - val_loss: 0.3212 - val_accuracy: 0.7945\n",
      "Epoch 751/1000\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.2968 - accuracy: 0.8142 - val_loss: 0.3830 - val_accuracy: 0.7521\n",
      "Epoch 752/1000\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.3017 - accuracy: 0.8093 - val_loss: 0.3191 - val_accuracy: 0.7942\n",
      "Epoch 753/1000\n",
      "31/31 [==============================] - 2s 57ms/step - loss: 0.2978 - accuracy: 0.8128 - val_loss: 0.3228 - val_accuracy: 0.7859\n",
      "Epoch 754/1000\n",
      "31/31 [==============================] - 2s 53ms/step - loss: 0.2962 - accuracy: 0.8179 - val_loss: 0.3210 - val_accuracy: 0.7929\n",
      "Epoch 755/1000\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.2954 - accuracy: 0.8131 - val_loss: 0.3386 - val_accuracy: 0.7715\n",
      "Epoch 756/1000\n",
      "31/31 [==============================] - 1s 48ms/step - loss: 0.2983 - accuracy: 0.8128 - val_loss: 0.3357 - val_accuracy: 0.7811\n",
      "Epoch 757/1000\n",
      "31/31 [==============================] - 2s 52ms/step - loss: 0.2974 - accuracy: 0.8146 - val_loss: 0.3269 - val_accuracy: 0.7851\n",
      "Epoch 758/1000\n",
      "31/31 [==============================] - 2s 52ms/step - loss: 0.2963 - accuracy: 0.8130 - val_loss: 0.3430 - val_accuracy: 0.7822\n",
      "Epoch 759/1000\n",
      "31/31 [==============================] - 2s 57ms/step - loss: 0.2927 - accuracy: 0.8204 - val_loss: 0.3125 - val_accuracy: 0.7963\n",
      "Epoch 760/1000\n",
      "31/31 [==============================] - 2s 55ms/step - loss: 0.2944 - accuracy: 0.8160 - val_loss: 0.3163 - val_accuracy: 0.7958\n",
      "Epoch 761/1000\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.2985 - accuracy: 0.8130 - val_loss: 0.3184 - val_accuracy: 0.7910\n",
      "Epoch 762/1000\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.2980 - accuracy: 0.8170 - val_loss: 0.3292 - val_accuracy: 0.7833\n",
      "Epoch 763/1000\n",
      "31/31 [==============================] - 2s 57ms/step - loss: 0.2967 - accuracy: 0.8152 - val_loss: 0.3137 - val_accuracy: 0.7995\n",
      "Epoch 764/1000\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.2963 - accuracy: 0.8132 - val_loss: 0.3077 - val_accuracy: 0.7982\n",
      "Epoch 765/1000\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.2960 - accuracy: 0.8138 - val_loss: 0.3203 - val_accuracy: 0.7867\n",
      "Epoch 766/1000\n",
      "31/31 [==============================] - 2s 49ms/step - loss: 0.2939 - accuracy: 0.8174 - val_loss: 0.3481 - val_accuracy: 0.7798\n",
      "Epoch 767/1000\n",
      "31/31 [==============================] - 2s 50ms/step - loss: 0.2979 - accuracy: 0.8136 - val_loss: 0.3219 - val_accuracy: 0.7865\n",
      "Epoch 768/1000\n",
      "31/31 [==============================] - 2s 52ms/step - loss: 0.2917 - accuracy: 0.8158 - val_loss: 0.3194 - val_accuracy: 0.7937\n",
      "Epoch 769/1000\n",
      "31/31 [==============================] - 2s 57ms/step - loss: 0.2947 - accuracy: 0.8172 - val_loss: 0.3210 - val_accuracy: 0.7894\n",
      "Epoch 770/1000\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.2963 - accuracy: 0.8172 - val_loss: 0.3307 - val_accuracy: 0.7918\n",
      "Epoch 771/1000\n",
      "31/31 [==============================] - 2s 63ms/step - loss: 0.2950 - accuracy: 0.8168 - val_loss: 0.3234 - val_accuracy: 0.7934\n",
      "Epoch 772/1000\n",
      "31/31 [==============================] - 2s 63ms/step - loss: 0.2949 - accuracy: 0.8168 - val_loss: 0.3174 - val_accuracy: 0.7926\n",
      "Epoch 773/1000\n",
      "31/31 [==============================] - 2s 68ms/step - loss: 0.2976 - accuracy: 0.8124 - val_loss: 0.3266 - val_accuracy: 0.7937\n",
      "Epoch 774/1000\n",
      "31/31 [==============================] - 2s 65ms/step - loss: 0.2961 - accuracy: 0.8143 - val_loss: 0.3173 - val_accuracy: 0.8022\n",
      "Epoch 775/1000\n",
      "31/31 [==============================] - 2s 66ms/step - loss: 0.2943 - accuracy: 0.8168 - val_loss: 0.3223 - val_accuracy: 0.7875\n",
      "Epoch 776/1000\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.2931 - accuracy: 0.8172 - val_loss: 0.3298 - val_accuracy: 0.7841\n",
      "Epoch 777/1000\n",
      "31/31 [==============================] - 2s 57ms/step - loss: 0.2972 - accuracy: 0.8142 - val_loss: 0.3384 - val_accuracy: 0.7862\n",
      "Epoch 778/1000\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.2988 - accuracy: 0.8124 - val_loss: 0.3371 - val_accuracy: 0.7766\n",
      "Epoch 779/1000\n",
      "31/31 [==============================] - 1s 48ms/step - loss: 0.2965 - accuracy: 0.8169 - val_loss: 0.3396 - val_accuracy: 0.7758\n",
      "Epoch 780/1000\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.2953 - accuracy: 0.8169 - val_loss: 0.3441 - val_accuracy: 0.7691\n",
      "Epoch 781/1000\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.3003 - accuracy: 0.8092 - val_loss: 0.3258 - val_accuracy: 0.7854\n",
      "Epoch 782/1000\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.2949 - accuracy: 0.8194 - val_loss: 0.3269 - val_accuracy: 0.7857\n",
      "Epoch 783/1000\n",
      "31/31 [==============================] - 1s 47ms/step - loss: 0.2933 - accuracy: 0.8160 - val_loss: 0.3234 - val_accuracy: 0.7841\n",
      "Epoch 784/1000\n",
      "31/31 [==============================] - 1s 47ms/step - loss: 0.2946 - accuracy: 0.8176 - val_loss: 0.3210 - val_accuracy: 0.7923\n",
      "Epoch 785/1000\n",
      "31/31 [==============================] - 1s 47ms/step - loss: 0.2956 - accuracy: 0.8121 - val_loss: 0.3295 - val_accuracy: 0.7934\n",
      "Epoch 786/1000\n",
      "31/31 [==============================] - 2s 49ms/step - loss: 0.2927 - accuracy: 0.8156 - val_loss: 0.3195 - val_accuracy: 0.7931\n",
      "Epoch 787/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 2s 51ms/step - loss: 0.2958 - accuracy: 0.8150 - val_loss: 0.3308 - val_accuracy: 0.7889\n",
      "Epoch 788/1000\n",
      "31/31 [==============================] - 1s 47ms/step - loss: 0.2922 - accuracy: 0.8187 - val_loss: 0.3405 - val_accuracy: 0.7822\n",
      "Epoch 789/1000\n",
      "31/31 [==============================] - 2s 52ms/step - loss: 0.2956 - accuracy: 0.8185 - val_loss: 0.3228 - val_accuracy: 0.7865\n",
      "Epoch 790/1000\n",
      "31/31 [==============================] - 2s 58ms/step - loss: 0.2958 - accuracy: 0.8137 - val_loss: 0.3258 - val_accuracy: 0.7822\n",
      "Epoch 791/1000\n",
      "31/31 [==============================] - 2s 53ms/step - loss: 0.2975 - accuracy: 0.8130 - val_loss: 0.3226 - val_accuracy: 0.7926\n",
      "Epoch 792/1000\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.2955 - accuracy: 0.8176 - val_loss: 0.3204 - val_accuracy: 0.7931\n",
      "Epoch 793/1000\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.2969 - accuracy: 0.8124 - val_loss: 0.3408 - val_accuracy: 0.7761\n",
      "Epoch 794/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.2979 - accuracy: 0.8128 - val_loss: 0.3232 - val_accuracy: 0.7953\n",
      "Epoch 795/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.2948 - accuracy: 0.8155 - val_loss: 0.3375 - val_accuracy: 0.7761\n",
      "Epoch 796/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.2940 - accuracy: 0.8160 - val_loss: 0.3200 - val_accuracy: 0.7923\n",
      "Epoch 797/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2954 - accuracy: 0.8170 - val_loss: 0.3626 - val_accuracy: 0.7603\n",
      "Epoch 798/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2959 - accuracy: 0.8171 - val_loss: 0.3220 - val_accuracy: 0.7931\n",
      "Epoch 799/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.2945 - accuracy: 0.8160 - val_loss: 0.3454 - val_accuracy: 0.7686\n",
      "Epoch 800/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.2936 - accuracy: 0.8165 - val_loss: 0.3299 - val_accuracy: 0.7859\n",
      "Epoch 801/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.2942 - accuracy: 0.8168 - val_loss: 0.3227 - val_accuracy: 0.7931\n",
      "Epoch 802/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.2941 - accuracy: 0.8185 - val_loss: 0.3157 - val_accuracy: 0.7963\n",
      "Epoch 803/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.2940 - accuracy: 0.8176 - val_loss: 0.3300 - val_accuracy: 0.7827\n",
      "Epoch 804/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.2946 - accuracy: 0.8124 - val_loss: 0.3354 - val_accuracy: 0.7811\n",
      "Epoch 805/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.2974 - accuracy: 0.8152 - val_loss: 0.3402 - val_accuracy: 0.7854\n",
      "Epoch 806/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.2963 - accuracy: 0.8140 - val_loss: 0.3304 - val_accuracy: 0.7915\n",
      "Epoch 807/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.2965 - accuracy: 0.8124 - val_loss: 0.3225 - val_accuracy: 0.7889\n",
      "Epoch 808/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.2951 - accuracy: 0.8166 - val_loss: 0.3117 - val_accuracy: 0.7945\n",
      "Epoch 809/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.2932 - accuracy: 0.8194 - val_loss: 0.3533 - val_accuracy: 0.7702\n",
      "Epoch 810/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2973 - accuracy: 0.8150 - val_loss: 0.3231 - val_accuracy: 0.7905\n",
      "Epoch 811/1000\n",
      "31/31 [==============================] - 1s 48ms/step - loss: 0.2928 - accuracy: 0.8139 - val_loss: 0.3235 - val_accuracy: 0.7929\n",
      "Epoch 812/1000\n",
      "31/31 [==============================] - 2s 49ms/step - loss: 0.2929 - accuracy: 0.8212 - val_loss: 0.3300 - val_accuracy: 0.7899\n",
      "Epoch 813/1000\n",
      "31/31 [==============================] - 1s 44ms/step - loss: 0.2928 - accuracy: 0.8206 - val_loss: 0.3357 - val_accuracy: 0.7854\n",
      "Epoch 814/1000\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.2937 - accuracy: 0.8145 - val_loss: 0.3269 - val_accuracy: 0.7889\n",
      "Epoch 815/1000\n",
      "31/31 [==============================] - 1s 44ms/step - loss: 0.2949 - accuracy: 0.8171 - val_loss: 0.3162 - val_accuracy: 0.7929\n",
      "Epoch 816/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2929 - accuracy: 0.8192 - val_loss: 0.3490 - val_accuracy: 0.7766\n",
      "Epoch 817/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2952 - accuracy: 0.8169 - val_loss: 0.3211 - val_accuracy: 0.7929\n",
      "Epoch 818/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2939 - accuracy: 0.8154 - val_loss: 0.3156 - val_accuracy: 0.7915\n",
      "Epoch 819/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2941 - accuracy: 0.8166 - val_loss: 0.3199 - val_accuracy: 0.7897\n",
      "Epoch 820/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.2923 - accuracy: 0.8172 - val_loss: 0.3405 - val_accuracy: 0.7734\n",
      "Epoch 821/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.2957 - accuracy: 0.8177 - val_loss: 0.3278 - val_accuracy: 0.7814\n",
      "Epoch 822/1000\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.2928 - accuracy: 0.8153 - val_loss: 0.3278 - val_accuracy: 0.7838\n",
      "Epoch 823/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.2948 - accuracy: 0.8125 - val_loss: 0.3235 - val_accuracy: 0.7886\n",
      "Epoch 824/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.2918 - accuracy: 0.8212 - val_loss: 0.3355 - val_accuracy: 0.7894\n",
      "Epoch 825/1000\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.2881 - accuracy: 0.8196 - val_loss: 0.3180 - val_accuracy: 0.8001\n",
      "Epoch 826/1000\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.2965 - accuracy: 0.8139 - val_loss: 0.3384 - val_accuracy: 0.7833\n",
      "Epoch 827/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.2960 - accuracy: 0.8154 - val_loss: 0.3233 - val_accuracy: 0.7974\n",
      "Epoch 828/1000\n",
      "31/31 [==============================] - 1s 44ms/step - loss: 0.2951 - accuracy: 0.8187 - val_loss: 0.3188 - val_accuracy: 0.7934\n",
      "Epoch 829/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.2929 - accuracy: 0.8206 - val_loss: 0.3151 - val_accuracy: 0.7979\n",
      "Epoch 830/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.2945 - accuracy: 0.8146 - val_loss: 0.3150 - val_accuracy: 0.8019\n",
      "Epoch 831/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.2884 - accuracy: 0.8214 - val_loss: 0.3239 - val_accuracy: 0.7915\n",
      "Epoch 832/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.2936 - accuracy: 0.8184 - val_loss: 0.3258 - val_accuracy: 0.7862\n",
      "Epoch 833/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.2918 - accuracy: 0.8208 - val_loss: 0.3264 - val_accuracy: 0.7971\n",
      "Epoch 834/1000\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.2891 - accuracy: 0.8206 - val_loss: 0.3304 - val_accuracy: 0.7849\n",
      "Epoch 835/1000\n",
      "31/31 [==============================] - 1s 44ms/step - loss: 0.2910 - accuracy: 0.8206 - val_loss: 0.3325 - val_accuracy: 0.7817\n",
      "Epoch 836/1000\n",
      "31/31 [==============================] - 1s 44ms/step - loss: 0.2932 - accuracy: 0.8176 - val_loss: 0.3354 - val_accuracy: 0.7865\n",
      "Epoch 837/1000\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.2926 - accuracy: 0.8206 - val_loss: 0.3380 - val_accuracy: 0.7793\n",
      "Epoch 838/1000\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.2931 - accuracy: 0.8201 - val_loss: 0.3398 - val_accuracy: 0.7817\n",
      "Epoch 839/1000\n",
      "31/31 [==============================] - 1s 48ms/step - loss: 0.2947 - accuracy: 0.8172 - val_loss: 0.3395 - val_accuracy: 0.7766\n",
      "Epoch 840/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.2924 - accuracy: 0.8182 - val_loss: 0.3284 - val_accuracy: 0.7843\n",
      "Epoch 841/1000\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.2960 - accuracy: 0.8167 - val_loss: 0.3282 - val_accuracy: 0.7835\n",
      "Epoch 842/1000\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.2915 - accuracy: 0.8166 - val_loss: 0.3085 - val_accuracy: 0.7977\n",
      "Epoch 843/1000\n",
      "31/31 [==============================] - 1s 47ms/step - loss: 0.2928 - accuracy: 0.8223 - val_loss: 0.3202 - val_accuracy: 0.7953\n",
      "Epoch 844/1000\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.2930 - accuracy: 0.8176 - val_loss: 0.3160 - val_accuracy: 0.7953\n",
      "Epoch 845/1000\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.2897 - accuracy: 0.8185 - val_loss: 0.3505 - val_accuracy: 0.7729\n",
      "Epoch 846/1000\n",
      "31/31 [==============================] - 1s 44ms/step - loss: 0.2965 - accuracy: 0.8150 - val_loss: 0.3361 - val_accuracy: 0.7875\n",
      "Epoch 847/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.2930 - accuracy: 0.8174 - val_loss: 0.3270 - val_accuracy: 0.7891\n",
      "Epoch 848/1000\n",
      "31/31 [==============================] - 1s 44ms/step - loss: 0.2934 - accuracy: 0.8163 - val_loss: 0.3302 - val_accuracy: 0.7915\n",
      "Epoch 849/1000\n",
      "31/31 [==============================] - 1s 48ms/step - loss: 0.2938 - accuracy: 0.8162 - val_loss: 0.3211 - val_accuracy: 0.7923\n",
      "Epoch 850/1000\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.2948 - accuracy: 0.8172 - val_loss: 0.3182 - val_accuracy: 0.7934\n",
      "Epoch 851/1000\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.2927 - accuracy: 0.8205 - val_loss: 0.3242 - val_accuracy: 0.7918\n",
      "Epoch 852/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.2952 - accuracy: 0.8162 - val_loss: 0.3358 - val_accuracy: 0.7811\n",
      "Epoch 853/1000\n",
      "31/31 [==============================] - 1s 47ms/step - loss: 0.2956 - accuracy: 0.8122 - val_loss: 0.3143 - val_accuracy: 0.7969\n",
      "Epoch 854/1000\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.2894 - accuracy: 0.8200 - val_loss: 0.3583 - val_accuracy: 0.7702\n",
      "Epoch 855/1000\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.2973 - accuracy: 0.8123 - val_loss: 0.3220 - val_accuracy: 0.7873\n",
      "Epoch 856/1000\n",
      "31/31 [==============================] - 2s 57ms/step - loss: 0.2962 - accuracy: 0.8146 - val_loss: 0.3709 - val_accuracy: 0.7569\n",
      "Epoch 857/1000\n",
      "31/31 [==============================] - 2s 49ms/step - loss: 0.2965 - accuracy: 0.8132 - val_loss: 0.3369 - val_accuracy: 0.7809\n",
      "Epoch 858/1000\n",
      "31/31 [==============================] - 1s 48ms/step - loss: 0.2916 - accuracy: 0.8167 - val_loss: 0.3297 - val_accuracy: 0.7846\n",
      "Epoch 859/1000\n",
      "31/31 [==============================] - 2s 74ms/step - loss: 0.2936 - accuracy: 0.8188 - val_loss: 0.3427 - val_accuracy: 0.7747\n",
      "Epoch 860/1000\n",
      "31/31 [==============================] - 2s 61ms/step - loss: 0.2942 - accuracy: 0.8172 - val_loss: 0.3299 - val_accuracy: 0.7897\n",
      "Epoch 861/1000\n",
      "31/31 [==============================] - 2s 52ms/step - loss: 0.2886 - accuracy: 0.8204 - val_loss: 0.3270 - val_accuracy: 0.7827\n",
      "Epoch 862/1000\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.2934 - accuracy: 0.8191 - val_loss: 0.3130 - val_accuracy: 0.8009\n",
      "Epoch 863/1000\n",
      "31/31 [==============================] - 2s 53ms/step - loss: 0.2940 - accuracy: 0.8130 - val_loss: 0.3247 - val_accuracy: 0.7902\n",
      "Epoch 864/1000\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.2941 - accuracy: 0.8149 - val_loss: 0.3196 - val_accuracy: 0.8003\n",
      "Epoch 865/1000\n",
      "31/31 [==============================] - 2s 49ms/step - loss: 0.2905 - accuracy: 0.8202 - val_loss: 0.3237 - val_accuracy: 0.7915\n",
      "Epoch 866/1000\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.2930 - accuracy: 0.8182 - val_loss: 0.3219 - val_accuracy: 0.7854\n",
      "Epoch 867/1000\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.2950 - accuracy: 0.8137 - val_loss: 0.3184 - val_accuracy: 0.7958\n",
      "Epoch 868/1000\n",
      "31/31 [==============================] - 2s 52ms/step - loss: 0.2893 - accuracy: 0.8220 - val_loss: 0.3190 - val_accuracy: 0.7905\n",
      "Epoch 869/1000\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.2904 - accuracy: 0.8205 - val_loss: 0.3140 - val_accuracy: 0.7961\n",
      "Epoch 870/1000\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.2930 - accuracy: 0.8167 - val_loss: 0.3586 - val_accuracy: 0.7686\n",
      "Epoch 871/1000\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.2913 - accuracy: 0.8173 - val_loss: 0.3163 - val_accuracy: 0.7950\n",
      "Epoch 872/1000\n",
      "31/31 [==============================] - 1s 47ms/step - loss: 0.2909 - accuracy: 0.8200 - val_loss: 0.3299 - val_accuracy: 0.7830\n",
      "Epoch 873/1000\n",
      "31/31 [==============================] - 1s 44ms/step - loss: 0.2909 - accuracy: 0.8191 - val_loss: 0.3636 - val_accuracy: 0.7681\n",
      "Epoch 874/1000\n",
      "31/31 [==============================] - 2s 53ms/step - loss: 0.2928 - accuracy: 0.8174 - val_loss: 0.3329 - val_accuracy: 0.7841\n",
      "Epoch 875/1000\n",
      "31/31 [==============================] - 2s 53ms/step - loss: 0.2929 - accuracy: 0.8171 - val_loss: 0.3257 - val_accuracy: 0.7955\n",
      "Epoch 876/1000\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.2914 - accuracy: 0.8142 - val_loss: 0.3283 - val_accuracy: 0.7851\n",
      "Epoch 877/1000\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.2932 - accuracy: 0.8156 - val_loss: 0.3332 - val_accuracy: 0.7758\n",
      "Epoch 878/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.2914 - accuracy: 0.8187 - val_loss: 0.3205 - val_accuracy: 0.7899\n",
      "Epoch 879/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2894 - accuracy: 0.8216 - val_loss: 0.3233 - val_accuracy: 0.7921\n",
      "Epoch 880/1000\n",
      "31/31 [==============================] - 2s 51ms/step - loss: 0.2944 - accuracy: 0.8156 - val_loss: 0.3318 - val_accuracy: 0.7830\n",
      "Epoch 881/1000\n",
      "31/31 [==============================] - 2s 49ms/step - loss: 0.2946 - accuracy: 0.8158 - val_loss: 0.3277 - val_accuracy: 0.7870\n",
      "Epoch 882/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.2948 - accuracy: 0.8158 - val_loss: 0.3388 - val_accuracy: 0.7798\n",
      "Epoch 883/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.2902 - accuracy: 0.8202 - val_loss: 0.3432 - val_accuracy: 0.7726\n",
      "Epoch 884/1000\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.2919 - accuracy: 0.8187 - val_loss: 0.3818 - val_accuracy: 0.7566\n",
      "Epoch 885/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.2948 - accuracy: 0.8156 - val_loss: 0.3273 - val_accuracy: 0.7849\n",
      "Epoch 886/1000\n",
      "31/31 [==============================] - 1s 47ms/step - loss: 0.2884 - accuracy: 0.8193 - val_loss: 0.3147 - val_accuracy: 0.7915\n",
      "Epoch 887/1000\n",
      "31/31 [==============================] - 1s 47ms/step - loss: 0.2903 - accuracy: 0.8210 - val_loss: 0.3336 - val_accuracy: 0.7817\n",
      "Epoch 888/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.2937 - accuracy: 0.8188 - val_loss: 0.3202 - val_accuracy: 0.7902\n",
      "Epoch 889/1000\n",
      "31/31 [==============================] - 1s 47ms/step - loss: 0.2894 - accuracy: 0.8208 - val_loss: 0.3203 - val_accuracy: 0.7974\n",
      "Epoch 890/1000\n",
      "31/31 [==============================] - 1s 48ms/step - loss: 0.2933 - accuracy: 0.8192 - val_loss: 0.3320 - val_accuracy: 0.7862\n",
      "Epoch 891/1000\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.2904 - accuracy: 0.8185 - val_loss: 0.3256 - val_accuracy: 0.7889\n",
      "Epoch 892/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2926 - accuracy: 0.8157 - val_loss: 0.3262 - val_accuracy: 0.7905\n",
      "Epoch 893/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2908 - accuracy: 0.8196 - val_loss: 0.3231 - val_accuracy: 0.7894\n",
      "Epoch 894/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.2894 - accuracy: 0.8195 - val_loss: 0.3267 - val_accuracy: 0.7833\n",
      "Epoch 895/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2916 - accuracy: 0.8191 - val_loss: 0.3397 - val_accuracy: 0.7795\n",
      "Epoch 896/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.2911 - accuracy: 0.8205 - val_loss: 0.3388 - val_accuracy: 0.7785\n",
      "Epoch 897/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.2927 - accuracy: 0.8176 - val_loss: 0.3283 - val_accuracy: 0.7859\n",
      "Epoch 898/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.2921 - accuracy: 0.8166 - val_loss: 0.3262 - val_accuracy: 0.7833\n",
      "Epoch 899/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 1s 40ms/step - loss: 0.2916 - accuracy: 0.8175 - val_loss: 0.3465 - val_accuracy: 0.7689\n",
      "Epoch 900/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.2921 - accuracy: 0.8164 - val_loss: 0.3227 - val_accuracy: 0.7921\n",
      "Epoch 901/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.2928 - accuracy: 0.8178 - val_loss: 0.3156 - val_accuracy: 0.7947\n",
      "Epoch 902/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.2924 - accuracy: 0.8185 - val_loss: 0.3191 - val_accuracy: 0.7934\n",
      "Epoch 903/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2886 - accuracy: 0.8224 - val_loss: 0.3175 - val_accuracy: 0.7945\n",
      "Epoch 904/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.2909 - accuracy: 0.8183 - val_loss: 0.3523 - val_accuracy: 0.7787\n",
      "Epoch 905/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.2906 - accuracy: 0.8221 - val_loss: 0.3224 - val_accuracy: 0.7915\n",
      "Epoch 906/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.2909 - accuracy: 0.8176 - val_loss: 0.3252 - val_accuracy: 0.7934\n",
      "Epoch 907/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.2879 - accuracy: 0.8198 - val_loss: 0.3328 - val_accuracy: 0.7827\n",
      "Epoch 908/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.2899 - accuracy: 0.8185 - val_loss: 0.3238 - val_accuracy: 0.7918\n",
      "Epoch 909/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.2908 - accuracy: 0.8181 - val_loss: 0.3317 - val_accuracy: 0.7737\n",
      "Epoch 910/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.2926 - accuracy: 0.8158 - val_loss: 0.3407 - val_accuracy: 0.7779\n",
      "Epoch 911/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.2940 - accuracy: 0.8178 - val_loss: 0.3281 - val_accuracy: 0.7830\n",
      "Epoch 912/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.2898 - accuracy: 0.8207 - val_loss: 0.3412 - val_accuracy: 0.7891\n",
      "Epoch 913/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.2899 - accuracy: 0.8217 - val_loss: 0.3314 - val_accuracy: 0.7798\n",
      "Epoch 914/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.2912 - accuracy: 0.8188 - val_loss: 0.3408 - val_accuracy: 0.7742\n",
      "Epoch 915/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.2898 - accuracy: 0.8180 - val_loss: 0.3199 - val_accuracy: 0.7945\n",
      "Epoch 916/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.2906 - accuracy: 0.8187 - val_loss: 0.3507 - val_accuracy: 0.7774\n",
      "Epoch 917/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.2895 - accuracy: 0.8209 - val_loss: 0.3190 - val_accuracy: 0.7918\n",
      "Epoch 918/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2894 - accuracy: 0.8173 - val_loss: 0.3238 - val_accuracy: 0.7875\n",
      "Epoch 919/1000\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.2895 - accuracy: 0.8195 - val_loss: 0.3406 - val_accuracy: 0.7809\n",
      "Epoch 920/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.2891 - accuracy: 0.8226 - val_loss: 0.3228 - val_accuracy: 0.8017\n",
      "Epoch 921/1000\n",
      "31/31 [==============================] - 1s 47ms/step - loss: 0.2874 - accuracy: 0.8237 - val_loss: 0.3208 - val_accuracy: 0.7913\n",
      "Epoch 922/1000\n",
      "31/31 [==============================] - 2s 55ms/step - loss: 0.2894 - accuracy: 0.8192 - val_loss: 0.3177 - val_accuracy: 0.7950\n",
      "Epoch 923/1000\n",
      "31/31 [==============================] - 2s 63ms/step - loss: 0.2884 - accuracy: 0.8184 - val_loss: 0.3278 - val_accuracy: 0.7835\n",
      "Epoch 924/1000\n",
      "31/31 [==============================] - 2s 67ms/step - loss: 0.2865 - accuracy: 0.8215 - val_loss: 0.3241 - val_accuracy: 0.7913\n",
      "Epoch 925/1000\n",
      "31/31 [==============================] - 2s 62ms/step - loss: 0.2940 - accuracy: 0.8185 - val_loss: 0.3170 - val_accuracy: 0.7987\n",
      "Epoch 926/1000\n",
      "31/31 [==============================] - 1s 47ms/step - loss: 0.2882 - accuracy: 0.8219 - val_loss: 0.3295 - val_accuracy: 0.7886\n",
      "Epoch 927/1000\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.2933 - accuracy: 0.8158 - val_loss: 0.3459 - val_accuracy: 0.7747\n",
      "Epoch 928/1000\n",
      "31/31 [==============================] - 2s 59ms/step - loss: 0.2921 - accuracy: 0.8215 - val_loss: 0.3212 - val_accuracy: 0.7897\n",
      "Epoch 929/1000\n",
      "31/31 [==============================] - 2s 64ms/step - loss: 0.2880 - accuracy: 0.8207 - val_loss: 0.3203 - val_accuracy: 0.7902\n",
      "Epoch 930/1000\n",
      "31/31 [==============================] - 2s 56ms/step - loss: 0.2898 - accuracy: 0.8201 - val_loss: 0.3234 - val_accuracy: 0.7913\n",
      "Epoch 931/1000\n",
      "31/31 [==============================] - 2s 56ms/step - loss: 0.2897 - accuracy: 0.8208 - val_loss: 0.3223 - val_accuracy: 0.7899\n",
      "Epoch 932/1000\n",
      "31/31 [==============================] - 1s 46ms/step - loss: 0.2886 - accuracy: 0.8194 - val_loss: 0.3574 - val_accuracy: 0.7721\n",
      "Epoch 933/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.2958 - accuracy: 0.8187 - val_loss: 0.3270 - val_accuracy: 0.7859\n",
      "Epoch 934/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.2942 - accuracy: 0.8170 - val_loss: 0.3246 - val_accuracy: 0.7905\n",
      "Epoch 935/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.2862 - accuracy: 0.8245 - val_loss: 0.3283 - val_accuracy: 0.7883\n",
      "Epoch 936/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.2896 - accuracy: 0.8180 - val_loss: 0.3349 - val_accuracy: 0.7827\n",
      "Epoch 937/1000\n",
      "31/31 [==============================] - 1s 45ms/step - loss: 0.2900 - accuracy: 0.8207 - val_loss: 0.3157 - val_accuracy: 0.8003\n",
      "Epoch 938/1000\n",
      "31/31 [==============================] - 1s 47ms/step - loss: 0.2895 - accuracy: 0.8212 - val_loss: 0.3176 - val_accuracy: 0.7982\n",
      "Epoch 939/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2869 - accuracy: 0.8208 - val_loss: 0.3417 - val_accuracy: 0.7822\n",
      "Epoch 940/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2921 - accuracy: 0.8180 - val_loss: 0.3065 - val_accuracy: 0.8001\n",
      "Epoch 941/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.2881 - accuracy: 0.8211 - val_loss: 0.3214 - val_accuracy: 0.7921\n",
      "Epoch 942/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2875 - accuracy: 0.8202 - val_loss: 0.3331 - val_accuracy: 0.7867\n",
      "Epoch 943/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.2879 - accuracy: 0.8194 - val_loss: 0.3183 - val_accuracy: 0.7939\n",
      "Epoch 944/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.2911 - accuracy: 0.8196 - val_loss: 0.3621 - val_accuracy: 0.7593\n",
      "Epoch 945/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.2942 - accuracy: 0.8150 - val_loss: 0.3247 - val_accuracy: 0.7878\n",
      "Epoch 946/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.2894 - accuracy: 0.8200 - val_loss: 0.3333 - val_accuracy: 0.7846\n",
      "Epoch 947/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.2875 - accuracy: 0.8268 - val_loss: 0.3244 - val_accuracy: 0.7945\n",
      "Epoch 948/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2910 - accuracy: 0.8154 - val_loss: 0.3392 - val_accuracy: 0.7809\n",
      "Epoch 949/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2904 - accuracy: 0.8208 - val_loss: 0.3191 - val_accuracy: 0.7961\n",
      "Epoch 950/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.2892 - accuracy: 0.8222 - val_loss: 0.3305 - val_accuracy: 0.7865\n",
      "Epoch 951/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.2895 - accuracy: 0.8200 - val_loss: 0.3202 - val_accuracy: 0.7913\n",
      "Epoch 952/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2902 - accuracy: 0.8225 - val_loss: 0.3209 - val_accuracy: 0.7891\n",
      "Epoch 953/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.2885 - accuracy: 0.8241 - val_loss: 0.3251 - val_accuracy: 0.7891\n",
      "Epoch 954/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.2896 - accuracy: 0.8170 - val_loss: 0.3282 - val_accuracy: 0.7902\n",
      "Epoch 955/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.2891 - accuracy: 0.8214 - val_loss: 0.3250 - val_accuracy: 0.7907\n",
      "Epoch 956/1000\n",
      "31/31 [==============================] - 1s 36ms/step - loss: 0.2904 - accuracy: 0.8190 - val_loss: 0.3203 - val_accuracy: 0.7923\n",
      "Epoch 957/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.2904 - accuracy: 0.8196 - val_loss: 0.3448 - val_accuracy: 0.7835\n",
      "Epoch 958/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.2902 - accuracy: 0.8180 - val_loss: 0.3150 - val_accuracy: 0.7953\n",
      "Epoch 959/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.2894 - accuracy: 0.8172 - val_loss: 0.3171 - val_accuracy: 0.7923\n",
      "Epoch 960/1000\n",
      "31/31 [==============================] - 1s 44ms/step - loss: 0.2871 - accuracy: 0.8226 - val_loss: 0.3124 - val_accuracy: 0.7979\n",
      "Epoch 961/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.2910 - accuracy: 0.8164 - val_loss: 0.3218 - val_accuracy: 0.7870\n",
      "Epoch 962/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.2889 - accuracy: 0.8195 - val_loss: 0.3346 - val_accuracy: 0.7937\n",
      "Epoch 963/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.2893 - accuracy: 0.8192 - val_loss: 0.3207 - val_accuracy: 0.7905\n",
      "Epoch 964/1000\n",
      "31/31 [==============================] - 1s 44ms/step - loss: 0.2902 - accuracy: 0.8216 - val_loss: 0.3162 - val_accuracy: 0.7942\n",
      "Epoch 965/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.2833 - accuracy: 0.8240 - val_loss: 0.3273 - val_accuracy: 0.7878\n",
      "Epoch 966/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.2909 - accuracy: 0.8194 - val_loss: 0.3314 - val_accuracy: 0.7886\n",
      "Epoch 967/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.2858 - accuracy: 0.8264 - val_loss: 0.3392 - val_accuracy: 0.7766\n",
      "Epoch 968/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.2871 - accuracy: 0.8187 - val_loss: 0.3304 - val_accuracy: 0.7977\n",
      "Epoch 969/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2876 - accuracy: 0.8220 - val_loss: 0.3200 - val_accuracy: 0.7945\n",
      "Epoch 970/1000\n",
      "31/31 [==============================] - 1s 44ms/step - loss: 0.2881 - accuracy: 0.8212 - val_loss: 0.3379 - val_accuracy: 0.7825\n",
      "Epoch 971/1000\n",
      "31/31 [==============================] - 1s 44ms/step - loss: 0.2879 - accuracy: 0.8218 - val_loss: 0.3322 - val_accuracy: 0.7889\n",
      "Epoch 972/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.2897 - accuracy: 0.8202 - val_loss: 0.3170 - val_accuracy: 0.7945\n",
      "Epoch 973/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2896 - accuracy: 0.8198 - val_loss: 0.3406 - val_accuracy: 0.7729\n",
      "Epoch 974/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.2882 - accuracy: 0.8230 - val_loss: 0.3255 - val_accuracy: 0.7894\n",
      "Epoch 975/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2864 - accuracy: 0.8242 - val_loss: 0.3303 - val_accuracy: 0.7918\n",
      "Epoch 976/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.2873 - accuracy: 0.8206 - val_loss: 0.3202 - val_accuracy: 0.7958\n",
      "Epoch 977/1000\n",
      "31/31 [==============================] - 1s 42ms/step - loss: 0.2905 - accuracy: 0.8167 - val_loss: 0.3490 - val_accuracy: 0.7846\n",
      "Epoch 978/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2898 - accuracy: 0.8179 - val_loss: 0.3303 - val_accuracy: 0.7859\n",
      "Epoch 979/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.2865 - accuracy: 0.8239 - val_loss: 0.3121 - val_accuracy: 0.8019\n",
      "Epoch 980/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.2887 - accuracy: 0.8200 - val_loss: 0.3185 - val_accuracy: 0.7926\n",
      "Epoch 981/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.2854 - accuracy: 0.8209 - val_loss: 0.3153 - val_accuracy: 0.8014\n",
      "Epoch 982/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.2868 - accuracy: 0.8224 - val_loss: 0.3413 - val_accuracy: 0.7865\n",
      "Epoch 983/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.2890 - accuracy: 0.8208 - val_loss: 0.3262 - val_accuracy: 0.7891\n",
      "Epoch 984/1000\n",
      "31/31 [==============================] - 1s 37ms/step - loss: 0.2870 - accuracy: 0.8220 - val_loss: 0.3562 - val_accuracy: 0.7673\n",
      "Epoch 985/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2876 - accuracy: 0.8227 - val_loss: 0.3443 - val_accuracy: 0.7795\n",
      "Epoch 986/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2865 - accuracy: 0.8217 - val_loss: 0.3238 - val_accuracy: 0.7921\n",
      "Epoch 987/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.2878 - accuracy: 0.8201 - val_loss: 0.3311 - val_accuracy: 0.7777\n",
      "Epoch 988/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2881 - accuracy: 0.8238 - val_loss: 0.3482 - val_accuracy: 0.7787\n",
      "Epoch 989/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2864 - accuracy: 0.8225 - val_loss: 0.3614 - val_accuracy: 0.7731\n",
      "Epoch 990/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.2930 - accuracy: 0.8186 - val_loss: 0.3235 - val_accuracy: 0.7899\n",
      "Epoch 991/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2873 - accuracy: 0.8203 - val_loss: 0.3403 - val_accuracy: 0.7817\n",
      "Epoch 992/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2886 - accuracy: 0.8210 - val_loss: 0.3301 - val_accuracy: 0.7907\n",
      "Epoch 993/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.2841 - accuracy: 0.8236 - val_loss: 0.3216 - val_accuracy: 0.7918\n",
      "Epoch 994/1000\n",
      "31/31 [==============================] - 1s 39ms/step - loss: 0.2867 - accuracy: 0.8233 - val_loss: 0.3230 - val_accuracy: 0.7910\n",
      "Epoch 995/1000\n",
      "31/31 [==============================] - 1s 41ms/step - loss: 0.2861 - accuracy: 0.8249 - val_loss: 0.3507 - val_accuracy: 0.7713\n",
      "Epoch 996/1000\n",
      "31/31 [==============================] - 1s 38ms/step - loss: 0.2872 - accuracy: 0.8224 - val_loss: 0.3378 - val_accuracy: 0.7902\n",
      "Epoch 997/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.2833 - accuracy: 0.8283 - val_loss: 0.3364 - val_accuracy: 0.7801\n",
      "Epoch 998/1000\n",
      "31/31 [==============================] - 1s 40ms/step - loss: 0.2869 - accuracy: 0.8224 - val_loss: 0.3175 - val_accuracy: 0.7923\n",
      "Epoch 999/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.2877 - accuracy: 0.8167 - val_loss: 0.3230 - val_accuracy: 0.7883\n",
      "Epoch 1000/1000\n",
      "31/31 [==============================] - 1s 43ms/step - loss: 0.2910 - accuracy: 0.8174 - val_loss: 0.3243 - val_accuracy: 0.7953\n",
      "289/289 - 1s - loss: 0.3123 - accuracy: 0.8016 - 749ms/epoch - 3ms/step\n"
     ]
    }
   ],
   "source": [
    "input_shape = (6, 6, 1)\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=input_shape),\n",
    "    Conv2D(filters=100, kernel_size=[2,2]), \n",
    "    Activation(\"relu\"),\n",
    "    Dense(100),\n",
    "    Activation(\"elu\"),\n",
    "    Conv2D(filters=20, kernel_size=[2,2]),\n",
    "    Dense(20),\n",
    "    Activation(\"elu\"),\n",
    "    Conv2D(filters=10, kernel_size=[2,2]),\n",
    "    Activation(\"elu\"),\n",
    "    Dropout(rate=0.1),\n",
    "    Dense(10),\n",
    "    Activation(\"elu\"),\n",
    "    Dropout(rate=0.2), \n",
    "    Flatten(),\n",
    "    Dense(3)\n",
    "])\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=100)\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.PolynomialDecay(\n",
    "    initial_learning_rate=1e-2,\n",
    "    decay_steps=300,\n",
    "    end_learning_rate=1e-3,\n",
    "    power=0.5)\n",
    "\n",
    "model.compile(\n",
    "    loss = keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    optimizer = keras.optimizers.RMSprop(lr_schedule),\n",
    "    metrics = [\"accuracy\"],\n",
    ")\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=500, epochs=1000, validation_split=0.2, verbose=True, callbacks=[callback])\n",
    "test_scores = model.evaluate(X_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78cf4846",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
